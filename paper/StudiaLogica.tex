%Version 3 October 2023
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style


%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove �Numbered� in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-vancouver.bst, sn-chicago.bst%  
 
%%\documentclass[sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
\documentclass[sn-mathphys-num]{sn-jnl}% Math and Physical Sciences Numbered Reference Style 
%%\documentclass[sn-mathphys-ay]{sn-jnl}% Math and Physical Sciences Author Year Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[sn-vancouver,Numbered]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style 
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{enumitem}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
\usepackage{proof}
\usepackage{quiver}
\usepackage{thm-restate}

\usepackage{CJKutf8} % Japanese fonts
%%%%
\newcommand{\curly}{\mathrel{\leadsto}}
\newcommand{\llangle}[1][]{\savebox{\@brx}{\(\m@th{#1\langle}\)}%
  \mathopen{\copy\@brx\kern-0.5\wd\@brx\usebox{\@brx}}}
\newcommand{\rrangle}[1][]{\savebox{\@brx}{\(\m@th{#1\rangle}\)}%
  \mathclose{\copy\@brx\kern-0.5\wd\@brx\usebox{\@brx}}}
\makeatother
\newcommand{\ldbc}{[\![}
\newcommand{\rdbc}{]\!]}
\newcommand{\tbar}{[\vec{x}/\vec{t}]}
\newcommand{\ltbar}{[\vec{x}, x/\vec{t}, x]}
\newcommand{\GG}{\Gamma}
\newcommand{\Gg}{\gamma}
\newcommand{\GD}{\Delta}
\newcommand{\Gd}{\delta}
\newcommand{\GL}{\Lambda}
\newcommand{\GO}{\Omega}
\newcommand{\GT}{\Theta}
\newcommand{\vd}{\vdash}
\newcommand{\tl}{\otimes \mathsf{L}}
\newcommand{\tr}{\otimes\mathsf{R}}
\newcommand{\tll}{\otimes^{\mathsf{L}} \mathsf{L}}
\newcommand{\tlr}{\otimes^{\mathsf{R}} \mathsf{L}}
\newcommand{\trl}{\otimes^{\mathsf{L}} \mathsf{R}}
\newcommand{\trr}{\otimes^{\mathsf{R}} \mathsf{R}}
\newcommand{\pass}{\mathsf{pass}}
\newcommand{\unitl}{\mathsf{IL}}
\newcommand{\unitr}{\mathsf{IR}}
\newcommand{\ax}{\mathsf{ax}}
\newcommand{\id}{\mathsf{id}}
\newcommand{\ot}{\otimes}
\newcommand{\otl}{\otimes^{\mathsf{L}}}
\newcommand{\otr}{\otimes^{\mathsf{R}}}
\newcommand{\ol}{\mathbin{\diagup}}
\newcommand{\lo}{\mathbin{\diagdown}}
\newcommand{\lolli}{\multimap}
\newcommand{\lleft}{{\lolli}\mathsf{L}}
\newcommand{\lright}{{\lolli}\mathsf{R}}
\newcommand{\llolli}{\multimap^{\mathsf{L}}}
\newcommand{\rlolli}{\multimap^{\mathsf{R}}}
\newcommand{\llleft}{{\llolli}\mathsf{L}}
\newcommand{\rlleft}{{\rlolli}\mathsf{L}}
\newcommand{\llright}{{\llolli}\mathsf{R}}
\newcommand{\rlright}{{\rlolli}\mathsf{R}}
\newcommand{\illol}{\rotatebox[origin=c]{180}{$\multimap$}}
\newcommand{\unit}{\mathsf{I}}
\newcommand{\msfL}{\mathsf{L}}
\newcommand{\defeq}{=_{\mathsf{df}}}
\newcommand{\comp}{\mathsf{comp}}
\newcommand{\RI}{\mathsf{RI}}
\newcommand{\LI}{\mathsf{LI}}
\newcommand{\Pass}{\mathsf{P}}
\newcommand{\F}{\mathsf{F}}
\newcommand{\xvdash}{\vdash^{x}}
\newcommand{\yvdash}{\vdash^{y}}
\newcommand{\comm}{\ot\mathsf{comm}}
\newcommand{\assl}{\mathsf{assoc}^{\mathsf{L}}}
\newcommand{\assr}{\mathsf{assoc}^{\mathsf{R}}}
\newcommand{\cdl}{\cdot^{\mf{L}}}
\newcommand{\cdr}{\cdot^{\mf{R}}}
\newcommand{\sls}{\slash}
\newcommand{\bsls}{\backslash}

\newcommand{\highlight}[1]{\textcolor{blue}{#1}}

\newcommand{\proofbox}[1]{\begin{tabular}{l} #1 \end{tabular}}

\newcommand{\MILL}{$\mathtt{MILL}$}
\newcommand{\NL}{$\mathtt{NL}$}
\newcommand{\NMILL}{$\mathtt{NMILL}$}
\newcommand{\SkNMILL}{$\mathtt{SkNMILL}$}
\newcommand{\LSkNL}{$\mathtt{LSkNL}$}
% \newcommand{\SkNMILL}{$\mathtt{LSkG}$}
% \newcommand{\SkNMILLm}{$\mathtt{LSkG^{-}}$}
\newcommand{\LSkT}{$\mathtt{LSkT}$}
\newcommand{\RSkT}{$\mathtt{RSkT}$}
\newcommand{\LSkTm}{$\mathtt{LSkT^{-}}$}
\newcommand{\LSkA}{$\mathtt{LSkA}$}
\newcommand{\FSkMCC}{\mathsf{FSkMCl}}
\newcommand{\SkBiC}{$\mathsf{SkBiC}$}
\newcommand{\SkBiCT}{$\mathtt{SkBiCT}$}
\newcommand{\SkBiCA}{$\mathtt{SkBiCA}$}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\mf}[1]{\mathsf{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\gs}[1]{\sigma_{X} (#1)}
\newcommand{\vars}[1]{\mf{var} (#1)}
\newcommand{\FL}{\textbf{FL}}
\newcommand{\scut}[2]{\mf{scut} (#1 , #2)}
\newcommand{\iccut}[2]{\mf{ccut}^* (#1 , #2)}
\newcommand{\MIP}{\textsf{MIP}}
\newcommand{\MMIP}{\textsf{MMIP}}
\newcommand{\sMIP}{\textsf{sMIP}}
\newcommand{\cMIP}{\textsf{cMIP}}
\newcommand{\cMMIP}{\textsf{cMMIP}}

\newcommand{\niccolo}[1]{\textcolor{red}{NV: #1}}
\newcommand{\cheng}[1]{\textcolor{blue}{CSW: #1}}

\setlist[description]{%
  font={\normalfont},
}
%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}[theorem]{Example}%
\newtheorem{remark}[theorem]{Remark}%
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{thmstylethree}%
\newtheorem{definition}[theorem]{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

% \declaretheorem[name=Theorem,numberwithin=section]{thm}

\begin{document}

\title[Craig Interpolation for Semi-{S}ubstructural Logics]{Craig Interpolation for Semi-{S}ubstructural Logics}

%%=============================================================%%
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% \author*[1,2]{\fnm{Joergen W.} \spfx{van der} \sur{Ploeg} 
%%  \sfx{IV}}\email{iauthor@gmail.com}
%%=============================================================%%

\author{\fnm{Niccol{\`o}} \sur{Veltri}}\email{niccolo@cs.ioc.ee}

\author{\fnm{Cheng-Syuan} \sur{Wan}}\email{cswan@cs.ioc.ee}
% \equalcont{These authors contributed equally to this work.}

% \author[1,2]{\fnm{Third} \sur{Author}}\email{iiiauthor@gmail.com}
% \equalcont{These authors contributed equally to this work.}

\affil{\orgdiv{Department of Software Science}, \orgname{Tallinn University of Technology}, \country{Estonia}}

% \affil[2]{\orgdiv{Department}, \orgname{Organization}, \orgaddress{\street{Street}, \city{City}, \postcode{10587}, \state{State}, \country{Country}}}

% \affil[3]{\orgdiv{Department}, \orgname{Organization}, \orgaddress{\street{Street}, \city{City}, \postcode{610101}, \state{State}, \country{Country}}}

%%==================================%%
%% Sample for unstructured abstract %%
%%==================================%%

\abstract{This work studies Craig interpolation for the sequent calculus of skew monoidal closed categories.
Skew monoidal closed categories are a relaxed version of monoidal closed categories, where the structural laws of associativity and left and right unitality, are merely natural transformations with a specific orientation.
The corresponding sequent calculus is semi-substructural because it only admits semi-associativity and semi-unitality, i.e. it is an intermediate logic between non-associative and associative linear logic.
Craig interpolation for various substructural logics has been studied both proof-theoretically and algebraically.
However, it is not clear whether these methods can be applied to semi-substructural logics.
Here we investigate the problem proof-theoretically and show that the sequent calculi for skew monoidal (closed) categories enjoy Craig interpolation by proving a skew version of Maehara interpolation.}

%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

\keywords{skew monoidal closed categories, Craig Interpolation, intuitionistic linear logic, Agda}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section{Introduction}\label{sec:intro}
% \niccolo{Here is how I would structure the introduction for a paper in Studia Logica:
%   \begin{itemize}
%   \item Craig interpolation: what is it and why is it useful, or what are some of its main applications.$\square$
%   \item Small description of substructural logics (like the 1st paragraph we currently have). I would also say here that associativity and unitality may are also appear in the list of structural rules, and nonassociative variants of (extensions of) Lambek calculus are very well studied.$\square$
%   \item Craig interpolation for substructural logics: which of them enjoy it, which methods have been used to prove it.$\square$
%   \item Also mention that other form of interpolation have been investigated in the substructural setting, like deductive interpolation and Maehara interpolation (is this how Ono called them?). Also that the implicational fragment of intuitionistic logic, and its substructural fragments, enjoy yet another form of interpolation. Cite the papers of Kanazawa and Pentus.$\square$
%   \item Now we can state that our work is on Craig interpolation for semi-substructural logics. Explain what semi-substructural means, e.g. by describing the shape of sequents and stating that certain (directions of) structural rules do not admit a proof. Also what connectives we consider. Similar to what is currently the 4th paragraph. $\square$
%   \item A small paragraph saying that our initial interest in these logic comes from category theory. Here we can mention the connection to skew monoidal closed categories and the coherence problem, and how we solved it through a calculus of focused proofs. Similar to what is currently the 2nd paragraph.$\square$
%   \item Here we should give some details on our proof of Craig interpolation. We use syntactic techniques to prove it. But we cannot directly use Maehara's method since, similarly to the implication fragment of Lambek calculus, Maehara interpolation fails. Instead, our sequent calculus satisfies yet another form of interpolation, scut/ccut-interpolation (we can write the statement here). Scut-interpolation is similar to Maheara interpolation, while ccut-interpolation is similar to Pebtus/Kanazawa interpolation $\square$
%   \item In our endeavour we are not only interested in provability, but also in proofs and their equality. This is again motivated by our categorical, as opposed to algebraic, interpretation. We introduce an equivalence of derivations capturing eta- and permutative conversions, which is sound and complete with respect to the categorical semantics.$\square$
%   \item In particular, we are also interested in proof-relevant interpolation in the sense of Cubric and recently Saurin. Instantiating the general categorical framework of Cubric to our setting, this means that our scut/ccut-interpolation procedures are in a way inverses of the admissible scut/ccut rules. Give the statement of what is currently Thm 7.$\square$
%   \item Finally, we have formalized everything in the Agda proof assistant.$\square$
%   \end{itemize}
% }

Craig interpolation is a fundamental result in first-order logic, named after the logician William Craig \cite{craig:interpolation:1957}.
A logic $\mc{L}$ has the \emph{Craig interpolation property} if, for any formula $A \to C$ provable in $\mc{L}$ (where $\to$ is the implication connective in $\mc{L}$), there exists a formula $B$ such that $A \to B$ and $B \to C$ are provable in $\mc{L}$, satisfying the variable condition: $\vars{B} \subseteq \vars{A} \cap \vars{C}$, where $\vars{A}$ is the set of atomic formulae appearing in $A$.
Craig interpolation has been moslty employed to prove model-theoretical results, including Beth's definability theorem \cite{Beth1953}, but more recently it has found applications in other areas, e.g. in model checking \cite{Henzinger2004}.

From the viewpoint of sequent calculus, substructural logics are defined by the absence of at least one structural rule.
A notable instance is Joachim Lambek's syntactic calculus \cite{lambek:mathematics:58}, which forbids weakening, contraction and exchange.
Its non-associative variant, which has been extensively studied \cite{moot:categorial:2012}, also disallows associativity. Another significant example is linear logic, introduced by Jean-Yves Girard \cite{girard:linear:87}, where weakening and contraction are disallowed but can be recovered for specific formulas through modalities.
Substructural logics have proven useful for modelling various phenomena in different research areas, from the computational analysis of natural language syntax to the development of programming languages sensitive to resource management.

Craig interpolation for substructural logics has been extensively studied, using either algebraic or proof-theoretic techniques. 

For substructural logics that lack a cut-free sequent calculus, such as arbitrary extensions of the full Lambek calculus with exchange ($\FL_{\textbf{e}}$), Craig interpolation is established using algebraic methods such as amalgamation.
For further details on this approach, see \cite{Kihara2009}.

For substructural logics that admit a cut-free sequent calculus, Craig interpolation is typically proven by adapting Maehara's method \cite{maehara1961}, which originally aimed to prove interpolation for $\mathbf{LK}$, a sequent calculus for classical logic.
This includes the full Lambek calculus (\FL) and its extensions that incorporate various combinations of weakening, exchange, and contraction.
In the case of \FL, for instance, the proof starts by establishing a stronger form of interpolation which we call \emph{Maehara interpolation property} (\MIP) \cite{ono:proof:nonclassical:1998}. 
The latter property states:
\begin{description}
  \item[(\MIP~for \FL)] Given $f : \Gamma \vdash C$ and a partition $\langle \Gamma_0, \Gamma_1, \Gamma_2 \rangle$ of $\Gamma$, there exist a formula $D$ and two derivations $g : \Gamma_1 \vdash D$ and $h : \Gamma_0, D, \Gamma_2 \vdash C$, and $\vars{D} \subseteq \vars{\Gamma_0} \cap \vars{\Gamma_0, \Gamma_1, C}$
\end{description}
Being a partition simply means that the ordered list of formulae $\Gamma$ is equal to the concatenation of $\Gamma_0, \Gamma_1$ and $\Gamma_2$, i.e. $\Gamma = \Gamma_0, \Gamma_1, \Gamma_2$. 
\FL~without additive connectives enjoys a stronger variant of Maehara interpolation where the variable condition is replaced by a  multiplicity condition \cite{roorda1991,moot:categorial:2012}.
The property states:
\begin{description}
  \item[(\MIP~for \FL~with multiplicity condition)] Given $f : \Gamma \vdash C$ and a partition $\langle \Gamma_0, \Gamma_1, \Gamma_2 \rangle$ of $\Gamma$, there exist a formula $D$ and two derivations $g : \Gamma_1 \vdash D$ and $h : \Gamma_0, D, \Gamma_2 \vdash C$, and $\gs{D} \leq \gs{\GG_1}$ and $\gs{D} \leq \gs{\GG_0, \GG_2 , C}$ for all atomic formulae $X$.
\end{description}
Above $\gs{A}$ is equal to the number of occurrences of the atomic formula $X$ in $A$.
Maehara interpolation also holds for the non-associative variant of \FL, for an appropriate reformulation of the principle in which antecedents are trees of formulae instead of lists.
Notice that Craig interpolation is a property of a logic (with a notion of implication), while Maehara interpolation is a property of a deductive system in which it is possible to appropriately partition antecedents.

Maehara interpolation is a stronger form of the so-called \emph{deductive interpolation property}. A logic $\mc{L}$ has the deductive interpolation property if, for any formulae $A$ and $C$, whenever $A \vd C$ (where $\vd$ is the consequence relation of $\mc{L}$), then there exists a formula $B$ such that $A \vd B$ and $B \vd C$ while also satisfying the usual variable condition. Furthermore, if the sequent calculus of $\mc{L}$ admits the invertibility of implication-right rules (as is the case in \FL\ for both left- and right-implication), Craig interpolation follows immediately as a consequence of deductive interpolation.

While Maheara's method is often applicable to extensions of \FL, it does not work for some of its fragment, which therefore do not enjoy Maehara interpolation. This is the case for fragments lacking multiplicative and/or additive conjunction, such as the product-free Lambek calculus \cite{Pentus1997} (with only left- and right-implications as connectives) and the implicational fragment of intuitionistic logic \cite{Kanazawa2006}. 
The variant of Maehara interpolation satisfied by the product-free Lambek calculus, which we dub \emph{Maehara multi-interpolation} (\MMIP), is particularly relevant for our work. Here is its statement, which we have slightly modified to better align with our forthcoming discussion:
\begin{description}
  \item[(\MMIP~for product-free Lambek calculus)]  Given $f: \Gamma \vd C$ and a partition $\langle \GG_0,\GG_1, \GG_2 \rangle$ of $\GG$, there exist 
    \begin{itemize}
    \item[--] a partition $\langle \GD_1, \dots, \GD_n \rangle$ of $\GG_1$,
    \item[--] a list of interpolant formulae $D_1, \dots, D_n$,
    \item[--] a derivation $g: \GG_0, D_1, \dots, D_n, \GG_2 \vd C$,
    \item[--] a derivation $h_i : \GD_i \vd D_i$ for all $i \in [1\dots n]$, such that
    \item[--] $\gs{D_i} \leq \gs{\GD_i}$ and $\gs{D_1, \dots, D_n} \leq \gs{\GG_0, \GG_2, C}$ for all $i \in [1 \dots n]$ and atomic formulae $X$.
  \end{itemize}
\end{description}
Differently from Maehara interpolation, in the above property we look for a  list of interpolants instead of a single formula.
This adjustment allows to overcome the difficulty caused by the absence of conjunction.
%\niccolo{(Are all difficulties actually overcome? Does this property still imply deductive/Craig interpolation?)}.


In this paper, we aim at proving Craig interpolation for the \emph{semi-substructural} logic \SkNMILL\ which we recently introduced in collaboration with Tarmo Uustalu \cite{UVW:protsn}.
In our terminology, a logic is semi-substructural if it is an intermediate logic inbetween (certain fragments of) non-associative and associative intuitionistic linear logic (or the Lambek calculus).
Semi-associativity and semi-unitality are encoded as follows.
Sequents are in the form $S \mid \Gamma \vdash A$, where the antecedent consists of an optional formula $S$, called stoup, adapted from Girard \cite{girard:constructive:91}, and an ordered list of formulae $\Gamma$.
The succedent is a single formula $A$.
We restrict the application of introduction rules in an appropriate way to allow only one of the directions of associativity and unitality, e.g. only $(A \ot B)\ot C \mid \quad \vd A \ot (B \ot C)$ is provable in \SkNMILL, while its inverse $A \ot (B \ot C) \mid \quad \vd (A \ot B) \ot C$ is not.
In other words, only directed variants of the structural rules of associativity and unitality are included, while their inverses are generally disallowed.

The introduction of semi-substructural logics was originally motivated by the study of cobinatorial properties of certain categorical structures, called \emph{left skew monoidal categories} \cite{szlachanyi:skew-monoidal:2012}.
These categories are a weaker variant of MacLane's monoidal categories.
In left skew monoidal categories, the structural morphisms of associativity and unitality (which are natural transformations typically called `associator' and `unitors') are not required to have an inverse. Instead, they are natural family of morphisms with a specific orientation.
For this reason, left skew monoidal categories can be seen as \emph{semi-associative} and \emph{semi-unital} variants of monoidal categories. 

Different variants of left skew monoidal categories have led to the development of their corresponding semi-substructural logic.
These include $(i)$ left skew semigroup \cite{zeilberger:semiassociative:19}, $(ii)$ left skew monoidal \cite{uustalu:sequent:2021}, $(iii)$ left skew (prounital) closed \cite{uustalu:deductive:nodate}, $(iv)$ left skew monoidal closed categories \cite{UVW:protsn,veltri:multifocus:23,wan2024}, and $(v)$ left distributive skew monoidal categories with finite products and coproducts \cite{VW:2023}.
Each of these logics admits a cut-free sequent calculus. Moreover, they admit a subcalculus of ``proofs in normal form'', which is inspired by Jean-Marc Andreoli's focusing method \cite{andreoli:logic:1992} and as such provides a way to make root-first proof search more deterministic.
Practically, the focusing method is employed for solving the coherence problem for the corresponding variants of left skew monoidal categories. In the case of left skew monoidal closed categories, a solution to the coherence (or word) problem consists of a procedure for deciding equality of parallel morphisms in the free left skew monoidal closed category on a given set $\mathsf{At}$.
In previous work, we showed that the focused subcalculus for \SkNMILL\ is a concrete presentation of such free category, so a solution to the coherence problem is obtained by checking whether two morphisms are represented by the same derivation in the focused subcalculus.


To prove Craig interpolation for \SkNMILL, we need to modify the statement of Maehara interpolation.
This modification is required due to issues similar to those encountered in the product-free Lambek calculus \cite{Pentus1997} and the implicational fragment of intuitionistic logic \cite{Kanazawa2006}, where Maehara interpolation fails. The main result of the paper is the following:
\begin{restatable*}{theorem}{genIntrp}\label{genIntrp}
In the sequent calculus for \SkNMILL, the two following interpolation properties hold:
\begin{description}
\item[(\sMIP)] Given a derivation $f: S \mid \Gamma \vd C$ and a partition $\langle \GG_0,\GG_1 \rangle$ of $\GG$, there exist
\begin{itemize}
  \item[--] an interpolant formula $D$,
  \item[--] a derivation $g : S \mid \GG_0 \vd D$,
  \item[--] a derivation $h : D \mid \GG_1 \vd C$, such that
  \item[--] $\gs{D} \leq \gs{S , \GG_0}$ and $\gs{D} \leq \gs{\GG_1 , C}$ for all atomic formulae $X$.
\end{itemize}
%   , where $s(S) = I$ if $S = {-}$ or $s(S) = B$ if $S = B$.
\item[(\cMMIP)] Given a derivation $f: S \mid \Gamma \vd C$ and a partition $\langle \GG_0,\GG_1, \GG_2 \rangle$ of $\GG$, there exist  
  \begin{itemize}
    \item[--] a partition $\langle \GD_1, \dots, \GD_n \rangle$ of $\GG_1$,
    \item[--] a list of interpolant formulae $D_1, \dots, D_n$,
    \item[--] $g: S \mid \GG_0, D_1, \dots, D_n, \GG_2 \vd C$,
    \item[--] $h_i : {-} \mid \GD_i \vd D_i$ for  all $i \in [1\dots n]$,
    \item[--] $\gs{D_i} \leq \gs{\GD_i}$ for all $i \in [1 \dots n]$ and atomic formulae $X$, and
    \item[--] $\gs{D_1, \dots, D_n} \leq \gs{S, \GG_0, \GG_2, C}$ for all $i \in [1 \dots n]$ and atomic formulae $X$.
  \end{itemize}
\end{description}
\end{restatable*}
In \SkNMILL, the first property \sMIP, which stands for \emph{stoup Maehara interpolation}, resembles Maehara interpolation for the \FL. Whereas $\cMMIP$, which stands for \emph{context Maehara multi-interpolation}, is similar to Maehara multi-interpolation for the product-free Lambek calculus. %discussed by Pentus and Kanazawa.


Motivated by the categorical interpretation of \SkNMILL, we take one more step and investigate the interplay between the admissible cut rules (called $\mf{scut}$ and $\mf{ccut}$) and the derivations produced by the interpolation algorithm of Theorem \ref{genIntrp}.
%how proofs and their equivalences behave under the interpolation procedure. 
In previous work \cite{UVW:protsn}, we introduced an equivalence relation on derivations ($\circeq$) that captures $eta$-conversions and permutative conversions, and is both sound and complete with respect to the categorical semantics.
We show that the \sMIP~and \cMMIP~procedures of Theorem \ref{genIntrp} are right inverses of the admissible rules $\mf{scut}$ and $\mf{ccut}$, respectively. Formally, we prove the following theorem:
\begin{restatable*}{theorem}{cutIntrp}\label{cutIntrp}
~
  \begin{enumerate}[label=(\roman*)]
  \item Let $g : S \mid \GG_0 \vd D$ and $h : D \mid \GG_1 \vd C$ be the derivations obtained by applying the \sMIP~procedure on a derivation $f: S \mid \GG \vd C$ with the partition $\langle \GG_0 , \GG_1 \rangle$. Then $\mf{scut}(g, h) \circeq f$.
  \item Let $g : S \mid \GG_0 , D_1 , \dots, D_n, \GG_2 \vd C$ and $h_i : {-} \mid \GD_i \vd D_i$ for $i \in [1 \dots n]$ be derivations obtained by applying the \cMMIP~procedure on a derivation $f: S \mid \GG \vd C$ with the partition $\langle \GG_0 , \GG_1 , \GG_2 \rangle$. Then $\mf{ccut}^*([h_i] , g) \circeq f$.
  \end{enumerate}
\end{restatable*}

In the above statement, $\mf{ccut}^*$ denotes multiple applications of the admissible $\mf{ccut}$ rule, one for each derivation $h_i$.
Theorems \ref{genIntrp} and \ref{cutIntrp} together show that \SkNMILL\ satisfies a \emph{proof-relevant} form of Craig interpolation, in the sense  formulated in the early 90s by {\v{C}}ubri{\'c} \cite{Cubric1994} in the setting of intuitionistic propositional logic and recently discussed also by Saurin \cite{Saurin2024} for (extensions of) classical linear logic.

% For example, consider the sequent $W, W\bsls Y, W , W \bsls X , X \bsls (Y \bsls Z) \longrightarrow Z $ with the partition $\langle [\ ] , [W, W\bsls Y, W , W \bsls X], [X \bsls (Y \bsls Z)] \rangle$ in the product-free Lambek calculus.
% By Maehara's method, the interpolant formula should be $X \cdot Y$, but the calculus does not include $\cdot$ as a connective.

% In both cases above, the formula-version of general interpolation fails because the additive ($\land$) and multiplicative ($\cdot$) conjunction are not present, respectively.

% \emph{Left skew monoidal categories} \cite{szlachanyi:skew-monoidal:2012} are a weaker variant of MacLane's monoidal categories where the structural morphisms of associativity and unitality are not required to be bidirectional, they are natural transformations with a particular orientation.
% Therefore, they can be seen as \emph{semi-associative} and \emph{semi-unital} variants of monoidal categories. 
% Left skew monoidal categories arise naturally in the semantics of programming languages \cite{altenkirch:monads:2014}, while the concept of semi-associativity is connected with combinatorial structures like the Tamari lattice and Stasheff associahedra \cite{zeilberger:semiassociative:19}.

% In recent years, in collaboration with Tarmo Uustalu and Noam Zeilberger, we started a research project on \emph{semi-substructural} logics, which is inspired by a series of developments on left skew monoidal categories and related variants by Szlach{\'a}nyi, Street, Bourke, Lack and many others \cite{szlachanyi:skew-monoidal:2012,street:skew-closed:2013,lack:triangulations:2014,bourke:skew:2018,bourke:lack:braided:2020}.

% We call the internal languages of left skew monoidal categories and their variants \emph{semi-substructural} logics, because they are intermediate logics in between (certain fragments of) non-associative and associative intuitionistic linear logic (or Lambek calculus).
% Semi-associativity and semi-unitality are encoded as follows.
% Sequents are in the form $S \mid \Gamma \vdash A$, where the antecedent consists of an optional formula $S$, called stoup, adapted from Girard \cite{girard:constructive:91}, and an ordered list of formulae $\Gamma$.
% The succedent is a single formula $A$.
% We restrict the application of introduction rules in an appropriate way to allow only one of the directions of associativity and unitality.
% % the one in the definition of skew monoidal category. For example, left-introduction rules are allowed to act only on the formula in stoup position, not on formulae in $\Gamma$.

% This approach has successfully captured internal languages for a variety of categories, including  $(i)$ left skew semigroup \cite{zeilberger:semiassociative:19}, $(ii)$ left skew monoidal \cite{uustalu:sequent:2021}, $(iii)$ left skew (prounital) closed \cite{uustalu:deductive:nodate}, $(iv)$ left skew monoidal closed categories \cite{UVW:protsn,veltri:multifocus:23}, and $(v)$ left distributive skew monoidal categories with finite products and coproducts \cite{VW:2023} through skew variants of the fragments of non-commutative intuitionistic linear logic consisting of combinations of connectives $(\unit,\ot,\lolli,\land,\lor)$.
% Additionally, discussions have covered partial normality conditions, in which one or more structural morphisms are allowed to have an inverse \cite{uustalu:proof:nodate}, as well as extensions with skew exchange \`a la Bourke and Lack \cite{veltri:coherence:2021,VW:2023}.

% All of the aforementioned calculi with sequents of the form $S \mid \GG \vd A$ are cut-free and therefore, by their rule design, they are decidable.
% Moreover, they all admit sound and complete subcalculi inspired by Andreoli's focusing \cite{andreoli:logic:1992} in which
% rules are restricted to be applied in a specific order.
% A focused calculus provides an algorithm to solve both the proof identity problems for its non-focused calculus and coherence problems for its corresponding variant of left skew monoidal category.

% The variation of Craig interpolation is defined by replacing the multiplicity condition with that given a set of formulae $\GT$, and given a derivation $f:A \vd^{\GT} C$, if all formulae appearing in $f$ are in $\GT$, then there exists a formula $B \in \GT$ and two derivations $f_0: A\vd^{\GT} B$ and $f_1: B \vd^{\GT} C$. 
% In this paper, we call the former Craig interpolation and the latter weak interpolation.

% In this work, we show that sequent calculi for left skew monoidal (closed) categories enjoy Craig interpolation.

All the proofs presented in this paper have been formalized in the proof assistant Agda. The full formalization is freely available at the following website:
\begin{center}
  \url{https://github.com/niccoloveltri/code-skewmonclosed/tree/interpolation}.
\end{center}
% By reversing all structural morphisms and modifying coherence conditions in left skew monoidal closed categories, right skew monoidal closed categories emerge \cite{uustalu:eilenberg-kelly:2020}.
% Moreover, skew bi-closed categories are defined by appropriately integrating left and right skew monoidal closed structures.
% It is natural for us to consider sound sequent calculi for these categories.
% However, the implication rules are not well-behaved when just modeling right skew monoidal closed categories with sequent calculus {\`a} la Girard.

% In short, both problems stem from the skew structure concealed within the flat antecedent of $S \mid \GG \vd A$.
% While the antecedent $S \mid \GG$ is defined similarly to an ordered list, it is actually a tree associating to the left.

% In this work, we analyze and solve these two problems with ideas and methods from non-associative Lambek calculus.
% We start in Section \ref{sec:syntax}, by introducing the sequent calculus {\` a} la Girard (\SkNMILL) for left skew monoidal closed categories from \cite{UVW:protsn} and elaborating its limitation on having interpolation.
% By generalizing the method in \cite{ono:proof:nonclassical:1998}, we prove interpolation for a cut-free sequent calculus \LSkT, which is inspired by sequent calculus 
% for non-associative Lambek calculus \cite{bulinska:2009,moot:categorial:2012} and equivalent to \SkNMILL.
% The antecedents of sequents in \LSkT~are trees, which save us from discussing impossible cases when proving interpolation.
% Moreover, by the equivalence between \SkNMILL~and \LSkT, we can prove a special form of interpolation for \SkNMILL~via \LSkT.

% In Section \ref{sec:skew:categories}, we introduce definitions of left (right) skew monoidal closed categories and skew bi-closed categories, and normality conditions for skew categories.
% In Section \ref{sec:calculi:skbic}, we describe two calculi for skew bi-closed categories: one is an axiomatic calculus (\SkBiCA), while the other is a sequent calculus (\SkBiCT) similar to the multimodal non-associative Lambek calculus \cite{moortgat:multimodl:1996}.
% In Section \ref{sec:algebraic:relational:model}, we introduce the relational semantics for \SkBiCA.
% We define the relational semantics via a Kripke frame with two ternary relations and show that the partially ordered set which consists of subsets of possible worlds with appropriate operations is a thin skew bi-closed category.
% Furthermore, by theorem (\ref{thm:main}), we can prove a thin version of main theorems in \cite{uustalu:eilenberg-kelly:2020}.

\section{A Sequent Calculus for \SkNMILL}\label{sec:syntax}
We start by recalling the sequent calculus for left skew monoidal closed categories that was introduced in \cite{UVW:protsn}, which we name \SkNMILL. This is a ``skew variant'' of non-commutative multiplicative intuitionistic linear logic, in a way that will be made precise later in this section.

Formulae are inductively generated by the grammar $A, B::= X \ | \ \unit \ | \ A \ot B \ | \ A \lolli B$, where $X$ comes from a set $\mathsf{At}$ of atoms, $\unit$ is a multiplicative unit, $\ot$ is multiplicative conjunction and $\lolli$ is a linear implication. The set of formulae is denoted $\mf{Fma}$.

A sequent is a triple of the form $S \mid \Gamma \vd A$. The antecedent consists of two parts: an optional formula $S$, called the \emph{stoup} (a terminology that comes from Girard \cite{girard:constructive:91}), and an ordered list of formulae $\Gamma$, that we call the \emph{context}. The succedent $A$ is a single formula.
The symbol $S$ consistently denotes a stoup, meaning $S$ can either be a single formula or empty, indicated as $S = {-}$. Furthermore, letters $X$, $Y$, $Z$ and $W$ always denote atomic formulae.
% The design of sequents is from previous work on syntactic characterizations for skew structures \cite{uustalu:sequent:2021,uustalu:proof:nodate,uustalu:deductive:nodate,veltri:coherence:2021}.
% The peculiar design of sequents, involving the presence of the stoup in the antecedent, comes from previous work on deductive systems with skew structure by Uustalu, Veltri and Zeilberger \cite{uustalu:sequent:2021,uustalu:proof:nodate,uustalu:deductive:nodate,veltri:coherence:2021}.

Derivations are generated recursively by the following rules:
\begin{equation}\label{eq:seqcalc:skmc:Gir}
	  % \def\arraystretch{2.5}
	  \begin{array}{cc}
		\infer[\ax]{A \mid \quad \vd A}{}
		&
                \infer[\pass]{{-} \mid A , \Gamma \vd C}{A \mid \Gamma \vd C}
                \\[10pt]
		\infer[\lleft]{A \lolli B \mid \Gamma , \Delta \vd C}{
		  {-} \mid \Gamma \vd A
		  &
		  B \mid \Delta \vd C
		}
		&
		\infer[\lright]{S \mid \Gamma \vd A \lolli B}{S \mid \Gamma , A \vd B}
                \\[10pt]
		\infer[\unitl]{\unit \mid \Gamma \vd C}{{-} \mid \Gamma \vd C}
		&
		\infer[\unitr]{{-} \mid \quad \vd \unit}{}
                \\[10pt]
		\infer[\tl]{A \ot B \mid \Gamma \vd C}{A \mid B , \Gamma \vd C}
		&
		\infer[\tr]{S \mid \Gamma , \Delta \vd A \ot B}{
		  S \mid \Gamma \vd A
		  &
		  {-} \mid \Delta \vd B
		}
	  \end{array}
    % \begin{array}{c}
		% \infer[\ax]{A \mid \quad \vd A}{}
		% \quad
    %         \infer[\pass]{{-} \mid A , \Gamma \vd C}{A \mid \Gamma \vd C}
		% \quad
    %         \infer[\unitr]{{-} \mid \quad \vd \unit}{}
    %         \quad
		% \infer[\unitl]{\unit \mid \Gamma \vd C}{{-} \mid \Gamma \vd C}
		% \\[5pt]
    %         \infer[\tl]{A \ot B \mid \Gamma \vd C}{A \mid B , \Gamma \vd C}
		% \quad
		% \infer[\tr]{S \mid \Gamma , \Delta \vd A \ot B}{
		%   S \mid \Gamma \vd A
		%   &
		%   {-} \mid \Delta \vd B
		% }
		% \\[5pt]
		% \infer[\lleft]{A \lolli B \mid \Gamma , \Delta \vd C}{
		%   {-} \mid \Gamma \vd A
		%   &
		%   B \mid \Delta \vd C
		% }
		% \quad
		% \infer[\lright]{S \mid \Gamma \vd A \lolli B}{S \mid \Gamma , A \vd B}
	  % \end{array}
	\end{equation}
The inference rules in (\ref{eq:seqcalc:skmc:Gir}) are similar to the ones in the sequent calculus for non-commutative multiplicative intuitionistic linear logic (\NMILL) \cite{abrusci:noncommutative:1990}, but with some crucial differences: 
% $(i)$ The left logical rules $\unitl$, $\tl$ and $\lleft$, read bottom-up, are only allowed to be applied on the formula in the stoup position. $(ii)$ The right tensor rule $\tr$, read bottom-up, splits the antecedent of a sequent $S \mid \Gamma, \Delta \vd A \ot B$ and in the case where $S$ is a formula, $S$ is always moved to the stoup of the left premise, even if $\Gamma$ is empty.
% $(iii)$ The presence of the stoup distinguishes two types of antecedents, $A \mid \Gamma$ and ${-} \mid A, \Gamma$. The structural rule $\pass$ (for `passivation'), read bottom-up, allows the moving of the leftmost formula in the context to the stoup position whenever the stoup is empty.
% $(iv)$ The logical connectives of \NMILL\ (and associative Lambek calculus) typically include two ordered implications $\lolli$ and $\illol$, which are two variants of linear implication arising from the removal of the exchange rule from intuitionistic linear logic. In \SkNMILL~only the left implication $\lolli$ (right residuation in Lambek calculus) is present. 
\begin{enumerate}
\item The left logical rules $\unitl$, $\tl$ and $\lleft$, read bottom-up, are only allowed to be applied on the formula in the stoup position.
% In particular, there is no general way to remove a unit $\unit$ nor decompose a tensor $A \ot B$ if these formulae are located in the context and not in the stoup
%  (we will see in (\ref{eq:lleft:gen}) that something can actually be done to deal with implications $A \lolli B$ in the context).
\item The right tensor rule $\tr$, read bottom-up, splits the antecedent of a sequent $S \mid \Gamma, \Delta \vd A \ot B$ and in the case where $S$ is a formula, $S$ is always moved to the stoup of the left premise, even if $\Gamma$ is empty.
% whereby the formula in the stoup, in case such a formula is present, has to be moved to the stoup of the first premise. In particular, the stoup formula of the conclusion cannot be moved to the antecedent of the second premise even if $\Gamma$ is chosen to be empty.
\item The presence of the stoup distinguishes two types of antecedents, $A \mid \Gamma$ and ${-} \mid A, \Gamma$. The structural rule $\pass$ (for `passivation'), read bottom-up, allows the moving of the leftmost formula in the context to the stoup position whenever the stoup is empty.
\item The logical connectives of \NMILL~typically include two ordered implications $\lolli$ and $\illol$ (often also called residuals), which are two variants of linear implication arising from the removal of the exchange rule from intuitionistic linear logic. In our logic \SkNMILL, only the implication $\lolli$ is present, which Lambek would call right implication/residual.
%  \niccolo{Is this left or right implication?}
% It is currently not clear to us whether the inclusion of the second implication to our logic is a meaningful addition and whether it corresponds to some particular categorical notion.
\end{enumerate}
% The restrictions in 1--4 are essential for precisely capturing all the features of skew monoidal closed categories and nothing more, as we discuss in Section \ref{sec:catsem}.
% Notice also that, similarly to the case of \NMILL, all structural rules of exchange, contraction, and weakening are absent. We give names to derivations and we write $f: S \mid \Gamma \vdash A$ when $f$ is a particular derivation of the sequent $S \mid \Gamma \vdash A$.

This calculus is cut-free, in the sense that the following two rules are admissible:
\begin{equation}\label{eq:cut}
      \infer[\mathsf{scut}]{S \mid \Gamma , \Delta \vd C}{
        \deduce{S \mid \Gamma \vd A}{}
        &
        \deduce{A \mid \Delta \vd C}{}
      }
      \qquad
      \infer[\mathsf{ccut}]{S \mid \Delta_0 , \Gamma , \Delta_1 \vd C}{
        \deduce{{-} \mid \Gamma \vd A}{}
        &
        \deduce{S \mid \Delta_0 , A , \Delta_1 \vd C}{}
      }
\end{equation}
The presence of two cut rules comes from the fact that the cut formula can appear either in the stoup or the context of the second premise.

% \niccolo{Define $\lright^*$ and $\lleft^*$ here.}

Given a list of formulae $\GL$ and a list of derivations $\phi$ of the form ${-} \mid \GG_i \vd A_i$ for $i \in [1 \dots n]$, we define iterated $\lright$ and $\lleft$ respectively as follows:
\begin{equation}\label{-oR-oL*}
  \begin{array}{c}
    \infer[\lright^*]{S \mid \GG \vd \ldbc \GL \mid B\rdbc}{
      \deduce{S \mid \GG , \GL \vd B}{f}
    }
    \qquad
    \infer[\lleft^*]{\ldbc \GL \mid B \rdbc \mid \GG , \GD \vd C}{
      \phi
      &
      \deduce{B \mid \GD \vd C}{f}
    }
  \end{array}
\end{equation}
The formula $\ldbc \GD \mid B \rdbc$ is defined inductively as
\begin{itemize}
  \item[--] If $\GD = [\ ]$, then $\ldbc \GD \mid B \rdbc = B$.
  \item[--] If $\GD =  (A_1 , \GD')$, then $\ldbc \GD \mid B \rdbc = A_1 \lolli \ldbc \GD' \mid B \rdbc$.
\end{itemize} 
% \begin{definition}
%   ~
%   \begin{itemize}
%     \item Given a derivation $f : S \mid \GG , \GD \vd B$, we define $\lright^* (\GD , f)$ recursively:
%   \begin{itemize}
%     \item If $\GD = [\ ]$, then $\lright^* (\GD, f) = f$.
%     \item If $\GD = (A_1 , \GD')$, then $\lright^* (\GD , f) = \lright (\lright^* (\GD' , f))$.
%   \end{itemize}
%   \item Given a derivation $f : B \mid \GD \vd C$ and a list of derivations $\phi$ that consists of $g_i : {-} \mid \GG_i \vd A_i$ for $i \in [1 \dots n]$, we define $\lleft^* (\phi , f)$ recursively:
%   \begin{itemize}
%     \item If $\phi = [\ ]$, then $\lleft^* (\phi , f) = f$.
%     \item If $\phi = (g_1 , \phi')$, then $\lleft^* (\phi , f) = \lleft (g_1 , \lleft^* (\phi' , f))$.
%   \end{itemize}
%   \end{itemize}
% \end{definition}

\section{Equivalence of Derivations}\label{sec:equiv}

Sets of derivations are quotiented by a congruence relation $\circeq$, generated by the pairs of derivations in Figure \ref{fig:circeqeta} and \ref{fig:circeq-perm}.
The three equations in Figure \ref{fig:circeqeta} are $\eta$-conversions, completely characterizing the $\ax$ rule on non-atomic formulae. The equations in Figure \ref{fig:circeq-perm} are permutative conversions.
\begin{figure}
\begin{displaymath}
\begin{array}{rcl}
    \proofbox{
      \infer[\ax]{\unit \mid \quad \vd \unit}{}
    }
  &\circeq&
  \proofbox{
     \infer[\unitl]{\unit \mid \quad \vd \unit}{
    \infer[\unitr]{{-} \mid \quad \vd \unit}{}
   }
  }
  \\[20pt]
  \proofbox{
    \infer[\ax]{A \ot B \mid \quad \vd A \ot B}{}
  }
  &\circeq&
  \proofbox{
    \infer[\tl]{A \ot B \mid \quad \vd A \ot B}{
      \infer[\tr]{A \mid B \vd A \ot B}{
        \infer[\ax]{A \mid \quad \vd A}{}
        &
        \infer[\pass]{{-} \mid B \vd B}{
          \infer[\ax]{B \mid \quad \vd B}{}
        }
      }
    }
  }
  \\[35pt]
  \proofbox{
    \infer[\ax]{A \lolli B \mid \quad \vd A \lolli B}{}
  }
  &\circeq&
  \proofbox{
    \infer[\lright]{A \lolli B \mid \quad \vd A \lolli B}{
      \infer[\lleft]{A \lolli B \mid A \vd B}{
        \infer[\pass]{{-} \mid A \vd A}{
          \infer[\ax]{A \mid \quad \vd A}{}
        }
        &
        \infer[\ax]{B \mid \quad \vd B}{}
      }
    }
  }
\end{array}
\end{displaymath}
\caption{Equivalence of derivations: $\eta$-conversions}
\label{fig:circeqeta}
\end{figure}

\begin{figure}
\begin{displaymath}
\arraycolsep=0pt    
\begin{array}{rcl}
  \proofbox{
    \infer[\tr]{{-} \mid A' , \GG , \GD \vd A \ot B}{
      \infer[\pass]{{-} \mid A' , \GG \vd A}{
        \deduce{A' \mid \GG \vd A}{f}
      }
      &
      \deduce{{-} \mid \GD \vd B}{g}
    }
  }
  
  &\circeq&
  
  \proofbox{
    \infer[\pass]{{-} \mid A' , \GG , \GD \vd A \ot B}{
      \infer[\tr]{A' \mid \GG , \GD \vd A \ot B}{
        \deduce{A' \mid \GG \vd A}{f}
        &
        \deduce{{-} \mid \GD \vd B}{g}
      }
    }
  }
  \\[30pt]
  \proofbox{
    \infer[\tr]{\unit \mid \GG , \GD \vd A \ot B}{
      \infer[\unitl]{\unit \mid \GG \vd A}{
        \deduce{{-} \mid \GG \vd A}{f}
      }
      &
      \deduce{{-} \mid \GD \vd B}{g}
    }
  }
  
  &\circeq&
  
  \proofbox{
    \infer[\unitl]{\unit \mid \GG , \GD \vd A \ot B}{
      \infer[\tr]{{-} \mid \GG , \GD \vd A \ot B}{
        \deduce{{-} \mid \GG \vd A}{f}
        &
        \deduce{{-} \mid \GD \vd B}{g}
      }
    }
  }
  \\[30pt]
  \proofbox{
    \infer[\tr]{A' \ot B' \mid \GG , \GD \vd A \ot B}{
      \infer[\tl]{A' \ot B' \mid \GG \vd A}{
        \deduce{A' \mid B' , \GG \vd A}{f}
      }
      &
      \deduce{{-} \mid \GD \vd B}{g}
    }
  }
  
  &\circeq&
  
  \proofbox{
    \infer[\tl]{A' \ot B' \mid \GG , \GD \vd A \ot B}{
      \infer[\tr]{A' \mid B' , \GG , \GD \vd A \ot B}{
        \deduce{A' \mid B', \GG \vd A}{f}
        &
        \deduce{{-} \mid \GD \vd B}{g}
      }
    }
  }
  \\[30pt]
  \proofbox{
    \infer[\tr]{C \lolli D \mid \GG , \GD , \GL \vd A \ot B}{
      \infer[\lleft]{C \lolli D \mid \GG , \GD \vd A}{
        \deduce{{-} \mid \GG \vd C}{f}
        & \!\!
        \deduce{D \mid \GD \vd A}{g}
      }
      & \!\!\!
      \deduce{{-} \mid \GL \vd B}{h}
    }
  } \!\!\!\!\!\!
  
  &\circeq&
  
  \proofbox{
    \infer[\lleft]{C \lolli D \mid \GG , \GD  , \GL\vd A \ot B}{
      \deduce{{-} \mid \GG \vd C}{f}
      & \!\!\!
      \infer[\tr]{D \mid \GD, \GL \vd A \ot B}{
        \deduce{D \mid \GD \vd A}{g}
        & \!\!
        \deduce{{-} \mid \GL \vd B}{h}
      }
    }
  }
  \\[30pt]
  \proofbox{
    \infer[\pass]{{-} \mid A' , \GG \vd A \lolli B}{
      \infer[\lright]{A' \mid \GG \vd A \lolli B}{
        \deduce{A' \mid \GG , A \vd B}{f}
      }
    }
  }
  
  &\circeq&
  
  \proofbox{
    \infer[\lright]{{-} \mid A' , \GG \vd A \lolli B}{
      \infer[\pass]{{-} \mid A' , \GG , A \vd B}{
        \deduce{A' \mid \GG , A \vd B}{f}
      }
    }
  }
  \\[30pt]
  \proofbox{
    \infer[\unitl]{\unit \mid \GG \vd A \lolli B}{
      \infer[\lright]{{-} \mid \GG \vd A \lolli B}{
        \deduce{{-} \mid \GG , A \vd B}{f}
      }
    }
  }
  
  &\circeq&
  
  \proofbox{
    \infer[\lright]{\unit \mid \GG \vd A \lolli B}{
      \infer[\unitl]{\unit \mid \GG , A \vd B}{
        \deduce{{-} \mid \GG , A \vd B}{f}
      }
    }
  }
  \\[30pt]
  \proofbox{
    \infer[\tl]{A' \ot B' \mid \GG \vd A \lolli B}{
      \infer[\lright]{A' \mid B' , \GG \vd A \lolli B}{
        \deduce{A' \mid B' , \GG , A \vd B}{f}
      }
    }
  }
  
  &\circeq&
  
  \proofbox{
    \infer[\lright]{A' \ot B' \mid \GG \vd A \lolli B}{
      \infer[\tl]{A' \ot B' \mid \GG , A \vd B}{
        \deduce{A' \mid B' , \GG , A \vd B}{f}
      }
    }
  }
  \\[30pt]
  \proofbox{
    \infer[\lleft]{A' \lolli B' \mid \GG , \GD \vd A \lolli B}{
      \deduce{{-} \mid \GG \vd A'}{f}
      &
      \infer[\lright]{B' \mid \GD \vd A \lolli B}{
        \deduce{B' \mid \GD , A \vd B}{g}
      }
    }
  }
  
  &\circeq&
  
  \proofbox{
    \infer[\lright]{A' \lolli B' \mid \GG , \GD \vd A \lolli B}{
      \infer[\lleft]{A' \lolli B' \mid \GG , A \vd B}{
        \deduce{{-} \mid \GG \vd A'}{f}
        &
        \deduce{B' \mid \GD , A \vd B}{g}
      }
    }
  }
\end{array}
\end{displaymath}
\caption{Equivalence of derivations: permutative conversions}
\label{fig:circeq-perm}
\end{figure}

% \begin{displaymath}
% \label{fig:circeq}
% \small\begin{array}{rlll}
%   \ax_{\unit} &\circeq \unitl \text{ } (\unitr)
%   \\[2pt]
%   \ax_{A \ot B} &\circeq \tl \text{ } (\tr \text{ } (\ax_{A} , \pass \text{ } \ax_{B}))
%   \\[2pt]
%   \ax_{A \lolli B} &\circeq \lright \text{ } (\lleft \text{ } (\pass \text{ } \ax_{A}, \ax_{B} ))
%   \\[2pt]
%   \tr \text{ } (\pass \text{ } f, g) &\circeq \pass \text{ } (\tr \text{ } (f, g)) &&f : A' \mid \Gamma \vdash A, g : {-} \mid \Delta \vdash B
%   \\[2pt]
%   \tr \text{ } (\unitl \text{ } f, g) &\circeq \unitl \text{ } (\tr \text{ } (f , g)) &&f : {-} \mid \Gamma \vdash A , g : {-} \mid \Delta \vdash B
%   \\[2pt]
%   \tr \text{ } (\tl \text{ } f, g) &\circeq \tl \text{ } (\tr \text{ } (f , g)) &&f : A' \mid B' , \Gamma \vdash A , g : {-} \mid \Delta \vdash B
%   \\[2pt]
%   \tr \text{ } (\lleft \text{ } (f , g), h) & \circeq \lleft \text{ } (f, \tr \text{ } (g, h)) &&f: {-} \mid \Gamma \vdash A, g : B \mid \Delta \vdash C, h : {-} \mid \Lambda \vdash D
%   \\[2pt]
%   \pass \text{ } (\lright \text{ } f) &\circeq \lright \text{ } (\pass \text{ } f) &&f : A' \mid \Gamma , A \vdash B
%   \\[2pt]
%   \unitl \text{ } (\lright \text{ } f) &\circeq \lright \text{ } (\unitl \text{ } f) &&f : {-} \mid \Gamma , A \vdash B
%   \\[2pt]
%   \tl \text{ } (\lright \text{ } f) &\circeq \lright \text{ } (\tl \text{ } f) &&f : A \mid B , \Gamma , C \vdash D
%   \\[2pt]
%   \lleft \text{ } (f, \lright \text{ } g) &\circeq \lright \text{ } (\lleft \text{ } (f, g)) &&f : {-} \mid \Gamma \vdash A', g : B' \mid \Delta , A \vdash B
% \end{array}
% \end{displaymath}

The generating equations of $\circeq$ have been carefully selected to appropriately match the equational theory of left skew monoidal closed categories. More information about this relationship in terms of categorical semantics can be found in \cite{UVW:protsn}, where a precise correspondence between sequent calculus derivations, the congruence relation $\circeq$ and left skew monoidal closed categories is described.
%For a more detailed explanation on the sequent calculus and an interpretation of the system as a logic of resources, see \cite[Section 2]{UVW:protsn}.
The latter paper also contains an interpretation of the sequent calculus as a logic of resources, as well as a calculus of derivations in normal form, which completely characterizes proofs modulo the congruence relation $\circeq$.

% \niccolo{Move admissible cut equations here.}
Moreover, following equations of derivations hold in \SkNMILL~due to the cut-elimination procedures defined in \cite{UVW:protsn,wan2024}.
\begin{proposition}\label{eq:cut}
    \begin{displaymath}
      \begin{array}{l}
      % scut-hass
      \begin{array}{c}
        \infer[\mf{scut}]{S \mid \GG_0, \GG_1 , \GG_2 , \GG_3 \vd C}{
          \deduce{S \mid \GG_0 \vd A}{f}
          &
          \infer[\mf{ccut}]{A \mid \GG_1 , \GG_2 , \GG_3 \vd C}{
            \deduce{{-} \mid \GG_2 \vd B}{g}
            &
            \deduce{A \mid \GG_1 , B , \GG_3 \vd C}{h}
          }
        }
      \end{array}
      \\[10pt]
        \qquad \qquad \qquad \qquad \qquad  =
        \begin{array}{c}
          \infer[\mf{ccut}]{S \mid \GG_0, \GG_1 , \GG_2 , \GG_3 \vd C}{
          \deduce{{-} \mid \GG_2 \vd B}{g}
          &
          \infer[\mf{scut}]{S \mid \GG_0 , \GG_1 , B , \GG_3 \vd C}{
            \deduce{S \mid \GG_0 \vd A}{f}
            &
            \deduce{A \mid \GG_1 , B , \GG_3 \vd C}{h}
          }
        }
        \end{array}
      \end{array}
      \end{displaymath}
      \begin{displaymath}
      \begin{array}{l}
      % ccut-hass
      \begin{array}{c}
        \infer[\mf{ccut}]{S \mid \GG_0 , \GG_1 , \GG_2 , \GG_3 , \GG_4 \vd C}{
          \deduce{{-} \mid \GG_1 \vd A}{f}
          &
          \infer[\mf{ccut}]{S \mid \GG_0 , A , \GG_2 , \GG_3 , \GG_4 \vd C}{
            \deduce{{-} \mid \GG_3 \vd B}{g}
            &
            \deduce{S \mid \GG_0 , A , \GG_2 , B , \GG_4 \vd C}{h}
          }
        }
      \end{array}
      \\[10pt]
      \qquad \qquad \qquad \qquad \qquad  =
      \begin{array}{c}
        \infer[\mf{ccut}]{S \mid \GG_0 , \GG_1 , \GG_2 , \GG_3 , \GG_4 \vd C}{
          \deduce{{-} \mid \GG_3 \vd B}{g}
          &
          \infer[\mf{ccut}]{S \mid \GG_0 , \GG_1 , \GG_2 , B , \GG_4 \vd C}{
            \deduce{{-} \mid \GG_1 \vd A}{f}
            &
            \deduce{S \mid \GG_0 , A , \GG_2 , B , \GG_4 \vd C}{h}
          }
        }
      \end{array}
      \\[30pt]
      \end{array}
    \end{displaymath}
    \begin{displaymath}
      \begin{array}{l}
      % scutscut-vass
      \begin{array}{c}
        \infer[\mf{scut}]{S \mid \GG_0 , \GG_1 , \GG_2 \vd C}{
          \deduce{S \mid \GG_0 \vd A}{f}
          &
          \infer[\mf{scut}]{A \mid \GG_1 , \GG_2 \vd C}{
            \deduce{A \mid \GG_1 \vd B}{g}
            &
            \deduce{B \mid \GG_2 \vd C}{h}
          }
        }
      \end{array}
      \\[10pt]
      \qquad \qquad \qquad \qquad \qquad  =
      \begin{array}{c}
        \infer[\mf{scut}]{S \mid \GG_0 , \GG_1 , \GG_2 \vd C}{
          \infer[\mf{scut}]{S \mid \GG_0 , \GG_1 \vd B}{
            \deduce{S \mid \GG_0 \vd A}{f}
            &
            \deduce{A \mid \GG_1 \vd B}{g}
          }
          &
          \deduce{B \mid \GG_2 \vd C}{h}
        }
      \end{array}
      \end{array}
      \end{displaymath}
      \begin{displaymath}
      \begin{array}{l}
      %  ccutscut-vass
      \begin{array}{c}
        \infer[\mf{ccut}]{S \mid \GG_0 , \GG_1 , \GG_2 , \GG_3 \vd C}{
          \deduce{{-} \mid \GG_1 \vd A}{f}
          &
          \infer[\mf{scut}]{S \mid \GG_0 , A , \GG_2 , \GG_3 \vd C}{
            \deduce{S \mid \GG_0 , A , \GG_2 \vd B}{g}
            &
            \deduce{B \mid \GG_3 \vd C}{h}
          }
        }
      \end{array}
      \\[10pt]
      \qquad \qquad \qquad \qquad \qquad  =
      \begin{array}{c}
        \infer[\mf{scut}]{S \mid \GG_0 , \GG_1 , \GG_2 , \GG_3 \vd C}{
          \infer[\mf{ccut}]{S \mid \GG_0 , \GG_1 , \GG_2 \vd B}{
            \deduce{{-} \mid \GG_1 \vd A}{f}
            &
            \deduce{S \mid \GG_0 , A , \GG_2 \vd B}{g}
          }
          &
          \deduce{B \mid \GG_3 \vd C}{h}
        }
      \end{array}
      \end{array}
      \end{displaymath}
      \begin{displaymath}
      \begin{array}{l}
      % ccutccut-vass
      \begin{array}{c}
        \infer[\mf{ccut}]{S \mid \GG_0 , \GG_1 , \GG_2 , \GG_3 , \GG_4 \vd C}{
          \deduce{{-} \mid \GG_2 \vd A}{f}
          &
          \infer[\mf{ccut}]{S \mid \GG_0 , \GG_1 , A , \GG_3 , \GG_4 \vd C}{
            \deduce{{-} \mid \GG_1 , A , \GG_3 \vd B}{g}
            &
            \deduce{S \mid \GG_0 , B , \GG_4 \vd C}{h}
          }
        }
      \end{array}
      \\[10pt]
      \qquad \qquad \qquad \qquad \qquad  =
      \begin{array}{c}
        \infer[\mf{ccut}]{S \mid \GG_0 , \GG_1 , \GG_2 , \GG_3 , \GG_4 \vd C}{
          \infer[\mf{ccut}]{S \mid \GG_1 , \GG_2 , \GG_3 \vd B}{
            \deduce{{-} \mid \GG_2 \vd A}{f}
            &
            \deduce{{-} \mid \GG_1 , A , \GG_3 \vd B}{g}
          }
          &
          \deduce{S \mid \GG_0 , B , \GG_4 \vd C}{h}
        }
      \end{array}
    \end{array}
   \end{displaymath}
\end{proposition}
\begin{proof}
  Equations are proved by mutual induction on derivations.
\end{proof}
Given a derivation $f : S \mid \GG_0 , A_1, \dots , A_n \vd B$ and a list of derivations $\phi$ that consists of $g_i : {-} \mid \GD_i \vd A_i$ for $i \in [1 \dots n]$, the following equation is derivable from the five equations in Proposition \ref{eq:cut}.
For simplicity, we denote $(A_1 , \dots , A_n)$ and $(\GD_1 , \dots , \GD_n)$ as $\GL$ and $\GD$, respectively.
   \begin{equation}\label{scut-or-ols}
   \begin{array}{l}
    \begin{array}{c}
    \infer[\mf{scut}]{S \mid \GG_0, \GD, \GG_1 \vd C}{
      \infer[\lright^*]{S \mid \GG_0 \vd \ldbc \GL \mid B\rdbc}{
        \deduce{S \mid \GG_0 , \GL \vd B}{f}
      }
      &
      \infer[\lleft^*]{\ldbc \GL \mid B\rdbc \mid \GD , \GG_1 \vd C}{
        \phi
        &
        \deduce{B \mid \GG_1 \vd C}{h}
      }
    }
   \end{array}
   \\[10pt]
   \qquad \qquad \qquad \qquad \qquad
   = 
   \quad
    \begin{array}{c}
      \infer[\mf{scut}]{S \mid \GG_0 , \GD , \GG_1 \vd C}{
        \infer[\mf{ccut}^*]{S \mid \GG_0 , \GD \vd B}{
          \phi
          &
          \deduce{S \mid \GG_0 , \GD \vd B}{f}
        }
        &
        \deduce{B \mid \GG_1 \vd C}{h}
      }
    \end{array}
   \end{array}
   \end{equation}
The iterated version of context cut ($\mf{ccut}^*$) is defined as follows:
\begin{definition}
~
\begin{itemize}
  \item  Given a derivation $f : S \mid \GG_0 , D_1 , \dots, D_n , \GG_2 \vd C$ and a list of derivations $\phi$ where for any $g_i \in \phi$, $\mf{ccut}(g_i , f)$ is a derivation. 
  We define $\mf{ccut}^* (\phi , f)$ recursively:
  \begin{itemize}
    \item[--] If $\phi = [\ ]$, then $\mf{ccut}^* (\phi , f) = f$.
    \item[--] If $\phi = (g_1 , \phi')$, then $\mf{ccut}^* (\phi , f) = \mf{ccut} (g_1 , (\mf{ccut}^* (\phi' , f)))$.
  \end{itemize}
\end{itemize}
\end{definition}
\section{Failure of Maehara Interpolation}\label{sec:failure}

The goal of this paper is proving that the logic \SkNMILL~satisfies the Craig interpolation property. But, as already mentioned in the introductive section, we cannot follow the same proof strategy used in the (associative or non-associative) Lambek calculus, where Craig interpolation follows as a corollary to Maehara interpolation. This is because the sequent calculus of \SkNMILL~does not satisfy Maehara interpolation. Let us see why.

First, in analogy with the presence of two admissible cut rules (\ref{eq:cut}), there are also two different form of interpolation. This is because the subsequence of the antecedents for which we wish to find an interpolant can either contain the stoup or it can be fully included in the context. More explicitly, given an antecedent $S \mid \Gamma$, we can either: $(i)$ split the context $\Gamma = \Gamma_1,\Gamma_2$ in two parts and look for an interpolant of the sub-antecedent $S \mid \Gamma_1$, or $(ii)$ split the context $\Gamma = \Gamma_0,\Gamma_1,\Gamma_2$ in three parts and look for an interpolant of the sub-context $\Gamma_1$.
The Maehara interpolation property in \SkNMILL~would then consist of two statement, a \emph{stoup Maheara interpolation} (\sMIP) and a \emph{context Maehara interpolation} (\cMIP):
\begin{description}
\item[(\sMIP)] Given $f: S \mid \Gamma \vd C$ and a partition $\langle \GG_0,\GG_1 \rangle$ of $\GG$, there exists  
\begin{itemize}
  \item[--] an interpolant formula $D$,
  \item[--] a derivation $g : S \mid \GG_0 \vd D$,
  \item[--] a derivation $h : D \mid \GG_1 \vd C$, such that
  \item[--] $\gs{D} \leq \gs{S , \GG_0}$ and $\gs{D} \leq \gs{\GG_1 , C}$ for all atomic formulae $X$.
\end{itemize}
\item[(\cMIP)] Given $f: S \mid \Gamma \vd C$ and a partition $\langle \GG_0,\GG_1, \GG_2 \rangle$ of $\GG$, there exists  
    \begin{itemize}
      \item[--] an interpolant formula $D$,
    \item[--] a derivation $g : {-} \mid \GG_1 \vd D$,
    \item[--] a derivation $h : S \mid \GG_0, D, \GG_2 \vd C$, such that
    \item[--] $\gs{D} \leq \gs{\GG_1}$ and $\gs{D} \leq \gs{S , \GG_0 , \GG_2 , C}$ for all atomic formulae $X$.    
  \end{itemize}
\end{description}



% In this section, we adapt Maehara's method to prove that \SkNMILL~enjoys Craig interpolation.
% Maehara's method is based on cut-free sequent calculi.
% The process is to prove Maehara interpolation, and then argue that Craig interpolation is a corollary.
% 
% Given a formula $A$ and an atomic formula $X$, $\gs{A}$ is a composition of two functions, one transforms a formula to a list of atomic formulae and the other counts the occurrences of $X$.
% Given a context $\GG$ and an atomic formula $X$, $\gs{\GG}$ is a composition of three functions, the first transforms each formula in $\GG$ to a list of atomic formulae, the second merges the lists into one list and the last counts the occurrences of $X$.
% 
% Adapted from \cite[Chapter 2.10]{moot:categorial:2012}, the Maehara interpolation for the associative Lambek calculus is:
% \begin{itemize}
%   \item[\ ] Given $f : \Gamma \vdash C$ and any partition $\langle \Gamma_0, \Gamma_1, \Gamma_2 \rangle$ of $\Gamma$, where $\GG_1$ is non-empty, there exists a formula $D$ such that
%   \begin{itemize}
%     \item[--] $g : \Gamma_1 \vdash D$,
%     \item[--] $h : \Gamma_0, D, \Gamma_2 \vdash C$, and 
%     \item[--] $\gs{D} \leq \gs{\GG_1}$ and  $\gs{D} \leq \gs{\GG_0 , \GG_1 , D}$ for every $X$.
%   \end{itemize}
% \end{itemize}
% The proof proceeds by induction on the height of derivations and we should exhaust all cases of any partition.
% \\
% It is natural to attempt to prove a similar statement for \SkNMILL:
% 
% % The statement of $\mf{ccut}$-interpolation does not align with the general structure of interpolation in non-commutative substructural logic, because the general form of the statement is unprovable in \SkNMILL.
% % To illustrate this, consider the following statement:
% \begin{itemize}
%   \item[\ ] Given $f: S \mid \Gamma \vd C$ and any partition $\langle \GG_0,\GG_1, \GG_2 \rangle$ of $\GG$, there exists a formula $D$ such that 
%   \begin{itemize}
%     \item[--] $g : {-} \mid \GG_1 \vd D$,
%     \item[--] $h : S \mid \GG_0, D, \GG_2 \vd C$, and
%     \item[--] $\gs{D} \leq \gs{\GG_1}$ and $\gs{D} \leq \gs{S , \GG_0 , \GG_2 , C}$ for every $X$.    
%   \end{itemize}
% \end{itemize}

However, this property is not provable in \SkNMILL. The problem lays in the validity of the second statement \cMIP. An attempt to prove this would proceed by induction on the height of the derivation $f : S \mid \Gamma \vdash C$ and then inspecting what is the last rule applied in $f$. The rules $\tr$ and $\lleft$ split the context, so one should be careful to consider all possible ways in which these splittings relate to the given partition $\langle \GG_0,\GG_1, \GG_2 \rangle$ of $\GG$.

The critical case is $f = \tr (f',f'')$ with the partition $\langle \GG_0, (\GG'_1, \GG''_1), \GG_2\rangle$ and two derivations $f' : S \mid \GG_0 , \GG'_1 \vd A$ and $f'' : {-} \mid \GG''_1 , \GG_2 \vd B$. So this is the case when the $\tr$ rule splits $\GG_1$ in two parts $\GG'_1,\GG''_1$.
By induction on $f'$ and the partition $\langle \GG_0 , \GG'_1, [\ ] \rangle$, we would be given a formula $D$ and derivations $g' : {-} \mid \GG'_1 \vd D$, and $h': S \mid \GG_0 , D \vd A$. By applying the indutice hypothsis on $f''$ and the partition $\langle [\ ], \GG''_1, \GG_2\rangle$, we would be given a formula $E$ and derivations $g'' : {-} \mid \GG''_1 \vd E$ and $h'': {-} \mid E, \GG_2 \vd B$.
We obtain $\tr (g',g'') : {-} \mid \GG'_1, \GG''_1 \vd D \ot E$, but we are unable to construct the other desired proof of sequent $S \mid \GG_0, D \ot E, \GG_1 \vd A \ot B$. We get very close via $\tr (h', h'') : S \mid \GG_0, D, E, \GG_1 \vd A \ot B$, but we are unable to merge $D$ and $E$ into $D \ot E$, since in our calculus the $\tl$ cannot be applied on formulae in context.

For a simple concrete counterexample, consider the derivation
\begin{equation*}
  \infer[\tr]{X \mid Y, Z \vd (X\ot Y)\ot Z}{
    \infer[\tr]{X \mid Y \vd X \ot Y}{
      \infer[\ax]{X \mid \quad \vd X}{}
      &
      \infer[\pass]{{-} \mid Y \vd Y}{
        \infer[\ax]{Y \mid \quad \vd Y}{}
        }
    }
    &
    \infer[\pass]{{-} \mid Z \vd Z}{
      \infer[\ax]{Z \mid \quad \vd Z}{}
    }
  }
\end{equation*}
and the partition $\langle [\ ], (Y,Z), [\ ]\rangle$. Suppose by contradiction that Maehara interpolation holds, so we would have a formula $D$ and two derivations $g: {-} \mid Y, Z \vd D$ and $h : X \mid D \vd (X\ot Y)\ot Z$.
The variable condition of Maehara interpolation and the existence of the derivation $g$ ensure that $D$ does not contain atomic formulae other than $Y$ and $Z$, and the latter must have a unique occurrence in $D$. Nevertheless, the existence of derivation $h$ is absurd. Since $X$ is atomic, $h$ can only be of the form: $(i)$ $f = \tr(f_1,f_2)$ for some derivations $f_1 : X \mid D \vd X \ot Y$ and $f_2 : {-} \mid \quad \vd Z$, or $(ii)$ $f = \tr(f'_1,f'_2)$ for some derivations $f'_1 : X \mid \quad \vd X \ot Y$ and $f'_2 : {-} \mid D \vd Z$. Case $(i)$ is impossible since there is no such $f_2$, while case $(ii)$ is impossible since there is no such $f'_1$.
% , and no other  are atomic, the only possibility is that $D = Y \ot Z$, however, the sequent $X \mid Y \ot Z \vd (X \ot Y) \ot Z$ does not have a proof in \SkNMILL.
% \begin{equation*}\label{example:ccut:failure}
%   \begin{array}{c}
%     \infer[\tr]{X \mid Y \ot Z \vd (X \ot Y) \ot Z}{
%     \deduce{X \mid Y\ot Z \vd X \ot Y}{??}
%     &
%     \deduce{{-} \mid \quad \vd Z}{??}
%   }
%   \\[15pt]
%   \infer[\tr]{X \mid Y \ot Z \vd (X \ot Y) \ot Z}{
%     \infer[\tr]{X \mid \quad \vd X \ot Y}{
%       \infer[\ax]{X \mid \quad \vd X}{}
%       &
%       \deduce{{-} \mid \quad \vd Y}{??}
%     }
%     &
%     \infer[\pass]{{-} \mid Y \ot Z \vd Z}{
%       \infer[\tl]{Y \ot Z \mid \quad \vd Z}{
%         \deduce{Y \mid Z \vd Z}{??}
%       }
%     }
%   }
%   \end{array}
% \end{equation*}
% In general, the rule
% \begin{displaymath}
% \begin{array}{c}
%   \infer[\ot\mf{C}]{S \mid \GG , A \ot B , \GD \vd C}{
%     \deduce{S \mid \GG, A , B , \GD \vd C}{}
%   }
% \end{array}
% \end{displaymath}
% is not admissible in \SkNMILL.
%\\

This situation is reminiscent of proving interpolation in the product-free Lambek calculus \cite{Pentus1997} and in the implicational fragment of intuitionistic logic \cite{Kanazawa2006}.
In both these cases, Maehara interpolation fails because none of the additive ($\land$) and multiplicative ($\ot$) conjunction is present.
A concrete counterexample in the product-free Lambek calculus (adapted from Kanazawa \cite{Kanazawa2006}) is given by the derivable sequent $W, W\bsls Y, W , W \bsls X , X \bsls (Y \bsls Z) \vd Z$ with the partition $\langle [\ ] , [W, W\bsls Y, W , W \bsls X], [X \bsls (Y \bsls Z)] \rangle$. This can be shown to not satisfy Maehara interpolation property. In the presence of $\ot$,  Maehara's method would produce the interpolant formula $X \ot Y$. The situation of \SkNMILL~ is somewhere inbetween: we have a multiplicative conjunction $\ot$ but we cannot do much with it if a formula $A \ot B$ is in context instead of the stoup position, since the rule $\tl$ cannot be applied arbitrarily in the antecedent.
The counterexample to \MIP~in product-free sequent calculus can, when appropriately modified, also works as a counterexample to \cMIP~in \SkNMILL: consider the derivable sequent  $X \lolli (Y \lolli Z) \mid W \lolli X, W , W \lolli Y, W \vd Z$ with the partition $\langle [\ ] , [W \lolli X, W , W \lolli Y, W], [\ ] \rangle$.
%This is an instance of a sequent calculus failing to have the formula-version of Maehara interpolation for a different reason.

\section{Craig Interpolation for \SkNMILL}\label{sec:interpolation}

In this section, we show that \SkNMILL~enjoys Craig interpolation, even though it does not generally enjoy Maehara interpolation.
This is again in analogy with the product-free Lambek calculus. 
As mentioned in the introductive section, Pentus \cite{Pentus1997} proved that the latter satisfies a relaxation of Maheara interpolation, that we dubbed Maehara multi-interpolation (\MMIP), which is sufficient to show Craig interpolation. 

Here is a brief sketch of the proof. 
Suppose the formula $A \bsls B$ is provable in product-free Lambek calculus.
This implies that there exists a derivation $f : A \vd B$.
Apply the Maehara multi-interpolation procedure to $f$ and the partition $\langle [\ ],[A],[\ ]\rangle$.
This produces a partition $\langle \Delta_1,\dots,\Delta_n \rangle$ of $[A]$.
Since $[A]$ is a singleton list, all $\Delta_i$ must be empty apart from one which is equal to $[A]$.
Maheara multi-interpolation also produces formulae $D_1,\dots,D_n$ satisfying the variable condition $\sigma_X(D_i) \leq \sigma_X(\Delta_i)$ for all $i$ and atomic formulae $X$. 
The latter cannot be true if $\Delta_i$ is empty, since this logic has no units.
This implies $n = 1$.
Therefore, Maheara multi-interpolation in this case produces only two derivations $h : A \vd D_1$ and $g : D_1 \vd B$, i.e. $D_1$ is the Craig interpolant of $A$ and $B$.
A similar proof also works for the product-free Lambek calculus enhanced with a multiplicative unit.

We showed in the previous section that \SkNMILL~does not satisfy the context Maehara interpolation property (\cMIP). 
We prove now that instead it satisfies a \emph{context Maehara multi-interpolation property} (\cMMIP).
And the stoup Maheara interpolation property (\sMIP) also holds.
\genIntrp
% \begin{theorem}\label{genIntrp}
% ~
% \\
% ($\mf{scut}$-interpolation) Given $f: S \mid \Gamma \vd C$ and any partition $\langle \GG_0,\GG_1 \rangle$ of $\GG$, there exists a formula $D$ 
% such that
% \begin{itemize}
%   \item[--] $g : S \mid \GG_0 \vd D$,
%   \item[--] $h : D \mid \GG_1 \vd C$, and 
%   \item[--] $\gs{D} \leq \gs{S , \GG_0}$ and $\gs{D} \leq \gs{\GG_1 , C}$ for every $X$.
% \end{itemize}
% %   , where $s(S) = I$ if $S = {-}$ or $s(S) = B$ if $S = B$.
%   ($\mf{ccut}$-interpolation) Given $f: S \mid \Gamma \vd C$ and any partition $\langle \GG_0,\GG_1, \GG_2 \rangle$ of $\GG$, there exist a partition of $\langle \GD_1, \dots, \GD_n \rangle$ of $\GG_1$ and a list of interpolant formulae $D_1, \dots, D_n$ such that
%   \begin{itemize}
%     \item[--] $g: S \mid \GG_0, D_1, \dots, D_n, \GG_2 \vd C$,
%     \item[--] $h_i : {-} \mid \GD_i \vd D_i$ for $i \in [1\dots n]$,
%     \item[--] $\gs{D_i} \leq \gs{\GD_i}$ for $i \in [1 \dots n]$ and $\gs{D_1, \dots, D_n} \leq \gs{S, \GG_0, \GG_2, C}$ for every $X$.
%   \end{itemize}
% \end{theorem}
These two statements of the Theorem are proved mutually by structural induction on derivations.
We separate the proofs for readability.
\begin{proof}[Proof of \sMIP]
We proceed by induction on the structure of $f$. 
\\
\underline{Case $f = \ax$.} Suppose $f = \ax : A \mid \quad \vd A$, which forces $\GG_0 = \GG_1 = [\ ]$.
In this case, the interpolant formula is $A$ and $g = h = \ax : A \mid \quad \vd A$, where the multiplicity condition is automatically satisfied.
\\
\underline{Case $f = \unitr$.} Since $f : \mid \quad \vd \unit$, this forces again $\GG_0$ and $\GG_1$ to be empty lists.
In this case, the interpolant formula is $\unit$ and $g =  \unitr : {-} \mid \quad \vd \unit$ and $h = \unitl (\unitr) : \unit \mid \quad \vd \unit$, where the multiplicity condition is vacuously satisfied.
\\
\underline{Case $f = \unitl \ f'$.}
Given a derivation $f' : {-} \mid \GG \vd C$, by induction on $f'$ with the same partition $\langle \GG_0, \GG_1 \rangle$ of $\GG$ we obtain  
\begin{itemize}
  \item[--] a formula $D$,
  \item[--] a derivation $g' : {-} \mid \GG_0 \vd D$,
  \item[--] a derivation $h' : D \mid \GG_1 \vd C$, such that
  \item[--] $\gs{D} \leq \gs{\GG_0}$ and $\gs{D} \leq \gs{\GG_1 , C}$ for every atomic formula $X$.
\end{itemize}
In this case, the interpolant formula for $f$ is $D$ and the two desired derivations are $g = \unitl \ g'$ and $h = h'$.
The multiplicity condition is automatically satisfied.
\\
\underline{Cases $f = \tl \ f'$ and $f = \lright \ f'$.} Analogous to the previous case.
\\
\underline{Case $f = \pass \ f'$}. Let $f' : A \mid \Gamma' \vd C$ and $\Gamma = A,\Gamma'$.
There are two subcases determined by the partition $\GG_0,\GG_1$ of $\GG$. 
Specifically, either $\GG_0$ is an empty list or not.
\begin{itemize}
  \item[$\bullet$] If $\GG_0 = [\ ]$, then the interpolant is $\unit$ and two desired derivations are $\unitr$ and $\unitl (\pass \ f')$.
The multiplicity condition is satisfied because $\gs{\unit} = 0$ for every $X$.
  \item[$\bullet$] If $\GG_0 = A, \GG'_0$, then by induction on $f'$ with the partition $\langle \GG'_0, \GG_1 \rangle$ we obtain
\begin{itemize}
\item[--] a formula $D$,
\item[--] a derivation $g' : A \mid \GG'_0 \vd D$,
\item[--] a derivation $h' : D \mid \GG_1 \vd C$, such that
\item[--] $\gs{D} \leq \gs{A, \GG'_0} $ and $ \gs{D} \leq \gs{\GG_1, C}$ for every atomic fomula $X$.
\end{itemize}
In this case, the interpolant formula for $f$ is $D$, and two desired derivations are $g = \pass \ g'$ and $h = h'$.
The multiplicity condition follows directly from the inductive hypothesis.
\end{itemize} 
\underline{Case $f = \tr (f',f'')$.} Let $f' : S \mid \Gamma' \vd A$ and $f'' : {-} \mid \Delta' \vd B$, so that $\GG = \GG' ,\Delta'$. We need to check how the latter splitting of $\GG$ compares to the given partition $\langle \GG_0,\GG_1 \rangle$. 
There are two possibilities:
\begin{itemize}
\item[$\bullet$] $\GG_0$ is fully contained in $\Gamma'$. 
This means that $\GG' = \GG_0 , \GG''$ and $\GG_1 = \GG'',\Delta'$.
Then $f' : S \mid \GG_0 , \GG'' \vd A$ and $f'' : {-} \mid \Delta' \vd B$.
In this case, by induction on $f'$ with the partition $\langle \GG_0 , \GG'' \rangle$ we obtain
\begin{itemize}
\item[--] a formula $D$,
\item[--] a derivation $g' : S \mid \GG_0 \vd D$, 
\item[--] a derivation $h' : D \mid \GG'' \vd A$ such that 
\item[--] $\gs{D} \leq \gs{S, \GG_0} $ and $ \gs{D} \leq \gs{\GG'' , A}$ for every $X$.
\end{itemize}
The desired interpolant formula is $D$ and the desired derivations are $g = g'$ and $h = \tr (h' , f'') : D \mid \GG'' , \Delta' \vd A \ot B$.
The multiplicity condition is satisfied because $\gs{D} \leq \gs{\GG'' , A} \leq \gs{\GG'' , \Delta' , A \ot B}$ for every $X$.
\item[$\bullet$]  $\Gamma_0$ splits between $\Gamma'$ and $\Delta'$. 
This means that $\Gamma_0 = \Gamma',\GG''$ and $\Delta' = \GG'',\Gamma_1$, and $\GG''$ is non-empty.
Then $f' : S \mid \GG' \vd A$ and $f'': {-} \mid \GG'', \GG_1 \vd B$.
In this case, by induction on $f'$ with the partition $\langle \GG' , [\ ] \rangle $ and on $f''$ with the partition $\langle \GG'' , \GG_1 \rangle$, respectively, we obtain
\begin{itemize}
  \item[--] formulae $E$ and $F$,
\item[--] derivations $g' : S \mid \GG' \vd E$ and $g'' : {-} \mid \GG'' \vd F$,
\item[--] derivations $h' : E \mid \quad \vd A$ and $h'' : F \mid \GG_1 \vd B$, such that
\item[--] $\gs{E} \leq \gs{S, \GG'} $ and $ \gs{E} \leq \gs{A}$ for every $X$, and
  \item[--] $\gs{F} \leq \gs{\GG''} $ and $\gs{F} \leq \gs{\GG_1, B}$ for every $X$.
\end{itemize}
The desired interpolant formula is $D = E \ot F$ and the desired derivations are
\begin{displaymath}
  \begin{array}{c}
  \begin{array}{c}
    g
=
    \proofbox{\infer[\tr]{S \mid \GG' , \GG'' \vd E \ot F}{
      \deduce{S \mid \GG' \vd E}{g'}
      &
      \deduce{{-} \mid \GG'' \vd F}{g''}
    }}
  \end{array}
    \qquad
    \begin{array}{c}
      h
=
      \proofbox{\infer[\tl]{E \ot F \mid \GG_1 \vd A \ot B}{
      \infer[\tr]{E \mid F , \GG_1 \vd A \ot B}{
        \deduce{E \mid \quad \vd A}{h'}
        &
        \infer[\pass]{{-} \mid F , \GG_1 \vd B}{
          \deduce{F \mid \GG_1 \vd B}{h''}
        }
      }
    }}
    \end{array}
  \end{array}
\end{displaymath}
The multiplicity condition is satisfied because $\gs{E \ot F} = \gs{E} + \gs{F} \leq \gs{S , \GG'} + \gs{\GG''} = \gs{S, \GG' , \GG''}$ and $\gs{E \ot F} = \gs{E} + \gs{F} \leq \gs{A} + \gs{\GG_1 , B} = \gs{A, \GG_1 , B} = \gs{\GG_1, A \ot B}$ for every $X$.
\end{itemize}
\underline{Case $f = \lleft(f',f'')$.}
Let $f' : {-} \mid \Gamma' \vd A$ and $f'' : B \mid \Delta' \vd C$, so that $\GG = \GG',\Delta'$. 
Again we check how the latter splitting of $\GG$ compares to the given partition $\langle \GG_0,\GG_1 \rangle$. 
There are two possibilities:
\begin{itemize}
\item[$\bullet$]  $\Gamma_1$ is fully contained in $\Delta'$. 
This means that $\Gamma_0 = \Gamma',\GG''$ and $\Delta' = \GG'',\Gamma_1$.
Then $f' : {-} \mid \GG' \vd A$ and $f'' : B \mid \GG'' , \GG_1 \vd C$.
In this case, by induction on $f''$ with the partition $\langle \GG'' , \GG_1 \rangle$ we obtain
\begin{itemize}
\item[--]  a formula $D$,
\item[--] a derivation $g'' : B \mid \GG'' \vd D$,
\item[--] a derivation $h'' : D \mid \GG_1 \vd C$ such that 
\item[--] $\gs{D} \leq \gs{B , \GG''}$ and $ \gs{D} \leq \gs{\GG_1 , C}$ for every atomic formula $X$.
\end{itemize}
The desired interpolant formula is $D$ and the desired derivations are $g = \lleft (f' , g'') : A \lolli B \mid \GG' , \GG'' \vd D$ and $h = h''$.
The multiplicity condition is satisfied because $\gs{D} \leq \gs{B , \GG''} \leq \gs{A \lolli B , \GG' , \GG''}$ for every $X$.

\item[$\bullet$] $\Gamma_1$ splits between $\Gamma'$ and $\Delta'$. 
This means that $\Gamma' = \GG_0,\GG''$ and $\GG_1 = \GG'',\Delta'$, and $\GG''$ is non-empty.
Then $f' : {-} \mid \GG_0,\GG'' \vd A$ and $f'': B \mid \Delta' \vd C$.
Our goal is to find a formula $D$ and derivations $g : A\lolli B \mid \GG_0 \vd D$ and $h: D \mid \GG'', \Delta' \vd C$.
By induction on $f''$ with the partition $\langle [\ ] , \Delta' \rangle$ we obtain
\begin{itemize}
\item[--] a formula $E$,
\item[--] a derivation $g'' : B \mid \quad \vd E$,
\item[--] a derivation $h'': E \mid \Delta' \vd C$ such that
\item[--] $\gs{E} \leq\gs{B}$ and $ \gs{E} \leq \gs{\GG_2 , C}$ for all atomic formulae $X$.
\end{itemize}
We also apply the \cMMIP~procedure (which, remember, is proved mutually with \sMIP) on the derivation $f'$ with the partition $\langle \GG_0 , \GG'' , [\ ]\rangle$ and obtain
\begin{itemize}
\item[--]  a partition $\langle \GD_1, \dots , \GD_n \rangle$ of $\GG''$,
\item[--] a list of formulae $D_1 , \dots , D_n$,
  \item[--] a derivation $g': {-} \mid \GG_0 , D_1, \dots, D_n \vd A$,
  \item[--] a list of derivations $h'_i : {-} \mid \GD_i \vd D_i$, for $i \in [1\dots n]$, such that
  \item[--] $\gs{D_i} \leq \gs{\GD_i}$ for all $i \in [1, \dots, n]$ and atomic formulae $X$,
\item[--] $\gs{D_1 , \dots , D_n} \leq \gs{\GG_0 , A}$ for all atomic formulae $X$.
\end{itemize}
The desired interpolant formula is $D = D_1 \lolli (D_2 \lolli (\dots (D_n \lolli E)\dots))$.
The desired derivations $g$ and $h$ are constructed as follows:
\begin{displaymath}
\begin{array}{rcl}
  g 
  &=&
  \proofbox{
      \infer[\lright^*]{A\lolli B \mid \GG_0 \vd D_1 \lolli (\dots (D_n \lolli E)\dots)}{
        \infer[\lleft]{A \lolli B \mid \GG_0 , D_1, \dots, D_n \vd E}{
          \deduce{{-} \mid \GG_0 , D_1, \dots, D_n \vd A}{g'}
          &
          \deduce{B \mid \quad \vd E}{g''}
      }
    }
%      \infer[\lright]{A\lolli B \mid \GG_0 \vd D_1 \lolli (\dots (D_n \lolli E)\dots)}{
%      \deduce{A \lolli B \mid \GG_0 , D_1 \vd D_2 \lolli (\dots (D_n \lolli E)\dots)}{\deduce{\vdots}{
%        \infer[\lright]{A \lolli B \mid \GG_0 , D_1, \dots ,D_{n-1} \vd D_n \lolli E}{
%        \infer[\lleft]{A \lolli B \mid \GG_0 , D_1, \dots, D_n \vd E}{
%          \deduce{{-} \mid \GG_0 , D_1, \dots, D_n \vd A}{g'}
%          &
%          \deduce{B \mid \quad \vd E}{g''}
%        }
%      }
%      }
%      }
%    }
}
    \\[1.5cm]
  h
    &=&
    \proofbox{
      \infer[\lleft^*]{D_1 \lolli (\dots (D_n \lolli E)\dots) \mid \GD_1, \dots, \GD_n, \GD' \vd C}{
      \deduce{[{-} \mid \GD_i \vd D_i]_{i \in [1, \dots,n]}}{[h'_i]}
      &
%      \deduce{D_2 \lolli (\dots (D_n \lolli E)\dots) \mid \GD_2, \dots, \GD_n, \GD' \vd C}{
%        \deduce{\vdots}{
%          \infer[\lleft]{D_n \lolli E \mid \GD_n, \GD' \vd C}{
%            \deduce{{-} \mid \GD_n, \GD' \vd D_n}{h'_n}
%            &
            \deduce{E \mid \GD' \vd C}{h''}
%          }
%        }
%      }
    }
    }
  \end{array}
\end{displaymath}
Notice that $\GG'' = \GD_1, \dots, \GD_n$, so the multiplicity condition is easy to check.
\end{itemize}
\end{proof}

\begin{proof}[Proof of \cMMIP]
The first base case is $f  = \ax : A \mid \quad \vd A$, which means that $\GG_0 = \GG_1 = \GG_2 = [\ ]$.
In this case, the partition of $\GG_1$ is $\langle [\ ] \rangle$ and the list of formulae and list of derivations are empty lists.
Another base case $f = \unitr$ is similar.

For inductive cases, we first deal with one-premise rules. 
The first group of rules are $\unitl$, $\tl$, and $\lright$. 
We show the case of $f = \unitl \ f'$, while the other two are similar.
Given a derivation $\unitl \ f' : \unit \mid \GG \vd C$ and a partition $\langle \GG_0 , \GG_1 , \GG_2\rangle$ of $\GG$.
By induction, we have 
\begin{itemize}
  \item[--] a partition $\langle \GD_0, \dots , \GD_0 \rangle$ of $\GG_1$, 
  \item[--] a list of interpolant formulae $D_1, \dots , D_n$ and
  \item[--] derivations $g' : {-} \mid \GG_0 , D_1 , \dots , D_n , \GG_2 \vd C$ and $h'_i : {-} \mid \GD_i \vd D_i$, for $i \in [1 \dots n]$
  \item[--]  $\gs{D_i} \leq \gs{\GD_i}$ for $i \in [1 \dots n]$ and $\gs{D_1, \dots, D_n} \leq \gs{S, \GG_0, \GG_2, C}$ for every $X$.
\end{itemize}
In this case, the partition, the list of interpolant formulae are the same as the inductive hypothesis.
The desired derivations are $g = \unitl \ g'$ and $h_i = h'_i$ for $i \in [1 \dots n]$.
The multiplicity condition is automatically satisfied.

The critical case among one-premise rules is $f = \pass \ f'$, with the partition $\langle [\ ], (A, \GG_1) , \GG_2 \rangle$ and derivation $f' : A \mid \GG_1 , \GG_2 \vd C$.
In this case, we apply the inductive hypothesis of $\mf{scut}$-interpolation on $f'$ and obtain a formula $D$ such that 
\begin{itemize}
  \item[--] $g': A \mid \GG_1 \vd D$,
  \item[--] $h' : D \mid \GG_2 \vd C$, and
  \item[--] $\gs{D} \leq \gs{A , \GG_1}$ and $\gs{D} \leq \gs{\GG_2 , C}$ for every $X$.
\end{itemize}
The desired derivations are $\pass \ g' : {-} \mid A , \GG_1 \vd D$ and $\pass \ h' : {-} \mid D, \GG_2 \vd C$, i.e. the partition of $A, \GG_1$ is itself and the list of formulae is the singleton list $[D]$.
The multiplicity condition is satisfied by hypothesis.

Next we deal with two-premises rules.
We show the case $f = \tr (f' , f'')$, while the case of $\lleft$ is similar.
Given a derivation $\tr (f' , f'')$, where $f' : S \mid \GL \vd A$ and $f'' : {-} \mid \GO \vd B$ and the partition $\langle \GG_0 , \GG_1, \GG_2 \rangle$ of $(\GL, \GO)$, there are three cases:
\begin{enumerate}
  \item If $\GG_0 = (\GG'_0 , \GG''_0)$ where $\GL = \GG'_0$ and $\GO = (\GG''_0 , \GG_1 , \GG_2)$, then we apply induction on $f''$ to obtain a partition $\langle \GD_0, \dots , \GD_0 \rangle$ of $\GG_1$ and a list of interpolant formulae $D_1, \dots , D_n$ such that
  \begin{itemize}
    \item[--] $g'' : {-} \mid \GG''_0 , D_1 , \dots , D_n , \GG_2 \vd B$,
    \item[--] $h''_i : {-} \mid \GD_i \vd D_i$, for $i \in [1 \dots n]$, and 
    \item[--] $\gs{D_i} \leq \gs{\GD_i}$ for $i \in [1 \dots n]$ and $\gs{D_1, \dots , D_n} \leq \gs{ \GG''_0 , \GG_2 , B}$ for every $X$.
  \end{itemize}
  The desired derivations are $g = \tr (f' , g'')$ and $h_i = h''_i$ for $i \in [1 \dots n]$.
  The multiplicity condition is satisfied because $\gs{D_1 , \dots , D_n} \leq \gs{ \GG''_0 , \GG_2 , B} \leq \gs{S, \GG'_0, \GG''_0 , \GG_2 , A \ot B}$.
  \item If $\GG_1 = (\GG'_1 , \GG''_1)$ where $\GL = (\GG_0 , \GG'_1)$ and $\GO = (\GG''_1 , \GG_2)$, then we apply induction on $f'$ and $f''$ respectively to obtain
  \begin{itemize}
    \item[--] a partition $\langle \GD'_0, \dots , \GD'_0 \rangle$ of $\GG'_1$ and a list of interpolant formulae $D'_1, \dots , D'_n$ such that
    \item[--] $g' : S \mid \GG_0 , D'_1 , \dots , D'_n \vd A$,
    \item[--] $h'_i : {-} \mid \GD'_i \vd D'_i$, for $i \in [1 \dots n]$, and 
    \item[--] $\gs{D'_i} \leq \gs{\GD'_i}$ for $i \in [1 \dots n]$ and $\gs{D'_1 , \dots , D'_n} \leq \gs{ S, \GG_0 , A}$ for every $X$ and
  \end{itemize}
  \begin{itemize}
    \item[--] a partition $\langle \GD''_0, \dots , \GD''_0 \rangle$ of $\GG''_1$ and a list of interpolant formulae $D''_1, \dots , D''_m$ such that
    \item[--] $g'' : {-} \mid D''_{n+1} , \dots , D''_{n+m} , \GG_2 \vd B$, 
    \item[--] $h''_i : {-} \mid \GD''_i \vd D''_i$, for $i \in [n+1 \dots n+m]$, and
    \item[--] $\gs{D''_{i}} \leq \gs{\GD''_{i}}$ for $i \in [n+1 \dots n+m]$ and $\gs{D''_{n+1} , \dots , D''_{n+m}} \leq \gs{\GG_2 , B}$ for every $X$.
  \end{itemize}
  The desired derivations are 
  \begin{itemize}
    \item[--] $g = \tr(g' , g'') : S \mid \GG_0 , D'_1 , \dots , D'_n , D''_{n+1} , \dots , D''_{n+m} , \GG_2 \vd A \ot B$ and 
    \item[--] for $i \in [1 \dots n+m]$, if $i \leq n$, then $h_i = h'_i$. Otherwise, let $h_i = h''_i$.
  \end{itemize}
  We abbreviate $D'_1 , \dots , D'_n$ as $[D']$, $\GD'_1, \dots , \GD'_n$ as $[\GD']$, $D''_{n+1} , \dots , D''_{n+m}$ as $[D'']$, and $\GD''_{n+1}, \dots , \GD''_{n+m}$ as $[\GD'']$. 
  For the multiplicity condition, we argue that for every $X$
  \begin{itemize}
    \item[--] by inductive hypothesis, we know that $\gs{[D']} \leq \gs{[\GD']}$ and $\gs{[D'']} \leq \gs{[\GD'']}$;
    \item[--] by the definition of $\sigma_{X}$, we have $\gs{[D'], [D'']} \leq \gs{[\GD'] , [\GD'']}$;
    \item[--] by inductive hypothesis, we know that $\gs{[D']} \leq \gs{ S, \GG_0 , A}$ and $\gs{[D'']} \leq \gs{\GG_2 , B}$;
    \item[--] by the definition of $\sigma_{X}$, we have $\gs{[D'], [D'']} \leq \gs{ S, \GG_0 , A , \GG_2 , B} = \gs{S , \GG_0 , \GG_2 , A \ot B}$
  \end{itemize}
  Therefore, $\gs{[D'], [D'']} \leq \gs{[\GD'] , [\GD'']} $ and $ \gs{[D'] , [D'']} \leq \gs{S , \GG_0 , \GG_2 , A \ot B}$, as desired.
  % By inductive hypothesis, we know that $\gs{[D']} \subseteq \gs{[\GD']}$ and $\gs{[D'']} \subseteq \gs{[\GD'']}$.
  % By the definition of $\mf{var}$, we have $\gs{[D'], [D'']} \subseteq \gs{[\GD'] , [\GD'']}$.
  % By inductive hypothesis, we know that $\gs{[D']} \subseteq \gs{ S, \GG_0 , A}$ and $\gs{[D'']} \subseteq \gs{\GG_2 , B}$.
  % By the definition of $\mf{var}$, we have $\gs{[D'], [D'']} \subseteq \gs{ S, \GG_0 , A , \GG_2 , B} = \gs{S , \GG_0 , \GG_2 , A \ot B}$.
  % Therefore, $\gs{[D'], [D'']} \subseteq \gs{[\GD'] , [\GD'']} \cap \gs{S , \GG_0 , \GG_2 , A \ot B}$, as desired.
  \item The case $\GG_2 = (\GG'_2 , \GG''_2)$ where $\GL = \GG_0 , \GG_1, \GG'_2$ and $\GO = \GG''_2$ is similar to the first case.
\end{enumerate}
\end{proof}
% \begin{lemma}\label{lem:ccut:intrp}
% ~
%   ($\mf{ccut}$-interpolation) Given $f: S \mid \Gamma \vd C$ and any partition $\langle \GG_0,\GG_1, \GG_2 \rangle$ of $\GG$, there exist a partition of $\langle \GD_1, \dots, \GD_n \rangle$ of $\GG_1$, a list of interpolant formulae $D_1, \dots, D_n$ such that
%   \begin{itemize}
%     \item[--] $g: S \mid \GG_0, D_1, \dots, D_n, \GG_2 \vd C$,
%     \item[--] $h_i : {-} \mid \GD_i \vd D_i$ for $i \in [1\dots n]$,
%     \item[--] $\gs{D_i} \leq \gs{\GD_i}$ for $i \in [1 \dots n]$ and $\gs{D_1, \dots, D_n} \leq \gs{S, \GG_0, \GG_2, C}$ for every $X$.
%   \end{itemize}
% \end{lemma}
% \begin{proof}
% The first base case is $f  = \ax : A \mid \quad \vd A$, which means that $\GG_0 = \GG_1 = \GG_2 = [\ ]$.
% In this case, the partition of $\GG_1$ is $\langle [\ ] \rangle$ and the list of formulae and list of derivations are empty lists.
% Another base case $f = \unitr$ is similar.

% For inductive cases, we first deal with one-premise rules. 
% The first group of rules are $\unitl$, $\tl$, and $\lright$. 
% We show the case of $f = \unitl \ f'$, while the other two are similar.
% Given a derivation $\unitl \ f' : \unit \mid \GG \vd C$ and a partition $\langle \GG_0 , \GG_1 , \GG_2\rangle$ of $\GG$.
% By induction, we have 
% \begin{itemize}
%   \item[--] a partition $\langle \GD_0, \dots , \GD_0 \rangle$ of $\GG_1$, 
%   \item[--] a list of interpolant formulae $D_1, \dots , D_n$ and
%   \item[--] derivations $g' : {-} \mid \GG_0 , D_1 , \dots , D_n , \GG_2 \vd C$ and $h'_i : {-} \mid \GD_i \vd D_i$, for $i \in [1 \dots n]$
%   \item[--]  $\gs{D_i} \leq \gs{\GD_i}$ for $i \in [1 \dots n]$ and $\gs{D_1, \dots, D_n} \leq \gs{S, \GG_0, \GG_2, C}$ for every $X$.
% \end{itemize}
% In this case, the partition, the list of interpolant formulae are the same as the inductive hypothesis.
% The desired derivations are $g = \unitl \ g'$ and $h_i = h'_i$ for $i \in [1 \dots n]$.
% The multiplicity condition is automatically satisfied.

% The critical case among one-premise rules is $f = \pass \ f'$, with the partition $\langle [\ ], (A, \GG_1) , \GG_2 \rangle$ and derivation $f' : A \mid \GG_1 , \GG_2 \vd C$.
% In this case, we apply the inductive hypothesis of $\mf{scut}$-interpolation on $f'$ and obtain a formula $D$ such that 
% \begin{itemize}
%   \item[--] $g': A \mid \GG_1 \vd D$,
%   \item[--] $h' : D \mid \GG_2 \vd C$, and
%   \item[--] $\gs{D} \leq \gs{A , \GG_1}$ and $\gs{D} \leq \gs{\GG_2 , C}$ for every $X$.
% \end{itemize}
% The desired derivations are $\pass \ g' : {-} \mid A , \GG_1 \vd D$ and $\pass \ h' : {-} \mid D, \GG_2 \vd C$, i.e. the partition of $A, \GG_1$ is itself and the list of formulae is the singleton list $[D]$.
% The multiplicity condition is satisfied by hypothesis.

% Next we deal with two-premises rules.
% We show the case $f = \tr (f' , f'')$, while the case of $\lleft$ is similar.
% Given a derivation $\tr (f' , f'')$, where $f' : S \mid \GL \vd A$ and $f'' : {-} \mid \GO \vd B$ and the partition $\langle \GG_0 , \GG_1, \GG_2 \rangle$ of $(\GL, \GO)$, there are three cases:
% \begin{enumerate}
%   \item If $\GG_0 = (\GG'_0 , \GG''_0)$ where $\GL = \GG'_0$ and $\GO = (\GG''_0 , \GG_1 , \GG_2)$, then we apply induction on $f''$ to obtain a partition $\langle \GD_0, \dots , \GD_0 \rangle$ of $\GG_1$ and a list of interpolant formulae $D_1, \dots , D_n$ such that
%   \begin{itemize}
%     \item[--] $g'' : {-} \mid \GG''_0 , D_1 , \dots , D_n , \GG_2 \vd B$,
%     \item[--] $h''_i : {-} \mid \GD_i \vd D_i$, for $i \in [1 \dots n]$, and 
%     \item[--] $\gs{D_i} \leq \gs{\GD_i}$ for $i \in [1 \dots n]$ and $\gs{D_1, \dots , D_n} \leq \gs{ \GG''_0 , \GG_2 , B}$ for every $X$.
%   \end{itemize}
%   The desired derivations are $g = \tr (f' , g'')$ and $h_i = h''_i$ for $i \in [1 \dots n]$.
%   The multiplicity condition is satisfied because $\gs{D_1 , \dots , D_n} \leq \gs{ \GG''_0 , \GG_2 , B} \leq \gs{S, \GG'_0, \GG''_0 , \GG_2 , A \ot B}$.
%   \item If $\GG_1 = (\GG'_1 , \GG''_1)$ where $\GL = (\GG_0 , \GG'_1)$ and $\GO = (\GG''_1 , \GG_2)$, then we apply induction on $f'$ and $f''$ respectively to obtain
%   \begin{itemize}
%     \item[--] a partition $\langle \GD'_0, \dots , \GD'_0 \rangle$ of $\GG'_1$ and a list of interpolant formulae $D'_1, \dots , D'_n$ such that
%     \item[--] $g' : S \mid \GG_0 , D'_1 , \dots , D'_n \vd A$,
%     \item[--] $h'_i : {-} \mid \GD'_i \vd D'_i$, for $i \in [1 \dots n]$, and 
%     \item[--] $\gs{D'_i} \leq \gs{\GD'_i}$ for $i \in [1 \dots n]$ and $\gs{D'_1 , \dots , D'_n} \leq \gs{ S, \GG_0 , A}$ for every $X$ and
%   \end{itemize}
%   \begin{itemize}
%     \item[--] a partition $\langle \GD''_0, \dots , \GD''_0 \rangle$ of $\GG''_1$ and a list of interpolant formulae $D''_1, \dots , D''_m$ such that
%     \item[--] $g'' : {-} \mid D''_{n+1} , \dots , D''_{n+m} , \GG_2 \vd B$, 
%     \item[--] $h''_i : {-} \mid \GD''_i \vd D''_i$, for $i \in [n+1 \dots n+m]$, and
%     \item[--] $\gs{D''_{i}} \leq \gs{\GD''_{i}}$ for $i \in [n+1 \dots n+m]$ and $\gs{D''_{n+1} , \dots , D''_{n+m}} \leq \gs{\GG_2 , B}$ for every $X$.
%   \end{itemize}
%   The desired derivations are 
%   \begin{itemize}
%     \item[--] $g = \tr(g' , g'') : S \mid \GG_0 , D'_1 , \dots , D'_n , D''_{n+1} , \dots , D''_{n+m} , \GG_2 \vd A \ot B$ and 
%     \item[--] for $i \in [1 \dots n+m]$, if $i \leq n$, then $h_i = h'_i$. Otherwise, let $h_i = h''_i$.
%   \end{itemize}
%   We abbreviate $D'_1 , \dots , D'_n$ as $[D']$, $\GD'_1, \dots , \GD'_n$ as $[\GD']$, $D''_{n+1} , \dots , D''_{n+m}$ as $[D'']$, and $\GD''_{n+1}, \dots , \GD''_{n+m}$ as $[\GD'']$. 
%   For the multiplicity condition, we argue that for every $X$
%   \begin{itemize}
%     \item[--] by inductive hypothesis, we know that $\gs{[D']} \leq \gs{[\GD']}$ and $\gs{[D'']} \leq \gs{[\GD'']}$;
%     \item[--] by the definition of $\sigma_{X}$, we have $\gs{[D'], [D'']} \leq \gs{[\GD'] , [\GD'']}$;
%     \item[--] by inductive hypothesis, we know that $\gs{[D']} \leq \gs{ S, \GG_0 , A}$ and $\gs{[D'']} \leq \gs{\GG_2 , B}$;
%     \item[--] by the definition of $\sigma_{X}$, we have $\gs{[D'], [D'']} \leq \gs{ S, \GG_0 , A , \GG_2 , B} = \gs{S , \GG_0 , \GG_2 , A \ot B}$
%   \end{itemize}
%   Therefore, $\gs{[D'], [D'']} \leq \gs{[\GD'] , [\GD'']} $ and $ \gs{[D'] , [D'']} \leq \gs{S , \GG_0 , \GG_2 , A \ot B}$, as desired.
%   % By inductive hypothesis, we know that $\gs{[D']} \subseteq \gs{[\GD']}$ and $\gs{[D'']} \subseteq \gs{[\GD'']}$.
%   % By the definition of $\mf{var}$, we have $\gs{[D'], [D'']} \subseteq \gs{[\GD'] , [\GD'']}$.
%   % By inductive hypothesis, we know that $\gs{[D']} \subseteq \gs{ S, \GG_0 , A}$ and $\gs{[D'']} \subseteq \gs{\GG_2 , B}$.
%   % By the definition of $\mf{var}$, we have $\gs{[D'], [D'']} \subseteq \gs{ S, \GG_0 , A , \GG_2 , B} = \gs{S , \GG_0 , \GG_2 , A \ot B}$.
%   % Therefore, $\gs{[D'], [D'']} \subseteq \gs{[\GD'] , [\GD'']} \cap \gs{S , \GG_0 , \GG_2 , A \ot B}$, as desired.
%   \item The case $\GG_2 = (\GG'_2 , \GG''_2)$ where $\GL = \GG_0 , \GG_1, \GG'_2$ and $\GO = \GG''_2$ is similar to the first case.
% \end{enumerate}
% \end{proof}

\niccolo{Text on why the mutual induction terminates.}

\begin{example}
  We compute the $\mf{scut}$-interpolant formula of the end-sequent of the derivation 
  \begin{displaymath}
    \begin{array}{c}
      \infer[\lleft]{Y \lolli Z \mid X \lolli Y , X \vd Z}{
        \infer[\pass]{{-} \mid X \lolli Y ,X \vd Y}{
          \infer[\lleft]{X \lolli Y \mid X \vd Y}{
            \infer[\pass]{{-} \mid X \vd X}{
              \infer[\ax]{X \mid \quad \vd X}{}
            }
            &
            \infer[\ax]{Y \mid \quad \vd Y}{}
          }
        }
        &
        \infer[\ax]{Z \mid \quad \vd Z}{}
      }
    \end{array}
  \end{displaymath}
  with the partition $\langle [X \lolli Y] , [X]\rangle$.
  \\
  Following the procedure in the proof of Theorem \ref{genIntrp}, we apply $\mf{ccut}$-interpolation on $\pass (\lleft ((\pass \ \ax), \ax)) : {-} \mid X \lolli Y , X \vd Y$ with the partition $\langle [X \lolli Y] , [X] , [\ ] \rangle$ to obtain
  \begin{itemize}
    \item[--] a partition $\langle [X] \rangle$ of $[X]$,
    \item[--] a singleton list of formulae $[X]$, and
    \item[--] derivations $\pass (\lleft ((\pass \ \ax), \ax)) : {-} \mid X \lolli Y , X \vd Y$ and $ \pass \ \ax : {-} \mid X \vd X$ 
  \end{itemize}
  such that the multiplicity condition holds.
  Next, we apply $\mf{scut}$-interpolation on $Z \mid \quad \vd Z$ with the partition $\langle [\ ] , [\ ] \rangle$ to obtain two derivations $\ax : Z \mid \quad \vd Z$ and $\ax : Z \mid \quad \vd Z$.
  Then we construct the desired derivations as follows:
  \begin{displaymath}
    \begin{array}{lc}
      \begin{array}{c}
        g
      \end{array}
      \quad
      =&
      \quad
      \begin{array}{c}
        \infer[\lright]{Y \lolli Z \mid X \lolli Y \vd X \lolli Z}{
          \infer[\lleft]{Y \lolli Z \mid X \lolli Y , X \vd Z}{
            \infer[\pass]{{-} \mid X \lolli Y , X \vd Y}{
              \infer[\lleft]{X \lolli Y \mid X \vd Y}{
                \infer[\pass]{{-} \mid X \vd X}{
                  \infer[\ax]{X \mid \quad \vd X}{}
            }
            &
            \infer[\ax]{Y \mid \quad \vd Y}{}
          }
        }
            &
            \infer[\ax]{Z \mid \quad \vd Z}{}
          }
        }
      \end{array}
      \\[50pt]
      \begin{array}{c}
        h
      \end{array}
      \quad
      =&
      \quad
      \begin{array}{c}
        \infer[\lleft]{X \lolli Z \mid X \vd Z}{
          \infer[\pass]{{-} \mid X \vd X}{
            \infer[\ax]{X \mid \quad \vd X}{}
          }
          &
          \infer[\ax]{Z \mid \quad \vd Z}{}
        }
      \end{array}
    \end{array}
  \end{displaymath}
\end{example}
\begin{lemma}\label{lem:gs:vars:equiv}
  For any formula $A$ and an atomic formula $X$, $X \in \vars{A}$ if and only if $1 \leq \gs{A}$.
\end{lemma}
\begin{proof}
  This is true by definition.
\end{proof}
\begin{lemma}\label{lem:gs2vars}
  For any formulae $A$ and $B$, if $\gs{A} \leq \gs{B}$ for every $X$, then $\vars{A} \subseteq \vars{B}$.
\end{lemma}
\begin{proof}
  For any $X \in \vars{A}$, by the assumption $\gs{A} \leq \gs{B}$ and Lemma \ref{lem:gs:vars:equiv}, we know that $X \in \vars{B}$ as well.
  Therefore we can conclude that $\vars{A} \subseteq \vars{B}$.
\end{proof}
\begin{theorem}\label{thm:craig:intrp}
  For any formulae $A$ and $C$, if $A \lolli C$ is provable, then there exists a formula $B$ such that both $A \lolli B$ and $B \lolli C$ are provable, and $\vars{B} \subseteq \vars{A} \cap \vars{C}$.
\end{theorem}
\begin{proof}
$A \lolli C$ being provable means that there is a derivation $f : {-} \mid \quad \vd A \lolli C$. 
By invertibility of the rule $\lright$, we obtain a derivation $f' : {-} \mid A \vd C$.
Then by applying $\mf{scut}$-interpolation on $f'$ with the partition $\langle [A ], [\ ]\rangle$, we get a formula $B$ such that 
\begin{itemize}
  \item[--] $g': {-} \mid A \vd B$,
  \item[--] $h': B \mid \quad \vd C$, and 
  \item[--] $\gs{B} \leq \gs{A} $ and $ \gs{B} \leq \gs{C}$ for every $X$.
\end{itemize}
The formulae $A \lolli B$ and $B \lolli C$ are proved by the derivations $\lright \ g' : {-} \mid \quad \vd A \lolli B$ and $\lright (\pass \ h') : {-} \mid \quad \vd B \lolli C$, respectively.
By Lemma \ref{lem:gs2vars}, we know that $\vars{B} \subseteq \vars{A}$ and $\vars{B} \subseteq \vars{C}$, which means that $\vars{B} \subseteq \vars{A} \cap \vars{C}$.
\end{proof}

\section{Proof-Relevant Interpolation}\label{sec:proof-rel} 
In this section we show proof-relevant interpolation for \SkNMILL~that is reminiscent to {\v{C}}ubri{\'c} \cite{Cubric1994} and Saurin \cite{Saurin2024}, in the sense that that the $\mf{scut}\sls \mf{ccut}$-interpolation procedures of Theorem \ref{genIntrp} are right inverses of $\mf{scut}$ and $\mf{ccut}$.
  % \begin{equation*}
  %  \begin{array}{l}
  %     %scut⊸r⋆⊸ls
  %     \begin{array}{c}
  %       \infer[\mf{scut}]{S \mid \GG_0 , \GD , \GG_2 \vd C}{
  %     \infer[\lright]{S \mid \GG_0 \vd A^*}{
  %     \deduce{S \mid \GG_0 , A_1 \vd A'^*}{
  %       \deduce{\vdots}{
  %       \infer[\lright]{S \mid \GG_0 , A_1, \dots ,A_{n-1} \vd A_n \lolli B}{
  %       \deduce{S \mid \GG_0 , A_1, \dots, A_n \vd B}{f}
  %     }
  %     }
  %     }
  %   }
  %     &
  %     \infer[\lleft]{A^* \mid \GD, \GG_2 \vd C}{
  %     \deduce{{-} \mid \GD_1 \vd A_1}{g_1}
  %     &
  %     \deduce{A'^* \mid \GD_2, \dots, \GD_n, \GG_2 \vd C}{
  %       \deduce{\vdots}{
  %         \infer[\lleft]{A_n \lolli B \mid \GD_n, \GG_2 \vd C}{
  %           \deduce{{-} \mid \GD_n \vd A_n}{g_n}
  %           &
  %           \deduce{B \mid \GG_2 \vd C}{h}
  %         }
  %       }
  %     }
  %   }
  %   }
  %     \end{array}
  %     \end{array}
  %     \end{equation*}
  %     \begin{equation}\label{scut-or-ols}
  %     \begin{array}{l}
  %     \qquad  =
  %     \begin{array}{c}
  %       \infer[\mf{scut}]{S \mid \GG_0 , \GD , \GG_2 \vd C}{
  %         \infer[\mf{ccut}]{S \mid \GG_0 , \GD \vd B}{
  %           \deduce{{-} \mid \GD_1 \vd A_1}{g_1}
  %           &
  %           \deduce{S \mid \GG_0 , A_1 , \GD_2 , \dots , \GD_n \vd B}{
  %             \deduce{\vdots}{
  %             \infer[\mf{ccut}]{S \mid \GG_0 , A_1 , \dots , \GD_n \vd B}{
  %               \deduce{{-} \mid \GD_n \vd A_n}{g_n}
  %               &
  %               \deduce{S \mid \GG_0 , A_1 , \dots , A_n \vd B}{f}
  %             }
  %           }
  %         }
  %         }
  %         &
  %         \deduce{B \mid \GG_2 \vd C}{h}
  %       }
  %     \end{array}
  %     %scut⊸r⋆⊸ls : {S : Stp} {Γ Δ Δ' Λ : Cxt} {B C : Fma}
  % % → (hs : Ders Δ Λ)
  % % → (f : S ∣ Γ ++ Λ ⊢ B)
  % % → (g : just B ∣ Δ' ⊢ C)
  % % → scut (⊸r⋆ Λ f) (⊸ls hs g) ≡ scut (ccut⋆ Γ [] hs f) g
  %  \end{array}
  %  \end{equation}
% With the definition and the equations above, we can state and prove the following:
% In particular, we can prove the following two theorems.
\cutIntrp
\begin{proof}
Similar to the proof of Theorem \ref{genIntrp}, we prove the theorem by mutual induction on derivations.
We show the proof of the statement $(i)$, while $(ii)$ is proved in a similar manner.
This proof relies on definitional equality of derivations where $\mf{scut}$ and $\mf{ccut}$ are defined according to the cut-elimination procedures described in \cite{uustalu:sequent:2021,wan2024}.

The first bases case is $f = \ax : A \mid \quad \vd A$, where the interpolant formula is $A$ and $g = h = f = \ax$. 
By definition, $\mf{scut} (\ax , \ax)$ is equal to $\ax$ which is equivalent to itself.
Another base case is $f = \unitr$, where the interpolant formula is $\unit$ and $\mf{scut} (\unitr , \unitl (\unitr)) = \unitr$ which is equivalent to itself.

For inductive cases, we first deal with one-premise rules.
The first group of one-premise rules are $\unitl, \tl$, and $\lright$.
We show the case of $f = \unitl \ f'$, while the other two are similar.
In this case, the interpolant formula is $D$, and two desired derivations are $g = \unitl \ g'$ and $h = h'$.
The derivation $\mf{scut} (\unitl \ g', h')$ is definitionally equal to $\unitl (\mf{scut} (g' , h'))$, then by inductive hypothesis and congruence of $\circeq$, we have $\unitl (\mf{scut} (g' , h')) \circeq \unitl \ f'$.

The last case of one-premise rules is $ f = \pass \ f'$.
There are two subcases determined by the partition of $\GG$, specifically, $\GG_0$ is an empty list or not.
\begin{itemize}
  \item[--] If $\GG_0 = [\ ]$, then the interpolant is $\unit$ and two desired derivations are $\unitr$ and $\unitl (\pass \ f')$. In this case, $\scut{\unitr}{\unitl (\pass \ f')} = \pass \ f'$, which is equivalent to itself.
  \item[--] If $\GG_0 = A, \GG'_0$, then we apply induction on $f'$ with the partition $\langle \GG'_0, \GG_1 \rangle$ and then obtain a formula $D$ and two derivations $g' : A \mid \GG'_0 \vd D$ and $h' : D \mid \GG_1 \vd C$.
In this case, the interpolant formula for $f$ is $D$, and two desired derivations are $g = \pass \ g'$ and $h = h'$.
The derivation $\scut{\pass \ g'}{h'} = \pass (\scut{g'}{h'})$ is equivalent to $\pass \ f'$ by inductive hypothesis and congruence.
\end{itemize} 
For two-premises rules, we first check $f = \tr (f',f'')$.
The first case of $\tr$ is the partition $\langle (\GG_0, \GG_1), \GG_2 \rangle$ ($\GG_1$ is a non-empty list) with $f' : S \mid \GG_0 \vd A$ and $f'': {-} \mid \GG_1, \GG_2 \vd B$.
In this case, we apply induction on $f'$ with the partition $\langle \GG_0 , [\ ] \rangle $and $f''$ with the partition $\langle \GG_1 , \GG_2 \rangle$ respectively to obtain
\begin{itemize}
  \item[--] a formula $E$ and two derivations $g' : S \mid \GG_0 \vd E$, $h' : E \mid \quad \vd A$, and
  \item[--] a formula $F$ and two derivations $g'' : {-} \mid \GG_1 \vd F$ and $h'' : F \mid \GG_2 \vd B$.
\end{itemize}
Then the desired interpolant formula is $E \ot F$ and the desired derivations are
\begin{displaymath}
  \begin{array}{c}
  \begin{array}{c}
    g
  \end{array}
  \quad
  =
  \quad
  \begin{array}{c}
    \infer[\tr]{S \mid \GG_0 , \GG_1 \vd E \ot F}{
      \deduce{S \mid \GG_0 \vd E}{g'}
      &
      \deduce{{-} \mid \GG_1 \vd F}{g''}
    }
  \end{array}
    \quad
    \begin{array}{c}
      h
    \end{array}
    \quad
    =
    \quad
    \begin{array}{c}
      \infer[\tl]{E \ot F \mid \GG_2 \vd A \ot B}{
      \infer[\tr]{E \mid F , \GG_2 \vd A \ot B}{
        \deduce{E \mid \quad \vd A}{h'}
        &
        \infer[\pass]{{-} \mid F , \GG_2 \vd B}{
          \deduce{F \mid \GG_2 \vd B}{h''}
        }
      }
    }
    \end{array}
  \end{array}
\end{displaymath}
Moreover, $\scut{g}{h}$ is equal to $\tr (\scut{g'}{h'} , \scut{g''}{h''})$ by the path below
\begin{displaymath}
  \begin{array}{lc}
  &
    \infer[\mf{scut}]{S \mid \GG_0 , \GG_1 , \GG_2 \vd A \ot B}{
      \infer[\tr]{S \mid \GG_0 , \GG_1 \vd E \ot F}{
      \deduce{S \mid \GG_0 \vd E}{g'}
      &
      \deduce{{-} \mid \GG_1 \vd F}{g''}
    }
      &
      \infer[\tl]{E \ot F \mid \GG_2 \vd A \ot B}{
      \infer[\tr]{E \mid F , \GG_2 \vd A \ot B}{
        \deduce{E \mid \quad \vd A}{h'}
        &
        \infer[\pass]{{-} \mid F , \GG_2 \vd B}{
          \deduce{F \mid \GG_2 \vd B}{h''}
        }
      }
    }
    }
    \\[10pt]
    \mapsto&
    \quad
    \begin{array}{c}
    \infer[\mf{scut}]{S \mid \GG_0 , \GG_1 , \GG_2 \vd A \ot B}{
      \deduce{S \mid \GG_0 \vd E}{g'}
      &
      \infer[\mf{ccut}]{E \mid \GG_1 , \GG_2 \vd A \ot B}{
        \deduce{{-} \mid \GG_1 \vd F}{g''}
        &
        \infer[\tr]{E \mid F , \GG_2 \vd A \ot B}{
        \deduce{E \mid \quad \vd A}{h'}
        &
        \infer[\pass]{{-} \mid F , \GG_2 \vd B}{
          \deduce{F \mid \GG_2 \vd B}{h''}
        }
      }
      }
    }
    \end{array}
    \\[20pt]
    \mapsto&
    \quad
    \begin{array}{c}
      \infer[\mf{scut}]{S \mid \GG_0 , \GG_1 , \GG_2 \vd A \ot B}{
      \deduce{S \mid \GG_0 \vd E}{g'}
      &
      \infer[\tr]{E \mid \GG_1 , \GG_2 \vd A \ot B}{
        \deduce{E \mid \quad \vd A}{h'}
        &
        \infer[\mf{ccut}]{E \mid \GG_1, \GG_2 \vd B}{
        \deduce{{-}\mid \GG_1 \vd F}{g''}
        &
        \infer[\pass]{{-} \mid F , \GG_2 \vd B}{
          \deduce{F \mid \GG_2 \vd B}{h''}
        }
      }
      }
    }
    \end{array}
    \\[20pt]
    \mapsto&
    \quad
    \begin{array}{c}
      \infer[\mf{scut}]{S \mid \GG_0 , \GG_1 , \GG_2 \vd A \ot B}{
      \deduce{S \mid \GG_0 \vd E}{g'}
      &
      \infer[\tr]{E \mid \GG_1 , \GG_2 \vd A \ot B}{
        \deduce{E \mid \quad \vd A}{h'}
        &
        \infer[\mf{scut}]{E \mid \GG_1, \GG_2 \vd B}{
        \deduce{{-}\mid \GG_1 \vd F}{g''}
        &
        \deduce{F \mid \GG_2 \vd B}{h''}
      }
      }
    }
    \end{array}
  \end{array}
  \end{displaymath}
  \begin{displaymath}
  \begin{array}{lr}
  % \\[20pt]
    \mapsto&
    \quad
    \begin{array}{c}
      \infer[\tr]{S \mid \GG_0 , \GG_1 , \GG_2 \vd A \ot B}{
      \infer[\mf{suct}]{S \mid \GG_0 \vd A}{
        \deduce{S \mid \GG_0 \vd E}{g'}
        &
        \deduce{E \mid \quad \vd A}{h'}
      }
      &
      \infer[\mf{scut}]{E \mid \GG_1, \GG_2 \vd B}{
        \deduce{{-}\mid \GG_1 \vd F}{g''}
        &
        \deduce{F \mid \GG_2 \vd B}{h''}
      }
    }
    \end{array}
  \end{array}
\end{displaymath}
$\tr (\scut{g'}{h'} , \scut{g''}{h''})$ is equivalent to $\tr (f' ,f'')$ by inductive hypothesis and congruence.

The second case of $\tr$ is the partition $\langle \GG_0, (\GG_1 , \GG_2) \rangle$ with $f' : S \mid \GG_0 , \GG_1 \vd A$ and $f'' : {-} \mid \GG_2 \vd B$.
In this case, we apply induction on $f'$ with the partition $\langle \GG_0 , \GG_1 \rangle$ and then obtain a formula $D$ and two derivations $g' : S \mid \GG_0 \vd D$ and $h' : D \mid \GG_1 \vd A$.
The interpolant formula is $D$ and the desired derivations are $g = g'$ and $h = \tr (h' , f'') : D \mid \GG_1 , \GG_2 \vd A \ot B$ where $\scut{g'}{\tr (h', f'')} = \tr (\scut{g'}{h'} , f'') \circeq \tr (f' , f'')$ by inductive hypothesis and congruence.

The first case of $\lleft$ is the partition $\langle \GG_0, (\GG_1, \GG_2) \rangle$ ($\GG_1$ is non-empty) of $\GG$ with $f' : {-} \mid \GG_0, \GG_1 \vd A$ and $f'': B \mid \GG_2 \vd C$.
Our goal is to find a formula $D$ and derivations $g : A\lolli B \mid \GG_0 \vd D$ and $h: D \mid \GG_1, \GG_2 \vd C$.
We first apply inductive hypothesis of $\mf{ccut}$-interpolation on $f'$ with the partition $\langle \GG_0 , \GG_1 , [\ ]\rangle$ and obtain a partition $\langle \GD_1, \dots , \GD_n \rangle$ of $\GG_1$ and a list of formulae $D_1 , \dots , D_n$ and derivations
\begin{itemize}
  \item[--] $g': {-} \mid \GG_0 , D_1, \dots, D_n \vd A$ and
  \item[--] $h'_i : {-} \mid \GD_i \vd D_i$, for $i \in [1\dots n]$.
\end{itemize}
By applying inductive hypothesis of $\mf{scut}$-interpolation on $f''$ with the partition $\langle [\ ] , \GG_2 \rangle$, we obtain a formula $E$ and derivations $g'' : B \mid \quad \vd E$ and $h'': E \mid \GG_2 \vd C$.
For simplicity, we denote $(D_1 , \dots , D_n)$ and $h'_i : {-} \mid \GD_i \vd D_i$, for $i \in [1\dots n]$ as $\GD$ and $\phi$, respectively.
The list of contexts $\GD_1, \dots, \GD_n$ always rewrites to $\GG_1$.
The desired derivations are constructed as follows:
\begin{displaymath}
\begin{array}{lcc}
  \begin{array}{c}
    g
  \end{array}
  \quad 
  &=&
  \quad
    \begin{array}{c}
      \infer[\lright^*]{A\lolli B \mid \GG_0 \vd \ldbc \GD \mid E\rdbc}{
        \infer[\lleft]{A \lolli B \mid \GG_0 , \GD \vd E}{
          \deduce{{-} \mid \GG_0 , \GD \vd A}{g'}
          &
          \deduce{B \mid \quad \vd E}{g''}
        }
      }
    \end{array}
    \\[30pt]
    \begin{array}{c}
      h
    \end{array}
    \quad
    &=&
    \quad
    \begin{array}{c}
      \infer[\lleft^*]{\ldbc \GD \mid E\rdbc \mid \GG_1 \GG_2 \vd C}{
            \phi
            &
            \deduce{E \mid \GG_2 \vd C}{h''}
          }
    \end{array}
  \end{array}
\end{displaymath}
Our goal is to show that $\scut{g}{h} \circeq \lleft(\iccut{\phi}{g'} , \scut{g''}{h''})$.
We rewrite $\scut{g}{h}$ by the following path
\begin{displaymath}
  \begin{array}{lr}
  \begin{array}{c}
    \infer[\mf{scut}]{A \lolli B \mid \GG_0 , \GG_1 , \GG_2 \vd C}{
      \infer[\lright^*]{A\lolli B \mid \GG_0 \vd \ldbc \GD \mid E\rdbc}{
        \infer[\lleft]{A \lolli B \mid \GG_0 , \GD \vd E}{
          \deduce{{-} \mid \GG_0 , \GD \vd A}{g'}
          &
          \deduce{B \mid \quad \vd E}{g''}
        }
      }
      &
      \infer[\lleft^*]{\ldbc \GD \mid E\rdbc \mid \GG_1 \GG_2 \vd C}{
            \phi
            &
            \deduce{E \mid \GG_2 \vd C}{h''}
          }
    }
  \end{array}
    &
    \qquad
    \qquad
    \qquad
  \end{array}
\end{displaymath}
\begin{displaymath}
  \begin{array}{lr}
    \begin{array}{c}
    (\text{Eq} \ \ref{scut-or-ols})
    \\
    \mapsto
  \end{array}
  \qquad
  \qquad
  &
  \begin{array}{c}
    \infer[\mf{scut}]{A \lolli B \mid \GG_0 , \GG_1 , \GG_2 \vd C}{
    \infer[\mf{ccut}^*]{A \lolli B \mid \GG_0 , \GG_1 \vd E}{
      \phi
      &
      \infer[\lleft]{A \lolli B \mid \GG_0 , \GD \vd E}{
        \deduce{{-} \mid \GG_0 , \GD \vd A}{g'}
        &
        \deduce{B \mid \quad \vd E}{g''}
      }
    }
    &
    \deduce{E \mid \GG_2 \vd C}{h''}
  }
  \end{array}
  \end{array}
\end{displaymath}
\begin{displaymath}
  \begin{array}{lr}
% \\[10 pt]
    \mapsto&
    \qquad \qquad
    \begin{array}{c}
      \infer[\mf{scut}]{A \lolli B \mid \GG_0 , \GG_1 , \GG_2 \vd C}{
      \infer[\lleft]{A \lolli B \mid \GG_0 , \GG_1 \vd E}{
        \infer[\mf{ccut}^*]{{-} \mid \GG_0 , \GG_1 \vd A}{
          \phi
          &
          \deduce{{-} \mid \GG_0 , \GD \vd A}{g'}
        }
        &
        \deduce{B \mid \quad \vd E}{g''}
      }
      &
      \deduce{E \mid \GG_2 \vd C}{h''}
    }
    \end{array}
%   \end{array}
% \end{displaymath}
% \begin{displaymath}
%   \begin{array}{lr}
\\[1.5cm]
    \mapsto&
    \qquad \qquad
    \begin{array}{c}
      \infer[\lleft]{A \lolli B \mid \GG_0 , \GG_1 , \GG_2 \vd C}{
        \infer[\mf{ccut}^*]{{-} \mid \GG_0 , \GG_1 \vd A}{
          \phi
          &
          \deduce{{-} \mid \GG_0 , \GD \vd A}{g'}
        }
        &
        \infer[\mf{scut}]{B \mid \GG_2 \vd C}{
          \deduce{B \mid \quad E}{g''}
          &
          \deduce{E \mid \GG_2 \vd C}{h''}
        }
      }
    \end{array}
  \end{array}
\end{displaymath}
% \begin{displaymath}
%   \begin{array}{lr}
%     &
%     \infer[\mf{scut}]{A \lolli B \mid \GG_0 , \GG_1 , \GG_2 \vd C}{
%       \infer[\lright]{A\lolli B \mid \GG_0 \vd D^*}{
%       \deduce{A \lolli B \mid \GG_0 , D_1 \vd D'^*}{
%         \deduce{\vdots}{
%         \infer[\lright]{A \lolli B \mid \GG_0 , D_1, \dots ,D_{n-1} \vd D_n \lolli E}{
%         \infer[\lleft]{A \lolli B \mid \GG_0 , D_1, \dots, D_n \vd E}{
%           \deduce{{-} \mid \GG_0 , D_1, \dots, D_n \vd A}{g'}
%           &
%           \deduce{B \mid \quad \vd E}{g''}
%         }
%       }
%       }
%       }
%     }
%       &
%       \infer[\lleft]{D^* \mid \GG_1, \GG_2 \vd C}{
%       \deduce{{-} \mid \GD_1 \vd D_1}{h'_1}
%       &
%       \deduce{D'^{*} \mid \GD_2, \dots, \GD_n, \GG_2 \vd C}{
%         \deduce{\vdots}{
%           \infer[\lleft]{D_n \lolli E \mid \GD_n, \GG_2 \vd C}{
%             \deduce{{-} \mid \GD_n, \GG_2 \vd D_n}{h'_n}
%             &
%             \deduce{E \mid \GG_2 \vd C}{h''}
%           }
%         }
%       }
%     }
%     }
%   \end{array}
%   \end{displaymath}
%   \begin{displaymath}
%   \begin{array}{lr}
%    \begin{array}{l}
%     (\text{Eq} \ \ref{scut-or-ols})
%     \\
%     \mapsto
%   \end{array}
%   &
%   \begin{array}{c}
%     \infer[\mf{scut}]{A \lolli B \mid \GG_0 , \GG_1 , \GG_2 \vd C}{
%     \infer[\mf{ccut}]{A \lolli B \mid \GG_0 , \GG_1 \vd E}{
%       \deduce{{-} \mid \GD_1 \vd D_1}{h'_1}
%       &
%       \deduce{A \lolli B \mid \GG_0 , D_1 , \GD_2 , \dots , \GD_n \vd E}{
%         \deduce{\vdots}{
%         \infer[\mf{ccut}]{A \lolli B \mid \GG_0 , D_1, D_2 ,\dots , \GD_n \vd E}{
%           \deduce{{-} \mid \GD_n \vd D_n}{h'_n}
%           &
%           \infer[\lleft]{A \lolli B \mid \GG_0 , D_1, \dots , D_n \vd E}{
%             \deduce{{-} \mid \GG_0 , D_1 , \dots , D_n \vd A}{g'}
%             &
%             \deduce{B \mid \quad \vd E}{g''}
%           }
%         }
%       }
%     }
%     }
%     &
%     \deduce{E \mid \GG_2 \vd C}{h''}
%    }
%   \end{array}
% \end{array}
% \end{displaymath}
% \begin{displaymath}
% \begin{array}{lr}
%   \mapsto&
%   \begin{array}{c}
%     \infer[\mf{scut}]{A \lolli B \mid \GG_0 , \GG_1 , \GG_2 \vd C}{
%     \infer[\lleft]{A \lolli B \mid \GG_0 , \GG_1 \vd E}{
%       \infer[\mf{ccut}]{{-} \mid \GG_0 , \GG_1 \vd A}{
%         \deduce{{-} \mid \GD_1 \vd D_1}{h'_1}
%         &
%         \deduce{{-} \mid \GG_0 , D_1 , \GD_2 , \dots , \GD_n \vd A}{
%           \deduce{\vdots}{
%         \infer[\mf{ccut}]{{-} \mid \GG_0 , D_1, D_2 , \dots , \GD_n \vd A}{
%           \deduce{{-} \mid \GD_n \vd D_n}{h'_n}
%           &
%           \deduce{{-} \mid \GG_0 , D_1 , \dots , D_n \vd A}{g'}
%         }
%         }
%       }
%       }
%       &
%       \deduce{B \mid \quad \vd E}{g''}
%     }
%     &
%     \deduce{E \mid \GG_2 \vd C}{h''}
%    }
%   \end{array}
%   \end{array}
%   \end{displaymath}
%   \begin{displaymath}
%   \begin{array}{lr}
%   \mapsto&
%   \begin{array}{c}
%     \infer[\lleft]{A \lolli B \mid \GG_0 , \GG_1 , \GG_2 \vd C}{
%       \infer[\mf{ccut}]{{-} \mid \GG_0 , \GG_1 \vd A}{
%         \deduce{{-} \mid \GD_1 \vd D_1}{h'_1}
%         &
%         \deduce{{-} \mid \GG_0 , D_1 , \GD_2 , \dots , \GD_n \vd A}{
%           \deduce{\vdots}{
%         \infer[\mf{ccut}]{{-} \mid \GG_0 , D_1, D_2 , \dots , \GD_n \vd A}{
%           \deduce{{-} \mid \GD_n \vd D_n}{h'_n}
%           &
%           \deduce{{-} \mid \GG_0 , D_1 , \dots , D_n \vd A}{g'}
%         }
%         }
%       }
%       }
%       &
%      \infer[\mf{scut}]{B \mid \GG_2 \vd C}{
%       \deduce{B \mid \quad \vd E}{g''}
%       &
%       \deduce{E \mid \GG_2 \vd C}{h''}
%     }
%    }
%   \end{array}
%   \end{array}
% \end{displaymath}
The derivation $\lleft (\iccut{\phi}{g'} , \scut{g''}{h''})$ is equivalent to $\lleft (f' , f'')$ by inductive hypothesis and congruence.

The second case of $\lleft$ is the partition $\langle (\GG_0 , \GG_1) , \GG_2 \rangle$ with derivations $f' : {-} \mid \GG_0 \vd A$ and $f'' : B \mid \GG_1 , \GG_2 \vd C$.
In this case, we apply the inductive hypothesis of $\mf{scut}$-interpolation on $f''$ with the partition $\langle \GG_1 , \GG_2 \rangle$ and then obtain a formula $D$, and two derivations $g'' : B \mid \GG_1 \vd D$ and $h'' : D \mid \GG_2 \vd C$.
The interpolant formula is $D$ and the desired derivations are $g = \lleft (f' , g'') : A \lolli B \mid \GG_0 , \GG_1 \vd D$ and $h = h''$.
The derivation $\scut{\lleft (f' , g'')}{h''}$ is equal to $\lleft (f' , \scut{g''}{h''})$ which is equivalent to $\lleft (f' , f'')$ by inductive hypothesis and congruence.
\end{proof}
\section{Formalization}
In this ongoing work, we show that sequent calculi for left skew monoidal (closed) categories enjoy Craig interpolation.
The proofs of two statements of generalized interpolation are formalized in the proof assistant Agda.
The code is available at
\begin{center}
  \url{https://github.com/niccoloveltri/code-skewmonclosed/tree/interpolation}.
\end{center}
For the future, we would like to extend the result to other semi-substructural logics in \cite{veltri:coherence:2021,VW:2023}.
\bibliography{StudiaLogica}


%%=============================================%%
%% For submissions to Nature Portfolio Journals %%
%% please use the heading ``Extended Data''.   %%
%%=============================================%%

%%=============================================================%%
%% Sample for another appendix section			       %%
%%=============================================================%%

%% \section{Example of another appendix section}\label{secA2}%
%% Appendices may be used for helpful, supporting or essential material that would otherwise 
%% clutter, break up or be distracting to the text. Appendices can consist of sections, figures, 
%% tables and equations etc.

%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%


\end{document}
