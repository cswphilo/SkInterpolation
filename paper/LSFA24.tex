% \documentclass{paper}
\documentclass[submission,copyright,creativecommons]{eptcs}
\providecommand{\event}{LSFA 2024} % Name of the event you are submitting to

\usepackage{iftex}

% \ifpdf
  \usepackage{underscore}         % Only needed if you use pdflatex.
  \usepackage[T1]{fontenc}        % Recommended with pdflatex
% \else
  \usepackage{breakurl}           % Not needed if you use pdflatex only.
% \fi
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{proof}
\usepackage{quiver}
\usepackage{thmtools, thm-restate}
% \declaretheorem{theorem}
%% \theorembodyfont{}
\newtheorem{theorem}{Theorem}[section]
\newtheorem*{theorem*}{Theorem}
% \declaretheorem{theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
\newtheorem{defn}[theorem]{Definition}
\newtheorem{example}{Example}[theorem]
%\newtheorem{defn}[definition]{Definition}
%\newtheorem{example}[definition]{Definition}
%\newtheorem*{proof}{Proof : }
\newtheorem{fact}[theorem]{Fact}
\newenvironment{proofsketch}{%
  \renewcommand{\proofname}{Proof sketch}\proof}{\endproof}
\makeatletter
\newsavebox{\@brx}
\newcommand{\curly}{\mathrel{\leadsto}}
\newcommand{\llangle}[1][]{\savebox{\@brx}{\(\m@th{#1\langle}\)}%
  \mathopen{\copy\@brx\kern-0.5\wd\@brx\usebox{\@brx}}}
\newcommand{\rrangle}[1][]{\savebox{\@brx}{\(\m@th{#1\rangle}\)}%
  \mathclose{\copy\@brx\kern-0.5\wd\@brx\usebox{\@brx}}}
\makeatother
\newcommand{\ldbc}{[\![}
\newcommand{\rdbc}{]\!]}
\newcommand{\tbar}{[\vec{x}/\vec{t}]}
\newcommand{\ltbar}{[\vec{x}, x/\vec{t}, x]}
\newcommand{\GG}{\Gamma}
\newcommand{\Gg}{\gamma}
\newcommand{\GD}{\Delta}
\newcommand{\Gd}{\delta}
\newcommand{\GL}{\Lambda}
\newcommand{\GO}{\Omega}
\newcommand{\GT}{\Theta}
\newcommand{\vd}{\vdash}
\newcommand{\tl}{\otimes \mathsf{L}}
\newcommand{\tr}{\otimes\mathsf{R}}
\newcommand{\tll}{\otimes^{\mathsf{L}} \mathsf{L}}
\newcommand{\tlr}{\otimes^{\mathsf{R}} \mathsf{L}}
\newcommand{\trl}{\otimes^{\mathsf{L}} \mathsf{R}}
\newcommand{\trr}{\otimes^{\mathsf{R}} \mathsf{R}}
\newcommand{\pass}{\mathsf{pass}}
\newcommand{\unitl}{\mathsf{IL}}
\newcommand{\unitr}{\mathsf{IR}}
\newcommand{\ax}{\mathsf{ax}}
\newcommand{\id}{\mathsf{id}}
\newcommand{\ot}{\otimes}
\newcommand{\otl}{\otimes^{\mathsf{L}}}
\newcommand{\otr}{\otimes^{\mathsf{R}}}
\newcommand{\ol}{\mathbin{\diagup}}
\newcommand{\lo}{\mathbin{\diagdown}}
\newcommand{\lolli}{\multimap}
\newcommand{\lleft}{{\lolli}\mathsf{L}}
\newcommand{\lright}{{\lolli}\mathsf{R}}
\newcommand{\llolli}{\multimap^{\mathsf{L}}}
\newcommand{\rlolli}{\multimap^{\mathsf{R}}}
\newcommand{\llleft}{{\llolli}\mathsf{L}}
\newcommand{\rlleft}{{\rlolli}\mathsf{L}}
\newcommand{\llright}{{\llolli}\mathsf{R}}
\newcommand{\rlright}{{\rlolli}\mathsf{R}}
\newcommand{\illol}{\rotatebox[origin=c]{180}{$\multimap$}}
\newcommand{\I}{\mathsf{I}}
\newcommand{\msfL}{\mathsf{L}}
\newcommand{\defeq}{=_{\mathsf{df}}}
\newcommand{\comp}{\mathsf{comp}}
\newcommand{\RI}{\mathsf{RI}}
\newcommand{\LI}{\mathsf{LI}}
\newcommand{\Pass}{\mathsf{P}}
\newcommand{\F}{\mathsf{F}}
\newcommand{\xvdash}{\vdash^{x}}
\newcommand{\yvdash}{\vdash^{y}}
\newcommand{\comm}{\ot\mathsf{comm}}
\newcommand{\assl}{\mathsf{assoc}^{\mathsf{L}}}
\newcommand{\assr}{\mathsf{assoc}^{\mathsf{R}}}
\newcommand{\vdG}{\vdash}
\newcommand{\vdL}{\vdash_{L}}
\newcommand{\vdT}{\vdash_{T}}
\newcommand{\cdl}{\cdot^{\mf{L}}}
\newcommand{\cdr}{\cdot^{\mf{R}}}
\newcommand{\sls}{\slash}
\newcommand{\bsls}{\backslash}

\newcommand{\highlight}[1]{\textcolor{blue}{#1}}

\newcommand{\proofbox}[1]{\begin{tabular}{l} #1 \end{tabular}}

\newcommand{\MILL}{$\mathtt{MILL}$}
\newcommand{\NL}{$\mathtt{NL}$}
\newcommand{\NMILL}{$\mathtt{NMILL}$}
\newcommand{\SkNMILL}{$\mathtt{SkNMILL}$}
\newcommand{\LSkNL}{$\mathtt{LSkNL}$}
\newcommand{\LSkG}{$\mathtt{LSkG}$}
\newcommand{\LSkGm}{$\mathtt{LSkG^{-}}$}
\newcommand{\LSkT}{$\mathtt{LSkT}$}
\newcommand{\RSkT}{$\mathtt{RSkT}$}
\newcommand{\LSkTm}{$\mathtt{LSkT^{-}}$}
\newcommand{\LSkA}{$\mathtt{LSkA}$}
\newcommand{\FSkMCC}{\mathsf{FSkMCl}}
\newcommand{\SkBiC}{$\mathsf{SkBiC}$}
\newcommand{\SkBiCT}{$\mathtt{SkBiCT}$}
\newcommand{\SkBiCA}{$\mathtt{SkBiCA}$}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\mf}[1]{\mathsf{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\vars}[1]{\mathsf{var}(#1)}

\title{Craig Interpolation for Semi-{S}ubstructural Logics}

% \author{Cheng-Syuan Wan
% \institute{Department of Software Science
% \\
% Tallinn University of Technology
% \\
% Tallinn, Estonia}
% \email{cswan@cs.ioc.ee}
% }
\author{
Niccol{\`o} Veltri \qquad\qquad Cheng-Syuan Wan
\institute{Tallinn University of Technology, Estonia}
\email{\quad niccolo@cs.ioc.ee \quad\qquad cswan@cs.ioc.ee}
}
% \and
% Co Author \qquad\qquad Yet S. Else
% \institute{Stanford University\\
% California, USA}
% \email{\quad is@gmail.com \quad\qquad somebody@else.org}
% }
\def\titlerunning{Craig Interpolation for Semi-{S}ubstructural Logics}
% \def\authorrunning{C.-S. Wan}

\def\authorrunning{N. Veltri \& C.-S. Wan}
\begin{document}
\maketitle
% \section{Introduction}\label{intro}
\begin{abstract}
This work studies Craig interpolation for the sequent calculus of skew monoidal closed categories.
Skew monoidal closed categories are a relaxed version of monoidal closed categories, where the structural laws of associativity and left and right unitality, are merely natural transformations with a specific orientation.
The corresponding sequent calculus is semi-substructural because it only admits semi-associativity and semi-unitality, i.e. it is an intermediate logic between non-associative and associative linear logic.
Craig interpolation for various substructural logics has been studied both proof-theoretically and algebraically.
However, it is not clear whether these methods can be applied to semi-substructural logics.
Here we investigate the problem proof-theoretically and show that the sequent calculi for skew monoidal (closed) categories enjoy Craig interpolation by proving a skew version of general interpolation.

% Uustalu et al. used syntax and techniques from linear logic to represent left skew monoidal closed categories, yielding results regarding proof identities and categorical coherence.
% However, their approach does not guarantee Craig interpolation in all cases and falls short in modularly capturing skew bi-closed categories.

% To address the problems above, we construct cut-free sequent calculi for left skew monoidal closed categories and skew bi-closed categories, reminiscent of the calculi of non-associative Lambek calculus.
% We show that both sequent calculi enjoy Craig interpolation by generalizing Maehara's method with an accumulator of tree rewriting.
% Moreover, the relational semantics of axiomatic calculus for skew bi-closed categories provides an algebraic way to understand the internal relationship between the left and right skew monoidal (closed) categories.
% we construct a sequent calculus analogous to the ones for non-associsyntactic and semantic methods from Lambek calculus to obtain a sequent calculus
% Here we employ syntactic and semantic methods from Lambek calculus to obtain a sequent calculus for left skew monoidal closed categories which enjoys Craig interpolation.
% Additionally, we provide sequent and axiomatic calculi for skew bi-closed categories.
% For the latter, its relational semantics gives an algebraic way to understand the internal relationship between the left and right skew monoidal (closed) categories.
\end{abstract}

\section{Introduction}\label{sec:intro}
Substructural logics are logic systems that lack at least one of the structural rules, weakening, contraction, and exchange.
Joachim Lambek's syntactic calculus \cite{lambek:mathematics:58} is a well-known example that disallows weakening, contraction, and exchange.
Another example, linear logic, proposed by Jean-Yves Girard \cite{girard:linear:87}, is a substructural logic in which weakening and contraction are in general disallowed but can be recovered for some formulae via modalities.
Substructural logics have been found in numerous applications from computational analysis of natural languages to the development of resource-sensitive programming languages.

\emph{Left skew monoidal categories} \cite{szlachanyi:skew-monoidal:2012} are a weaker variant of MacLane's monoidal categories where the structural morphisms of associativity and unitality are not required to be bidirectional, they are natural transformations with a particular orientation.
Therefore, they can be seen as \emph{semi-associative} and \emph{semi-unital} variants of monoidal categories. 
Left skew monoidal categories arise naturally in the semantics of programming languages \cite{altenkirch:monads:2014}, while the concept of semi-associativity is connected with combinatorial structures like the Tamari lattice and Stasheff associahedra \cite{zeilberger:semiassociative:19}.

In recent years, in collaboration with Tarmo Uustalu and Noam Zeilberger, we started a research project on \emph{semi-substructural} logics, which is inspired by a series of developments on left skew monoidal categories and related variants by Szlach{\'a}nyi, Street, Bourke, Lack and many others \cite{szlachanyi:skew-monoidal:2012,street:skew-closed:2013,lack:triangulations:2014,bourke:skew:2018,bourke:lack:braided:2020}.

We call the internal languages of left skew monoidal categories and their variants \emph{semi-substructural} logics, because they are intermediate logics in between (certain fragments of) non-associative and associative intuitionistic linear logic (or Lambek calculus).
Semi-associativity and semi-unitality are encoded as follows.
Sequents are in the form $S \mid \Gamma \vdash A$, where the antecedent consists of an optional formula $S$, called stoup, adapted from Girard \cite{girard:constructive:91}, and an ordered list of formulae $\Gamma$.
The succedent is a single formula $A$.
We restrict the application of introduction rules in an appropriate way to allow only one of the directions of associativity and unitality.
% the one in the definition of skew monoidal category. For example, left-introduction rules are allowed to act only on the formula in stoup position, not on formulae in $\Gamma$.

This approach has successfully captured internal languages for a variety of categories, including  $(i)$ left skew semigroup \cite{zeilberger:semiassociative:19}, $(ii)$ left skew monoidal \cite{uustalu:sequent:2021}, $(iii)$ left skew (prounital) closed \cite{uustalu:deductive:nodate}, $(iv)$ left skew monoidal closed categories \cite{UVW:protsn,veltri:multifocus:23}, and $(v)$ left distributive skew monoidal categories with finite products and coproducts \cite{VW:2023} through skew variants of the fragments of non-commutative intuitionistic linear logic consisting of combinations of connectives $(\I,\ot,\lolli,\land,\lor)$.
Additionally, discussions have covered partial normality conditions, in which one or more structural morphisms are allowed to have an inverse \cite{uustalu:proof:nodate}, as well as extensions with skew exchange Ã  la Bourke and Lack \cite{veltri:coherence:2021,VW:2023}.

All of the aforementioned calculi with sequents of the form $S \mid \GG \vd A$ are cut-free and therefore, by their rule design, they are decidable.
Moreover, they all admit sound and complete subcalculi inspired by Andreoli's focusing \cite{andreoli:logic:1992} in which
rules are restricted to be applied in a specific order.
A focused calculus provides an algorithm to solve both the proof identity problems for its non-focused calculus and coherence problems for its corresponding variant of left skew monoidal category.

We say a consequence relation $\vdash$ has Craig interpolation if for any $f: A \vdash C$, there exist a formula $B$ and two derivations $g: A \vdash B$ and $h: B \vdash C$, satisfying the variable condition: $\vars{B} \subseteq \vars{A} \cap \vars{C}$ ($\vars{A}$ is the set of atomic formulae appearing in $A$) \cite{craig:interpolation:1957}.
% The variation of Craig interpolation is defined by replacing the variable condition with that given a set of formulae $\GT$, and given a derivation $f:A \vd^{\GT} C$, if all formulae appearing in $f$ are in $\GT$, then there exists a formula $B \in \GT$ and two derivations $f_0: A\vd^{\GT} B$ and $f_1: B \vd^{\GT} C$. 
% In this paper, we call the former Craig interpolation and the latter weak interpolation.

In this work, we show that sequent calculi for left skew monoidal (closed) categories enjoy Craig interpolation.

% By reversing all structural morphisms and modifying coherence conditions in left skew monoidal closed categories, right skew monoidal closed categories emerge \cite{uustalu:eilenberg-kelly:2020}.
% Moreover, skew bi-closed categories are defined by appropriately integrating left and right skew monoidal closed structures.
% It is natural for us to consider sound sequent calculi for these categories.
% However, the implication rules are not well-behaved when just modeling right skew monoidal closed categories with sequent calculus {\`a} la Girard.

% In short, both problems stem from the skew structure concealed within the flat antecedent of $S \mid \GG \vd A$.
% While the antecedent $S \mid \GG$ is defined similarly to an ordered list, it is actually a tree associating to the left.

% In this work, we analyze and solve these two problems with ideas and methods from non-associative Lambek calculus.
% We start in Section \ref{sec:syntax}, by introducing the sequent calculus {\` a} la Girard (\LSkG) for left skew monoidal closed categories from \cite{UVW:protsn} and elaborating its limitation on having interpolation.
% By generalizing the method in \cite{ono:proof:nonclassical:1998}, we prove interpolation for a cut-free sequent calculus \LSkT, which is inspired by sequent calculus 
% for non-associative Lambek calculus \cite{bulinska:2009,moot:categorial:2012} and equivalent to \LSkG.
% The antecedents of sequents in \LSkT~are trees, which save us from discussing impossible cases when proving interpolation.
% Moreover, by the equivalence between \LSkG~and \LSkT, we can prove a special form of interpolation for \LSkG~via \LSkT.

% In Section \ref{sec:skew:categories}, we introduce definitions of left (right) skew monoidal closed categories and skew bi-closed categories, and normality conditions for skew categories.
% In Section \ref{sec:calculi:skbic}, we describe two calculi for skew bi-closed categories: one is an axiomatic calculus (\SkBiCA), while the other is a sequent calculus (\SkBiCT) similar to the multimodal non-associative Lambek calculus \cite{moortgat:multimodl:1996}.
% In Section \ref{sec:algebraic:relational:model}, we introduce the relational semantics for \SkBiCA.
% We define the relational semantics via a Kripke frame with two ternary relations and show that the partially ordered set which consists of subsets of possible worlds with appropriate operations is a thin skew bi-closed category.
% Furthermore, by theorem (\ref{thm:main}), we can prove a thin version of main theorems in \cite{uustalu:eilenberg-kelly:2020}.

\section{Sequent Calculus and Interpolation}\label{sec:syntax}
Recall the sequent calculus (\LSkG) for left skew monoidal closed categories from \cite{UVW:protsn}, which is a skew variant of non-commutative multiplicative intuitionistic linear logic.

Formulae ($\mf{Fma}$) are inductively generated by the grammar $A, B::= X \ | \ \I \ | \ A \ot B \ | \ A \lolli B$, where $X$ comes from a countably infinite set $\mathsf{At}$ of atoms, $\I$ is a multiplicative unit, $\ot$ is multiplicative conjunction and $\lolli$ is a linear implication.

A sequent is a triple of the form $S \mid \Gamma \vdG A$, where the antecedent splits into: an optional formula $S$, called \emph{stoup} \cite{girard:constructive:91}, and an ordered list of formulae $\Gamma$ and succedent $A$ is a single formula.
The symbol $S$ consistently denotes a stoup, meaning $S$ can either be a single formula or empty, indicated as $S = {-}$; furthermore, $X$, $Y$, and $Z$ always represent atomic formulae.
% The design of sequents is from previous work on syntactic characterizations for skew structures \cite{uustalu:sequent:2021,uustalu:proof:nodate,uustalu:deductive:nodate,veltri:coherence:2021}.
% The peculiar design of sequents, involving the presence of the stoup in the antecedent, comes from previous work on deductive systems with skew structure by Uustalu, Veltri and Zeilberger \cite{uustalu:sequent:2021,uustalu:proof:nodate,uustalu:deductive:nodate,veltri:coherence:2021}.

Derivations in are generated recursively by the following rules:
\begin{equation}\label{eq:seqcalc:skmc:Gir}
	  % \def\arraystretch{2.5}
	  \begin{array}{c}
		\infer[\ax]{A \mid \quad \vdG A}{}
		\quad
		\infer[\lleft]{A \lolli B \mid \Gamma , \Delta \vdG C}{
		  {-} \mid \Gamma \vdG A
		  &
		  B \mid \Delta \vdG C
		}
		\quad
		\infer[\unitl]{\I \mid \Gamma \vdG C}{{-} \mid \Gamma \vdG C}
		\quad
		\infer[\tl]{A \ot B \mid \Gamma \vdG C}{A \mid B , \Gamma \vdG C}
		\\[5pt]
    \infer[\pass]{{-} \mid A , \Gamma \vdG C}{A \mid \Gamma \vdG C}
		\quad
		\infer[\lright]{S \mid \Gamma \vdG A \lolli B}{S \mid \Gamma , A \vdG B}
		\quad
		\infer[\unitr]{{-} \mid \quad \vdG \I}{}
		\quad
		\infer[\tr]{S \mid \Gamma , \Delta \vdG A \ot B}{
		  S \mid \Gamma \vdG A
		  &
		  {-} \mid \Delta \vdG B
		}
	  \end{array}
	\end{equation}
The inference rules in (\ref{eq:seqcalc:skmc:Gir}) are similar to the ones in the sequent calculus for non-commutative multiplicative intuitionistic linear logic (\NMILL) \cite{abrusci:noncommutative:1990}, but with some crucial differences: 
% $(i)$ The left logical rules $\unitl$, $\tl$ and $\lleft$, read bottom-up, are only allowed to be applied on the formula in the stoup position. $(ii)$ The right tensor rule $\tr$, read bottom-up, splits the antecedent of a sequent $S \mid \Gamma, \Delta \vdG A \ot B$ and in the case where $S$ is a formula, $S$ is always moved to the stoup of the left premise, even if $\Gamma$ is empty.
% $(iii)$ The presence of the stoup distinguishes two types of antecedents, $A \mid \Gamma$ and ${-} \mid A, \Gamma$. The structural rule $\pass$ (for `passivation'), read bottom-up, allows the moving of the leftmost formula in the context to the stoup position whenever the stoup is empty.
% $(iv)$ The logical connectives of \NMILL\ (and associative Lambek calculus) typically include two ordered implications $\lolli$ and $\illol$, which are two variants of linear implication arising from the removal of the exchange rule from intuitionistic linear logic. In \LSkG~only the left implication $\lolli$ (right residuation in Lambek calculus) is present. 
\begin{enumerate}
\item The left logical rules $\unitl$, $\tl$ and $\lleft$, read bottom-up, are only allowed to be applied on the formula in the stoup position.
% In particular, there is no general way to remove a unit $\I$ nor decompose a tensor $A \ot B$ if these formulae are located in the context and not in the stoup
%  (we will see in (\ref{eq:lleft:gen}) that something can actually be done to deal with implications $A \lolli B$ in the context).
\item The right tensor rule $\tr$, read bottom-up, splits the antecedent of a sequent $S \mid \Gamma, \Delta \vdG A \ot B$ and in the case where $S$ is a formula, $S$ is always moved to the stoup of the left premise, even if $\Gamma$ is empty.
% whereby the formula in the stoup, in case such a formula is present, has to be moved to the stoup of the first premise. In particular, the stoup formula of the conclusion cannot be moved to the antecedent of the second premise even if $\Gamma$ is chosen to be empty.
\item The presence of the stoup distinguishes two types of antecedents, $A \mid \Gamma$ and ${-} \mid A, \Gamma$. The structural rule $\pass$ (for `passivation'), read bottom-up, allows the moving of the leftmost formula in the context to the stoup position whenever the stoup is empty.
\item The logical connectives of \NMILL~typically include two ordered implications $\lolli$ and $\illol$, which are two variants of linear implication arising from the removal of the exchange rule from intuitionistic linear logic. In here, only the left implication $\lolli$ is present. 
% It is currently not clear to us whether the inclusion of the second implication to our logic is a meaningful addition and whether it corresponds to some particular categorical notion.
\end{enumerate}
% The restrictions in 1--4 are essential for precisely capturing all the features of skew monoidal closed categories and nothing more, as we discuss in Section \ref{sec:catsem}.
% Notice also that, similarly to the case of \NMILL, all structural rules of exchange, contraction, and weakening are absent. We give names to derivations and we write $f: S \mid \Gamma \vdash A$ when $f$ is a particular derivation of the sequent $S \mid \Gamma \vdash A$.
For a more detailed explanation and an interpretation of the system as a logic of resources, see \cite[Section 2]{UVW:protsn}.
% a linear logical interpretation of the calculus

This calculus is sound and complete wrt. left skew monoidal closed categories and cut-free, i.e., following two rules are admissible:
\begin{displaymath}
      \infer[\mathsf{scut}]{S \mid \Gamma , \Delta \vdG C}{
        \deduce{S \mid \Gamma \vdG A}{}
        &
        \deduce{A \mid \Delta \vdG C}{}
      }
      \qquad
      \infer[\mathsf{ccut}]{S \mid \Delta_0 , \Gamma , \Delta_1 \vdG C}{
        \deduce{{-} \mid \Gamma \vdG A}{}
        &
        \deduce{S \mid \Delta_0 , A , \Delta_1 \vdG C}{}
      }
    \end{displaymath}
% By soundness and completeness, similar to the result in \cite{uustalu:sequent:2021} for skew monoidal categories, we mean that \LSkG~is syntactically equivalent to the axiomatic characterization of the free left skew monoidal closed category.
% % This axiomatic calculus (\LSkNL) is reminiscent of Lambek's syntactic calculus \cite{lambek:deductive:68,lambek:deductive:69}:
% \begin{equation*}\label{eq:seqcalc:skmc:Lam}
%   % \def\arraystretch{1.5}
%   \begin{array}{c}
%         \infer[\id]{A \vdL A}{}
%         \qquad
%         \infer[\mathsf{comp}]{A \vdL C}{
%           A \vdL B
%           &
%           B \vdL C
%         }
% %    \end{displaymath}
%         %    \begin{displaymath}
%         \qquad
%       \infer[\otimes]{A \ot B \vdL C \ot D}{
%         A \vdL C
%         &
%         B \vdL D
%       }
%       \qquad
%       \infer[\lolli]{A \lolli B \vdL C \lolli D}{
%         C \vdL A
%         &
%         B \vdL D
%       }
% %    \end{displaymath}
%       %    \begin{displaymath}
%       \\[5pt]
%       \infer[\lambda]{\I \ot A \vdL A}{}
%       \quad
%       \infer[\rho]{A \vdL A \ot \I}{}
%       \quad
%       \infer[\alpha]{(A \ot B) \ot C \vdL A \ot (B \ot C)}{}
% %    \end{displaymath}
%       %    \begin{displaymath}
%       \quad
%       \infer=[\pi]{A \vdL B \lolli C}{A \ot B \vdL C}
%       % \quad
%       % \infer[\pi^{-1}]{A \ot B \vdL C}{A \vdL B \lolli C}
%   \end{array}
% \end{equation*}
% In particular, this is a semi-unital and semi-associative variation of Moortgat and Oehrle's calculus \cite[Chapter 4]{moot:categorial:2012} of non-associative Lambek calculus (\NL), where only right residuation is present.
% We only care about provability in this paper, therefore the congruence relations on sets of derivations $A \vdL B$ and $S \mid \Gamma \vdG A$ similar to ones in \cite{uustalu:sequent:2021} are omitted.
% However, the congruence relations are essential for these calculi being correct characterizations of the free left skew monoidal closed category.

% The calculus \LSkG, being an equivalent presentation of a skew version of \NL,\  provides an effective procedure to determine formulae derivability in \LSkNL.
% In other words, for any formula $A$, $ \vdL A$ if and only if ${-} \mid \quad \vdG A$.
% Proof search in \LSkG~always terminates, so for any $A$, either there is a proof in \LSkG~or the proof search terminates without finding any proof.

We are interested in if \LSkG~enjoys Craig interpolation.
For substructural logic (especially non-commutative logic), we have a general version of interpolation \cite{ono:proof:nonclassical:1998}:
\begin{itemize}
  \item[\ ] Given $f : \Gamma \vdash C$ and any partition $\langle \Gamma_0, \Gamma_1, \Gamma_2 \rangle$ of $\Gamma$, there exist a formula $D$ and two derivations $g : \Gamma_1 \vdash D$ and $h : \Gamma_0, D, \Gamma_1 \vdash C$, and $\vars{D} \subseteq \vars{\Gamma_0} \cap \vars{\Gamma_0, \Gamma_1, C}$ ($\vars{A}$ is the set of atomic formulae appearing in $A$ and $\vars{\Gamma}$ means $\bigcup \vars{A_i}$ for $A_i \in \Gamma$).
\end{itemize}

Due to two cut rules in \LSkG, we should consider two versions of general interpolation:
\begin{itemize}
  \item[\ ] ($\mf{scut}$-interpolation) Given $f: S \mid \Gamma \vdG C$ and any partition $\langle \GG_0,\GG_1 \rangle$ of $\GG$, there exist a formula $D$ and two derivations $g : S \mid \GG_0 \vdG D$ and $h : D \mid \GG_1 \vdG C$, and $\vars{D} \subseteq \vars{s(S), \GG_0} \cap \vars{\GG_1, C}$, where $s(S) = I$ if $S = {-}$ or $s(S) = B$ if $S = B$.
  \item[\ ] ($\mf{ccut}$-interpolation) Given $f: S \mid \Gamma \vdG C$ and any partition $\langle \GG_0,\GG_1, \GG_2 \rangle$ of $\GG$, there exist a partition of $\langle \GD_1, \dots, \GD_n \rangle$ of $\GG_1$, a list of formulae $D_1, \dots, D_n$ and derivations $g: S \mid \GG_0, D_1, \dots, D_n, \GG_2 \vdG C$ and $h_i : {-} \mid \GD_i \vdG D_i$ for $i \in [1\dots n]$ such that $\vars{D_1, \dots, D_n} \subseteq \vars{\GD_1, \dots, \GD_n} \cap \vars{s(S), \GG_0, \GG_2, C}$.
\end{itemize}
These two statements are proved by mutual induction on derivations.
\\
For $\mf{scut}$-interpolation, the critical case is $f = \lleft (f',f'')$, with the partition $\langle \GG_0, (\GG_1, \GG_2) \rangle$ for $\GG$, and two derivations $f' : {-} \mid \GG_0, \GG_1 \vdG A$ and $f'': B \mid \GG_2 \vdG C$.
Our goals is to find a formula $D$ and derivations $g : A\lolli B \mid \GG_0 \vdG D$ and $h: D \mid \GG_1, \GG_2 \vdG C$.
We first apply inductive hypothesis of $\mf{ccut}$-interpolation on $f'$ and then get $g': {-} \mid \GG_0 , D_1, \dots, D_n \vdG A$, $h'_i : {-} \mid \GD_i \vdG D_i$, $i \in [1\dots n]$.
By applying inductive hypothesis of $\mf{scut}$-interpolation on $f''$, we obtain derivations $g'' : B \mid \quad \vdG E$ and $h'': E \mid \GG_2 \vdG C$.
Then we construct desired derivations as follows:
\begin{displaymath}
  \small\begin{array}{c}
    \infer[\lright]{A\lolli B \mid \GG_0 \vdG D_1 \lolli (\dots (D_n \lolli E)\dots)}{
      \deduce{\vdots}{
        \infer[\lright]{A \lolli B \mid \GG_0 , D_1, \dots ,D_{n-1} \vdG D_n \lolli E}{
        \infer[\lleft]{A \lolli B \mid \GG_0 , D_1, \dots, D_n \vdG E}{
          \deduce{{-} \mid \GG_0 , D_1, \dots, D_n \vdG A}{g'}
          &
          \deduce{B \mid \quad \vdG E}{g''}
        }
      }
      }
    }
    \quad
    \infer[\lleft]{D_1 \lolli (\dots (D_n \lolli E)\dots) \mid \GD_1, \dots, \GD_n, \GG_2 \vdG C}{
      \deduce{{-} \mid \GD_1 \vdG D_1}{h'_1}
      &
      \deduce{D_2 \lolli (\dots (D_n \lolli E)\dots) \mid \GD_2, \dots, \GD_n, \GG_2 \vdG C}{
        \deduce{\vdots}{
          \infer[\lleft]{D_n \lolli E \mid \GD_n, \GG_2 \vdG C}{
            \deduce{{-} \mid \GD_n, \GG_2 \vdG D_n}{h'_n}
            &
            \deduce{E \mid \GG_2 \vdG C}{h''}
          }
        }
      }
    }
  \end{array}
\end{displaymath}
Notice that $\GG_1 = \GD_1, \dots, \GD_n$, and the variable condition is easy to check.

For $\mf{ccut}$-interpolation, the critical case is $f = \pass \ f'$, with the partition $\langle [\ ], (A, \GG_1) , \GG_2 \rangle$ and derivation $f' : A \mid \GG_1 , \GG_2 \vdG C$.
In this case, we apply inductive hypothesis of $\mf{scut}$-interpolation on $f'$ and obtain derivations $g': A \mid \GG_1 \vdG D$ and $h' : D \mid \GG_2 \vdG C$, the desired derivations are $\pass \ g' : {-} \mid A , \GG_1 \vdG D$ and $\pass \ h' : {-} \mid D, \GG_2 \vdG C$, i.e. the partition of $A, \GG_1$ is itself and the list of formulae is the singleton list $[D]$.
The variable condition is automatically satisfied.
\begin{theorem*}
  For any $f: A \mid \quad \vdG C$, there exist a formula $B$ and two derivations $g: A\mid \quad \vdash B$ and $h: B\mid \quad \vdash C$, satisfying the variable condition: $\vars{B} \subseteq \vars{A} \cap \vars{C}$.
\end{theorem*}
\begin{proof}
  By applying $\mf{scut}$-interpolation on $f$ with the partition $\langle [\ ], [\ ]\rangle$, we get a formula $B$ and two derivations $g: A \mid \quad \vdG B$ and $h: B \mid \quad \vdG C$, where $\vars{B}\subseteq \vars{s(A), [\ ]} = \vars{A}$ and $\vars{B} \subseteq \vars{[\ ], C} = \vars{C}$, as desired. 
\end{proof}
The arguments above also apply to the sequent calculus for left skew monoidal categories in \cite{uustalu:sequent:2021}.
%  however, it is impossible to find such $D$, $f'_0$, and $f'_1$ by induction without $\mf{ccut}$ interpolation.
% then $D$ is the correct interpolant because we have $\lleft \ f'_0 \ f'' : A \lolli B \mid \GG_0, D, \GG_2 \vdG C$ and the variable condition is satisfied.
% However, it is impossible to find $D$, $f'_0$, and $f'_1$ by induction without $\mf{ccut}$ interpolation.
% \paragraph*{Remark}

The statement of $\mf{ccut}$-interpolation does not align with the general structure of interpolation in non-commutative substructural logic, because the general form of the statement is unprovable in \LSkG.
To illustrate this, consider the following statement:
\begin{itemize}
  \item[\ ] ($\mf{ccut'}$-interpolation) Given $f: S \mid \Gamma \vdG C$ and any partition $\langle \GG_0,\GG_1, \GG_2 \rangle$ of $\GG$, there exist a formula $D$ and two derivations  $g : {-} \mid \GG_1 \vdG D$ and $h : S \mid \GG_0, D, \GG_2 \vdG C$, and $\vars{D} \subseteq \vars{\GG_1} \cap \vars{s(S), \GG_0, \GG_2, C}$.
\end{itemize}
The critical case is $f = \tr (f',f'')$ with the partition $\langle \GG_0, (\GG'_1, \GG''_1), \GG_2\rangle$ and two derivations $f' : S \mid \GG_0 , \GG'_1 \vdG A$ and $f'' : {-} \mid \GG''_1 , \GG_2 \vdG B$.
By induction on $f'$ and the partition $\langle \GG_0 , \GG'_1, [\ ] \rangle$, and on $f''$ and the partition $\langle [\ ], \GG''_1, \GG_2\rangle$ respectively, we have a formula $D$, $g' : {-} \mid \GG'_1 \vdG D$, and $h': S \mid \GG_0 , D \vdG A$ and a formula $E$, $g'' : {-} \mid \GG''_1 \vdG E$ and $h'': {-} \mid E, \GG_2 \vdG B$.
We obtain $\tr (g',g'') : {-} \mid \GG'_1, \GG''_1 \vdG D \ot E$ and $\tr (h', h'') : S \mid \GG_0, D, E, \GG_1 \vdG A \ot B$, so the last step is to produce $D \ot E$ in the latter.
But we get stuck because $\tl$ cannot be applied on formulae in context.

For example, suppose $f = \tr (f',f''): X \mid Y, Z \vdG (X\ot Y)\ot Z$ where $f':X \mid Y \vdG X\ot Y$ and $f'': {-} \mid Z \vdG Z$, then given the partition $\langle [\ ], (Y,Z), [\ ]\rangle$, our goal is to find a formula $D$ and two derivations $g: {-} \mid Y, Z \vdG D$ and $X \mid D \vdG (X\ot Y)\ot Z$.
Because $Y$ and $Z$ are atomic, the only possibility is that $D = Y \ot Z$, however, the sequent $X \mid Y \ot Z \vdG (X \ot Y) \ot Z$ does not have a proof in \LSkG.
\begin{equation*}\label{example:ccut:failure}
  \small\begin{array}{c}
    \infer[\tr]{X \mid Y \ot Z \vdG (X \ot Y) \ot Z}{
    \deduce{X \mid Y\ot Z \vdG X \ot Y}{??}
    &
    \deduce{{-} \mid \quad \vdG Z}{??}
  }
  \qquad
  \infer[\tr]{X \mid Y \ot Z \vdG (X \ot Y) \ot Z}{
    \infer[\tr]{X \mid \quad \vdG X \ot Y}{
      \infer[\ax]{X \mid \quad \vdG X}{}
      &
      \deduce{{-} \mid \quad \vdG Y}{??}
    }
    &
    \infer[\pass]{{-} \mid Y \ot Z \vdG Z}{
      \infer[\tl]{Y \ot Z \mid \quad \vdG Z}{
        \deduce{Y \mid Z \vdG Z}{??}
      }
    }
  }
  \end{array}
\end{equation*}
In general, the rule
\begin{displaymath}
  \infer[\ot\mf{C}]{S \mid \GG , A \ot B , \GD \vdG C}{
    \deduce{S \mid \GG, A , B , \GD \vdG C}{}
  }
\end{displaymath}
is not admissible in \LSkG.

% This unsatisfying result motivates us to consider another calculus equivalent to \LSkG.
% A good candidate is \LSkT, a cut-free sequent calculus analogous to \NL, where antecedents are defined as trees.

% Adapted from \cite{moot:categorial:2012}, trees are inductively defined by the grammar $T::= \mf{Fma} \mid {-} \mid(T , T)$, where ${-}$ is an empty tree.
% A context is a tree with a hole defined as $\mc{C} ::= [\cdot] \mid ( \mc{C}, T ) \mid (T, \mc{C})$. 
% The substitution of a hole with a tree is defined recursively:
% \begin{displaymath}
%   \begin{array}{rcl}
%   subst([\cdot], U) &=& U
%   \\
%   subst((T',T[\cdot]), U) &=& (T' , subst(T[\cdot],U) )
%   \\
%   subst((T[\cdot],T'), U) &=& (subst(T[\cdot],U),T' )
%   \end{array}
% \end{displaymath}
% $T[U]$ is an abbreviation of $subst(T[\cdot], U)$.
% Sometimes we omit parentheses for trees when it does not cause ambiguity.
% Sequents in \LSkT~are in the form $T \vdT A$ where $T$ is a tree and $A$ is a single formula.
% \\
% Derivations in \LSkT~are generated recursively by following rules:
% \begin{equation*}\label{eq:seqcalc:skmc:Lam:tree}
%   \small\begin{array}{lc}
%     &
%     \infer[\ax]{A \vdT A}{}
%     \quad
%     \infer[\unitl]{T[\I] \vdT C}{T [{-}] \vdT C}
%     \quad
%     \infer[\unitr]{{-} \vdT \I}{}
%     \quad
%     \infer[\tl]{T [A \ot B] \vdT C}{T [A , B] \vdT C}
%     \quad
%     \infer[\tr]{T , U \vdT A \ot B}{
%       T \vdT A
%       &
%       U \vdT B  
%     }
%     \\[5pt]
%     (\text{logical rules})
%     &
%     \infer[\lleft]{T[A \lolli B , U] \vdT C}{
%       U \vdT A
%       &
%       T[B] \vdT C
%     }
%     \quad
%     \infer[\lright]{T \vdT A \lolli B}{T , A \vdT B}
%     \\[5pt]
%     (\text{structural rules})
%     &
%     % \infer=[\comm]{T[B ; A] \vdT C}{T [A , B] \vdT C}
%     % \quad
%     \infer[\mf{assoc}]{T [(U_0 , U_1) , U_2] \vdT C}{T [U_0 , (U_1 , U_2)] \vdT C}
%     \quad
%     \infer[\mf{unitL}]{T [{-}, U] \vdT C}{T [U] \vdT C}
%     \quad
%     \infer[\mf{unitR}]{T[U] \vdT C}{T[U , {-}] \vdT C}
%   \end{array}
% \end{equation*}
% This calculus is similar to the ones for \NL~\cite{moot:categorial:2012} and \NL~with unit \cite{bulinska:2009} but with semi-associative ($\mf{assoc}$) and semi-unital ($\mf{unitL}$ and $\mf{unitR}$) rules.
% The structural rule $\mf{unitL}$, read bottom-up, removes an empty tree from the left. It helps us to correctly characterize the axiom $\lambda$ in \LSkT, i.e. $\I \ot A \vdT A$ is derivable while $A \vdT \I \ot A$ is not.
% Analogously for the rule $\mf{unitR}$, from a bottom-up perspective, adds an empty tree from the right, and we cannot capture $\rho$ in \LSkT~without $\mf{unitR}$:
% \begin{displaymath}
%   \small\begin{array}{c}
%     \infer[\tl]{\I \ot A \vdT A}{
%       \infer[\unitl]{\I , A \vdT A}{
%         \infer[\mf{unitL}]{{-} , A \vdT A}{
%           \infer[\ax]{A \vdT A}{}
%         }
%       }
%     }
%     \qquad
%     \infer[\mf{unitR}]{X \vdT \I \ot X}{
%       \infer[\tr]{X,{-} \vdT \I \ot X}{
%         \deduce{X \vdT \I}{??}
%         &
%         \deduce{{-} \vdT X}{??}
%       }
%     }
%     % \deduce{X \vdT \I \ot X}{??}
%     \qquad
%     \infer[\mf{unitR}]{A \vdT A \ot I}{
%       \infer[\tr]{A , {-} \vdT A \ot \I}{
%         \infer[\ax]{A \vdT A}{}
%         &
%         \infer[\unitr]{{-} \vdT \I}{}
%       }
%     }
%     \qquad
%     \infer[\tl]{X \ot \I \vdT X}{
%       \infer[\unitl]{X , \I \vdT X}{
%         \deduce{X , {-} \vdT X}{??}
%       }
%     }
%   \end{array}
% \end{displaymath}
% Admissibility of following rules in \LSkT~are proved by structural induction on derivation:
% \begin{displaymath}
%   \small\begin{array}{c}
%     \infer[\tl^{-1}]{T[A , B] \vdT C}{
%       T[A \ot B] \vdT C
%     }
%     \qquad
%     \infer[\unitl^{-1}]{T[{-}] \vdT C}{
%       T[\I] \vdT C
%     }
%     \qquad
%     \infer[\mf{cut}]{T[U] \vdT C}{
%       U \vdT A
%       &
%       T[A] \vdT C
%     }
%   \end{array}
% \end{displaymath}
% A principal tree in the conclusion of a rule is the smallest subtree affected by the rule.
% For example, the principal trees in the following derivations are those in red color.
% \begin{displaymath}
%   \small\begin{array}{c}
%     \infer[\mf{assoc}]{\textcolor{red}{((U'_0 , U''_0), U'''_0)}, (U_1, U_2)  \vdT C}{
%       \deduce{(U'_0 , (U''_0, U'''_0)), (U_1, U_2) \vdT C}{f}
%     }
%     \qquad
%     \infer[\tr]{\textcolor{red}{T , U} \vdT A \ot B}{
%       \deduce{T \vdT A}{f}
%       &
%       \deduce{U \vdT B}{g}  
%     }
%     \qquad
%     \infer[\mf{unitR}]{T[\textcolor{red}{U}] \vdT C}{
%       \deduce{T[U , {-}] \vdT C}{f}
%     }
%   \end{array}
% \end{displaymath}
% We define a function $\Gd$ that transforms a tree into a list of formulae:
% \begin{displaymath}
%   \small\begin{array}{rcl}
%     \Gd(A) &=& A \text{ if } A \in \mf{Fma}
%     \\
%     \Gd({-}) &=& \I
%     \\
%     \Gd(T,U) &=& \Gd(T), \Gd(U)
%   \end{array}
% \end{displaymath}
% % With the function and definitions above, we can prove the interpolation property for \LSkT~following Maehara's method \cite{ono:proof:nonclassical:1998}.
% % \begin{proof}
% %   hi
% % \end{proof}
% \begin{restatable}{theorem}{CraigLSkT}\label{thm:Craig:interpolation:LSkT}
%   Given a derivation, $f : T[U] \vdT C$, then there exist a formula $D$ and two derivations $f_0 : U \vdT D$ and $f_1: T[D] \vdT C$, and $\mf{var} (D) \subseteq \mf{var} (\Gd (U)) \cap \mf{var}(\Gd (T[{-}]), C)$.
% \end{restatable}
% One attempt is to prove by induction on $f$, and the critical case is 
% \begin{displaymath}
%   \small\begin{array}{c}
%     \infer[\mf{assoc}]{T[(U_0, U_1), U_2] \vdT C}{
%       \deduce{T[U_0, (U_1, U_2)] \vdT C}{f}
%     }
%   \end{array}
% \end{displaymath}
% where $U = U_0, U_1$, therefore, the goal is to find a formula $D$ and two derivations $g: U_0, U_1 \vdT D$ and $T[D,U_2] \vdT C$ and $\mf{var} (D) \subseteq \mf{var} (\Gd (U_0, U_1)) \cap \mf{var}(\Gd (T[{-},U_2]), C)$.
% We cannot apply inductive hypothesis on $f$ twice, because the procedure of finding an interpolant formula and corresponding derivations is not height preserving.
% \\
% Therefore, we need a more general lemma:
% \begin{restatable}{lemma}{CraigLSkTGen}\label{thm:GenCraig:interpolation:LSkT}
%   Given trees $U$, $W$, a context $V[\cdot]$, and a derivation, $f : W \vdT C$,
%   if  $V[U] \curly W$, 
%   then there exist a formula $D$ and two derivations $f_0 : U \vdT D$ and $f_1: V[D] \vdT C$, and $\mf{var} (D) \subseteq \mf{var} (\Gd (U)) \cap \mf{var}(\Gd (V[{-}]), C)$, where $V[U] \curly W$ is an arrow in the free skew monoidal category generated from trees defined above.
%   In particular, objects, unit, and tensor product are trees, empty tree, and comma, respectively.
% \end{restatable}
% \begin{proofsketch}
%   Proof proceeds by induction on $f$.
%   \begin{itemize}
%     \item In the case $f = \mf{assoc} f'$, by assumptions, we know $V[U] \curly T[U_0,(U_1,U_2)]$, then by inductive hypothesis, there exist a formula $D$, $f_0 : U \vdT D$, and $f_1: V[D] \vdT C$, where $\mf{var} (D) \subseteq \mf{var} (\Gd (U)) \cap \mf{var}(\Gd (V[{-}]), C)$, as desired. Other structural rules are similar.
%     \item In the case $f = \tl f'$, by the assumption $V[U] \curly T[A \ot B]$, we can construct an arrow $V[U] \curly T[(A, B)]$ by replacing the tree $A\ot B$ with the tree $(A, B)$. Therefore by inductive hypothesis, we obtain the formula and derivations as desired, where the variable condition is satisfied. Other one-premise rules are similar.
%     \item In the case $f = \tr f'f'' : W_1 , W_2 \vdT A \ot B$, we analyze the structure of $V[U]$ and $W$. By assumption, we know $V[U] \curly W_1, W_2$, then there are cases:
%     \begin{itemize}
%       \item $\Gd(U)$ is a sublist of $\Gd(W_1)$ (or $\Gd(W_2)$):
%     \begin{itemize}
%       \item There exist $U'$ and $W'_1[\cdot]$ such that $W_1 = W'_1[U']$ and $U \curly U'$. We apply inductive hypothesis on $f'$ to obtain $g':U \vdT D$ and $h': W'_1[D] \vdT A$. Then we can have a sequent $V[D] \vdT A \ot B$ by applying $\mf{assoc}$ finitely many times on $\tr h'f'': W'_1[D],W_2 \vdT A \ot B$. The dual case is similar.
%       \item If there exists $V'[\cdot]$, $V''[\cdot]$, $W'_1$, and $W''_1[\cdot]$ such that $V''[V'[U]]$, $W_1 = W''_1[W'_1]$, and  $V'[U] \curly W'_1$. In this situation, there exist $U'$ and $V'''$ such that $V'[U] \curly (U', V''') \curly W'_1$. By applying $\mf{assoc}$ finitely many times on $f'$, we obtain $W''_1 [U', V''']\vdT A$ on which we apply inductive hypothesis and get $g':U \vdT D$ and $W''_1[D,V'''] \vdT A$. Analogous to the argument above, we can derive a sequent $V[D] \vdT A \ot B$. The dual case is similar.
%     \end{itemize} 
%       \item $\Gd(W_1)$ is a sublist of $\Gd(U)$:
%       \begin{itemize}
%         \item There exist $U',U''$, and $W''_2$, such that $U \curly (U',U'')$, $U' \curly W_1$, and $(U'', W''_2) \curly W_2$, which means that  In this case, we apply inductive on $f'$ and $f''$ respectively to obtain $g':U' \vdT D$, $h':D \vdT A$, $g'':U''\vdT E$, and $E,W''_2 \vdT B$. By applying $\mf{assoc}$ finitely many times on $\tr g'g''$, we have $U \vdT D \ot E$, and by applying $\mf{assoc}$ finitely many times on $\tl(\mf{assoc}(\tr h'h'')): (D \ot E), W''_2 \vdT A \ot B$, we have $V[(D \ot E)] \vdT A \ot B$.
%       \end{itemize}
%     \end{itemize}
%     \item The $\lleft$ case is similar to $\tr$.
%   \end{itemize}
%   Notice that a set of variables is invariant with respect to tree rewriting, so the variable condition is satisfied automatically in all cases. 
% \end{proofsketch}
% Therefore the interpolation theorem is proved by taking $U = U$, $W = T[U]$, and $V[\cdot] = T[\cdot]$, where $V[U] \curly V[U]$ is automatically true.
%   % The idea is to inspect the structure of $f$.
% %   If $f= \mc{R}f'$ or $\mc{R'}f'f''$ for any one-premise rule $\mc{R}$ or two-premises rule $\mc{R'}$, then we permute $\mf{assoc}$ with $\mc{R}$ ($\mc{R'}$) and apply inductive hypothesis on $\mf{assoc}f'$ (or $\mf{assoc}f''$).
% %   This step is valid because if the height of $\mc{R}f'$ ($\mc{R'}f'f''$) is $n$, then the height of $\mf{assoc}f'$ (or $\mf{assoc}f''$) is $n$ as well.
% %   If $f = \mf{assoc}f'$ again, then we check the principal tree of $\mf{assoc}$.
% %   \begin{itemize}
% %     \item If the principal tree is inside $U_0$, $U_1$, $U_2$, or anywhere in $T$, then we permute the second $\mf{assoc}$ with the first one and apply inductive hypothesis.
% %   \end{itemize} 
% %   Suppose $f = \mc{R} f'$, where $\mc{R}$ is a one-premise rule and neither of $U_0, (U_1, U_2)$ and $(U_1, U_2)$ is the principal tree of $\mc{R}$, then we can permute the rule $\mf{assoc}$ up and apply inductive hypothesis on $\mf{assoc}f'$.
% %   This step is valid because if the height of $\mc{R}f'$ is $n$, then the height of $\mf{assoc}f'$ is $n$ as well.
% %   The last step is to apply $\mc{R}$ appropriately to make sure two derivations are correct, then the interpolant formula is the interpolant of $\mf{assoc}f'$, and the variable condition is automatically satisfied.
% %   If $\mc{R}$ is a two-premises rule, then we proceed similarly to the proof in \cite{ono:proof:nonclassical:1998}.

% %   If $\mc{R} = \mf{unitL}$ and the principal tree is $(U_1, U_2)$, then we we apply the inductive hypothesis on $f'$ to obtain a formula $D$ and two derivations $g: U_0 \vdT D$ and $h: T[D, U_2] \vdT C$.
% %   In this case, formula $D \ot \I$ is the interpolant and the variable condition is satisfied since $\mf{var}(\I) = \emptyset$.

% %   If $\mc{R} = \mf{assoc}$ and the principal tree is $U_0, (U_1, U_2)$ or $(U_1, U_2)$, then we inspect one more step in the derivation until we reach one of the cases above.
% %   This procedure always terminates since $\ax$ and $\unitr$ only have single trees in their antecedents.
% %   % then construct the interpolant formula and derivations as follows:
% %   %     \begin{displaymath}
% %   %       \small\begin{array}{c}
% %   %         \infer[\tr]{U_0,{-} \vdT D \ot \I}{
% %   %           \deduce{U_0 \vdT D}{g}
% %   %           &
% %   %           \infer[\unitr]{{-} \vdT \I}{}
% %   %         }
% %   %         \qquad
% %   %         \infer[\tl]{T[D\ot \I , U_2] \vdT C}{
% %   %           \infer[\unitl]{T[(D, \I) , U_2] \vdT C}{
% %   %             \infer[\mf{assoc}]{T[(D, {-}) , U_2] \vdT C}{
% %   %               \infer[\mf{unitL}]{T[D, ({-} , U_2)] \vdT C}{
% %   %                 \deduce{T[D, U_2] \vdT C}{h}
% %   %               }
% %   %             }
% %   %           }
% %   %         }
% %   %       \end{array}
% %   %     \end{displaymath}
% %   %     The variable condition is satisfied since $\mf{var}(\I) = \emptyset$
% % \end{proof}
% % Adapted from \cite{buszkowski:2010}, let $\Theta$ be a set of formulae that contains $\I$ and is closed under subformulae. 
% % By a $\Theta$-sequent $T \vdT^{\Theta} A$, we mean that all formula appearing in $T$ and $A$ are in $\Theta$.
% % A derivation in the form $f: T \vdT^{\Theta} A$ is a derivation consisting of $\GT$-sequents only.
% % Following the discussion from \cite[Section 3]{buszkowski:2010}, we can prove weak interpolation for \LSkT~by further assuming that $\GT$ is closed under $\ot$, which is critical for the inductive case $f = \mf{assoc} f'$.
% % \begin{theorem}\label{thm:interpolation:LSkT}
% %   Given $f : T[U] \vdT^{\Theta} C$, then there exist a formula $A \in \Theta$ and two derivations $f' : U \vdT^{\Theta} A$ and $f'': T[A] \vdT^{\Theta} C$.
% % \end{theorem}
% % \begin{proof}
% %   The cases other than $\mf{unitL}$ are proved by modifying arguments from \cite{bulinska:2009,buszkowski:2010}.
% %   For the case $f = \mf{unitL} \ f': T[{-}, A] \vdT C$, there are three possibilities for $U$, $(i)$ if $U = {-}$ in any place of $T$, then the interpolant is $\I$ and two derivations are $\unitr$ and $\unitl \ (\mf{unitL} \ f')$ ($\unitl$ should be applied on the correct place), $(ii)$ if $U = {-} , A$, then the interpolant is $A$ and two derivations are $\mf{unitL}\ \ax$ and $f'$, and $(iii)$ for any non-empty tree $U$ in any other place of $T$, we apply inductive hypothesis on $f'$ and proceed inductively.
% % \end{proof}
% We have confirmed that \LSkT~enjoys interpolation, so the next step is to check whether it is equivalent to \LSkG.
% The proof of equivalence relies on the following admissible rules, lemma and definition.
% \begin{displaymath}
%   \begin{array}{c}
%     \infer[\tl^{-1}]{A \mid B , \GG \vdG C}{
%       \deduce{A \ot B \mid \GG \vdG C}{f}
%     }
%     \qquad
%     \infer[\unitl^{-1}]{{-} \mid \GG \vdG C}{
%       \deduce{\I \mid \GG \vdG C}{f}
%     }
%   \end{array}
% \end{displaymath}
% \begin{lemma}
%   The rule $\tl$ is invertible in \LSkG, i.e. this rule
%   \begin{displaymath}
%     \infer[\tl^{-1}]{A \mid B , \GG \vdG C}{
%       \deduce{A \ot B \mid \GG \vdG C}{f}
%     }
%   \end{displaymath}
%   is admissible.
% \end{lemma}
% \begin{proof}
%   By structural induction on $f$.
% \end{proof}
% \begin{lemma}
%   If $f: T[B]^* \mid \quad \vdG C$ and $g: A \mid \quad \vdG B$, then $T[A]^* \mid \quad \vdG C$, where $T^*$ transforms a tree into a formula by replacing commas with $\ot$ and ${-}$ with $\I$, respectively.
% \end{lemma}
% \begin{proof}
%   By structural induction on $T[A]^*$ to construct $T[A]^* \mid \quad \vdG T[B]^*$ from $g$.
% \end{proof}
% \begin{proof}
%   Notice that $\mf{scut}$ is admissible in \LSkG, so we only have to check whether $T[A]^* \mid \quad \vdG T[B]^*$ is derivable from $g$.
%   Proof proceeds by induction on the structure of $T[A]$.
%   If $T[A] = A$, then we have $T[A]^* = A$ and $T[B]^* = B$, and we already have $g : A \mid \quad \vdG B$.
%   \\
%   If $T[A] = T'[A] , T''$, then by inductive hypothesis, we have $g': T'[A]^* \mid \quad \vdG T'[B]^*$ and following derivation:
%   \begin{displaymath}
%     \infer[\tl]{T'[A]^* \ot T''^* \mid \quad \vdG T'[B]^* \ot T''^*}{
%       \infer[\tr]{T'[A]^* \mid T''^* \vdG T'[B]^* \ot T''^*}{
%         \deduce{T'[A]^* \mid \quad \vdG T'[B]^*}{g'}
%         &
%         \infer[\pass]{{-}\mid T''^*  \vdG T''^*}{
%           \infer[\ax]{T''^* \mid \quad \vdG T''^*}{}
%         }
%       }
%     }
%   \end{displaymath} 
%   The other case ($T[A] = T'', T'[B]$) is symmetric.
% \end{proof}
% \begin{defn}
%   We define an encoding function $\ldbc {-} \mid {-} \rdbc$ that transforms a tree and an ordered list of formulae into a tree:
% \begin{displaymath}
% \begin{array}{c}
%   \ldbc T \mid [\ ] \rdbc = T
%   \\[5pt]
%   \ldbc T \mid B , \GG \rdbc = \ldbc (T , B) \mid \GG\rdbc
% \end{array}
% \end{displaymath}
% \end{defn}
% With the above lemmata, definition, and functions $s(S)$ that maps a stoup to a formula and $T^*$ that transforms trees into formulae, we can state and prove the equivalence between \LSkG~and \LSkT.
% \begin{theorem}\label{thm:equiv:LSkGLSKT}
% The calculi \LSkG~and \LSkT~are equivalent, meaning that the two statements below are true:
%   \begin{itemize}
%     \item For any derivation $f: S \mid \Gamma \vdG C$, there exists a derivation ${\mf{G2T}} f : \ldbc s(S) \mid \GG \rdbc \vdT C$.
%     \item For any derivation $f: T \vdT C$, there exists a derivation $\mf{T2G} f: T^* \mid \quad \vdG C$.
%   \end{itemize}
% \end{theorem}
% \begin{proof}
%   Both $\mf{G2T}$ and $\mf{T2G}$ are proved by structural induction on $f$.
% \end{proof}
% By the equivalence of \LSkG~and \LSkT, we can prove $\mf{scut}$ interpolation.
% % We define $\GT$-sequents and $\GT$-derivations of \LSkG~analogously to the \LSkT~case.
% % Notice that $\GT$ is closed under $\ot$, therefore theorem (\ref{thm:equiv:LSkGLSKT}) can be lifted to $\GT$-sequents and $\GT$-derivations.
% Given any $f: S \mid \GG \vdG C$ and any partition $\langle \GG_0,\GG_1\rangle$ of $\GG$, we have $\mf{G2T}f: (s (S), \GG_0), \GG_1 \vdT C$.
% $(s (S), \GG_0), \GG_1$ is an abbreviation of $((((\dots (s (S) , A_1), \dots), A_n), B_1), \dots),B_m$, where $\GG_0 = A_1, \dots , A_n$ and $\GG_1 = B_1 , \dots , B_m$ if $\GG_0$ and $\GG_1$ are non-empty.
% Let $s(S), \GG_0$ be $U$, then we apply theorem (\ref{thm:Craig:interpolation:LSkT}) on $\mf{G2T}f$ to obtain a formula $D$ and two derivations $g: s(S), \GG_0 \vdT D$ and $h: D, \GG_1 \vdT C$.
% The next step is to apply $\mf{T2G}$ on $g$ and $h$ respectively, then we have a formula $D$ and derivations $\mf{T2G} g$ and $\mf{T2G} h$.
% By applying $\tl^{-1}$ finitely many times on $\mf{T2G} g$ and $\mf{T2G} h$ respectively, and possibly $\unitl^{-1}$ once on $\mf{T2G} g$ if $S = {-}$, we obtain two derivations $g': S \mid \GG_0 \vdG D$ and $h':D \mid \GG_1\vdG C$ as desired and the variable condition is satisfied automatically.

% Although we can prove $\mf{scut}$ interpolation for \LSkG~via \LSkT, we are still not able to prove it directly in \LSkG.
% The same problem of $\mf{scut}$ interpolation still applies.

% When we adapt this argument to the $\mf{ccut}$ interpolation case, we need to re-associate the tree \linebreak$((s (S), \GG_0), \GG_1),\GG_2$ to isolate $\GG_1$.
% However, the re-association is impossible because we can only move brackets from right to left via $\mf{assoc}$ in \LSkT.
% The reason why \LSkT~enjoys interpolation but \LSkG~does not is that although the antecedent looks flat in \LSkG~, they are trees associating to the left.
% We can see this from the encoding $\ldbc s(S) \mid \GG\rdbc$ of $S \mid \GG$.
% For instance, if $S = A$ and $\GG = B, C, D$, then $\ldbc s(S) \mid \GG\rdbc$ = $(((A, B), C), D)$.
% Intuitively, we can think of \LSkG~as a variation of \LSkT~in which, from the top-down perspective, antecedents are always normalized after each rule application.

% Recall the counterexample $f = \tr f'f''$, where $f':X \mid Y \vdG X \ot Y$ and $f'': {-} \mid Z \vdG Z$ and the partition $\langle [\ ],(Y,Z),[\ ]\rangle$.
% By theorem (\ref{thm:equiv:LSkGLSKT}), we have a derivation:
% \begin{displaymath}
%   \small\begin{array}{c}
%     \infer[\mf{unitR}]{(X, Y), Z \vdT (X \ot Y) \ot Z}{
%       \infer[\mf{assoc}]{((X, Y), {-}), Z \vdT (X \ot Y) \ot Z}{
%         \infer[\unitl^{-1}]{(X, Y), ({-}, Z) \vdT (X \ot Y) \ot Z}{
%           \infer[\tr]{(X, Y), (\I, Z) \vdT (X \ot Y) \ot Z}{
%             \deduce{X, Y \vdT X \ot Y}{\mf{G2T} f'}
%             &
%             \deduce{\I , Z \vdT Z}{\mf{G2T} f''}
%           }
%         }
%       }
%     }
%   \end{array}
% \end{displaymath}
% \begin{displaymath}
%   \small\begin{array}{c}
%     \infer[\tr]{(X, Y), Z \vdT (X \ot Y) \ot Z}{
%       \deduce{X, Y \vdT X \ot Y}{\mf{G2T} f'}
%       &
%       \infer[\mf{unitR}]{Z \vdT Z}{
%         \infer[\unitl^{-1}]{{-}, Z \vdT Z}{
%           \deduce{\I , Z \vdT Z}{\mf{G2T} f''}
%         }
%       }
%     }
%   \end{array}
% \end{displaymath}

% The partition $\langle [\ ],(Y,Z),[\ ]\rangle$ condition is transformed into $T[(Y,Z)] \vdT (X \ot Y) \ot Z$ for some $T[\cdot]$, which is impossible.
% Therefore, the flat antecedents in \LSkG~lead to impossible cases when proving $\mf{ccut}$ interpolation.

% interpolation theorem: given a partition $\langle \GG_0, (\GG'_1, \GG''_1), \GG_2\rangle$ and a formula $f = \tr f' f''$, where $f' : S \mid \GG_0 , \GG'_1 \vdG A$ and $f'' : {-} \mid \GG''_1 , \GG_2 \vdG B$.
% The interpolant formula demands resources from both $f'$ and $f''$, which is reasonable in associative Lambek calculus and other associative substructural logics.
% \textcolor{red}{we can revisit the simple counterexample and explain the difference}
% However, in \LSkG, this causes a problem because $\ot\mf{C}$ is inadmissible.
% In contrast, in \LSkT, the situation is straightforward because the interpolant can only comprise formulae from one of the premises of any two-premises rule.
% Consequently, the flat context conceals the left-associative structure of antecedents in \LSkG, leading to impossible cases when proving interpolation.

% \paragraph{Remark}
% \LSkT, unfortunately, does not enjoy Craig interpolation because it has a similar problem as in $\mf{scut}$ Craig interpolation.
% For example, assume that there is a derivation\footnote{We learned this example from Tarmo Uustalu and Giulio Fellin.}:
% \begin{equation}\label{example:failure:Craig:interpolation:LSkT}
%   \small\begin{array}{c}
%     \infer[\mf{assoc}]{(Y \lolli Z, X \lolli Y), X \vdT Z}{
%     \infer[\lleft]{Y \lolli Z, (X \lolli Y, X) \vdT Z}{
%       \infer[\lleft]{X \lolli Y , X \vdT Y}{
%         \infer[\ax]{X \vdT X}{}
%         &
%         \infer[\ax]{Y \vdT Y}{}
%       }
%       &
%       \infer[\ax]{Z \vdT Z}{}
%     }
%   }
%   \end{array}
% \end{equation}
% Our goal is to find a formula $D$ and two derivations $g: Y \lolli Z, X \lolli Y \vdT D$ and $h: D, X \vdT Z$.
% A good candidate of $D$ is $X \lolli Z$, which, however, cannot be obtained from induction.
% By induction, we can only find a formula $(Y \lolli Z) \ot (X \lolli Y)$ and two derivations $g: Y \lolli Z, X \lolli Y \vdT (Y \lolli Z) \ot (X \lolli Y)$ and $h: (Y \lolli Z) \ot (X \lolli Y) \vdT Z$, but the variable condition is not satisfied.
% The sequent calculus for left skew monoidal categories (\LSkGm) has sequents of the form $S \mid \GG \vdG A$, but formulae are generated by the grammar $A,B::= X \mid \I \mid A \ot B$ and rules are those in (\ref{eq:seqcalc:skmc:Gir}) without $\lleft$ and $\lright$ \cite{uustalu:sequent:2021}.
% We call its equivalent sequent calculus with trees as antecedents \LSkTm.
% As mentioned in Section \ref{sec:intro}, \LSkGm~has a special form of Craig interpolation, i.e. it has $\mf{scut}$ Craig interpolation.
% Moreover, we can prove that \LSkTm~has Craig interpolation as well because the counterexample does not hold in \LSkTm.
% In general, \LSkGm~lacks both Craig and weak $\mf{ccut}$ interpolation due to the inadmissibility of $\ot\mf{C}$.




% \section{Skew Categories}\label{sec:skew:categories}
% In this section, we present the definitions of left (right) skew monoidal closed categories, skew bi-closed categories, and various terms that will be used in the following section for discussion.
% \begin{defn}\label{def:left:skewcat}
% A \emph{left skew monoidal closed category} $\mathbb{C}$ is a category with a unit object $\I$ and two functors $\ot : \mathbb{C} \times \mathbb{C} \rightarrow \mathbb{C}$ and $\lolli : \mathbb{C}^{\mathsf{op}} \times \mathbb{C} \rightarrow \mathbb{C}$ forming an adjunction ${-} \ot B \dashv B \lolli {-}$ for all $B$,
% and three natural transformations $\lambda$, $\rho$, $\alpha$ typed
% 	%\begin{displaymath}
% $\lambda_A : \I \ot A \to A$, $\rho_A : A \to A \ot \I$ and $\alpha_{A,B,C} : (A \ot B) \ot C \to A \ot (B \ot C)$,
% 	%\end{displaymath}
% satisfying coherence conditions on morphisms due to Mac Lane \cite{maclane1963natural}:
% 	\begin{center}
% 	  %(m1)
% 	  % https://q.uiver.app/?q=WzAsMyxbMSwwLCJcXEkgXFxvdCBcXEkiXSxbMCwxLCJcXEkiXSxbMiwxLCJcXEkiXSxbMSwwLCJcXHJob197XFxJfSJdLFswLDIsIlxcbGFtYmRhX3tcXEl9Il0sWzEsMiwiIiwyLHsibGV2ZWwiOjIsInN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XV0=
% 	\begin{tikzcd}
% 		& {\I \ot \I} \\[-.2cm]
% 		\I && \I
% 		\arrow["{\rho_{\I}}", from=2-1, to=1-2]
% 		\arrow["{\lambda_{\I}}", from=1-2, to=2-3]
% 		\arrow[Rightarrow, no head, from=2-1, to=2-3]
% 	\end{tikzcd}
% 	\qquad
% 	%(m2)
% 	% https://q.uiver.app/?q=WzAsNCxbMCwwLCIoQSBcXG90IFxcSSkgXFxvdCBCIl0sWzEsMCwiQSBcXG90IChcXEkgXFxvdCBCKSJdLFsxLDEsIkEgXFxvdCBCIl0sWzAsMSwiQSBcXG90IEIiXSxbMywyLCIiLDAseyJsZXZlbCI6Miwic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFszLDAsIlxccmhvX0EgXFxvdCBCIl0sWzEsMiwiQSBcXG90IFxcbGFtYmRhX3tCfSJdLFswLDEsIlxcYWxwaGFfe0EgLCBcXEkgLCBCfSJdXQ==
% 	\begin{tikzcd}
% 		{(A \ot \I) \ot B} & {A \ot (\I \ot B)} \\[-.3cm]
% 		{A \ot B} & {A \ot B}
% 		\arrow[Rightarrow, no head, from=2-1, to=2-2]
% 		\arrow["{\rho_A \ot B}", from=2-1, to=1-1]
% 		\arrow["{A \ot \lambda_{B}}", from=1-2, to=2-2]
% 		\arrow["{\alpha_{A , \I , B}}", from=1-1, to=1-2]
% 	\end{tikzcd}
	
% 	%(m3)
% 	% https://q.uiver.app/?q=WzAsMyxbMCwwLCIoXFxJIFxcb3QgQSApIFxcb3QgQiJdLFsyLDAsIlxcSSBcXG90IChBIFxcb3QgQikiXSxbMSwxLCJBIFxcb3QgQiJdLFswLDEsIlxcYWxwaGFfe1xcSSAsIEEgLEJ9Il0sWzEsMiwiXFxsYW1iZGFfe0EgXFxvdCBCfSJdLFswLDIsIlxcbGFtYmRhX3tBfSBcXG90IEIiLDJdXQ==
% 	\begin{tikzcd}
% 		{(\I \ot A ) \ot B} && {\I \ot (A \ot B)} \\[-.3cm]
% 		& {A \ot B}
% 		\arrow["{\alpha_{\I , A ,B}}", from=1-1, to=1-3]
% 		\arrow["{\lambda_{A \ot B}}", from=1-3, to=2-2]
% 		\arrow["{\lambda_{A} \ot B}"', from=1-1, to=2-2]
% 	\end{tikzcd}
% 	\qquad
% 	%(m4)
% 	% https://q.uiver.app/?q=WzAsMyxbMCwwLCIoQSBcXG90IEIpIFxcb3QgXFxJIl0sWzIsMCwiQSBcXG90IChCIFxcb3QgXFxJKSJdLFsxLDEsIkEgXFxvdCBCIl0sWzAsMSwiXFxhbHBoYV97QSAsIEIsIFxcSX0iXSxbMiwxLCJBIFxcb3QgXFxyaG9fQiIsMl0sWzIsMCwiXFxyaG9fe0EgXFxvdCBCfSJdXQ==
% 	\begin{tikzcd}
% 		{(A \ot B) \ot \I} && {A \ot (B \ot \I)} \\[-.3cm]
% 		& {A \ot B}
% 		\arrow["{\alpha_{A , B, \I}}", from=1-1, to=1-3]
% 		\arrow["{A \ot \rho_B}"', from=2-2, to=1-3]
% 		\arrow["{\rho_{A \ot B}}", from=2-2, to=1-1]
% 	\end{tikzcd}
	
% 	%(m5)
% 	% https://q.uiver.app/?q=WzAsNSxbMCwwLCIoQVxcb3QgKEIgXFxvdCBDKSkgXFxvdCBEIl0sWzIsMCwiQSBcXG90ICgoQiBcXG90IEMpIFxcb3QgRCkiXSxbMiwxLCJBIFxcb3QgKEIgXFxvdCAoQyBcXG90IEQpKSJdLFsxLDEsIihBIFxcb3QgQikgXFxvdCAoQyBcXG90IEQpIl0sWzAsMSwiKChBIFxcb3QgKEJcXG90IEMpIFxcb3QgRCkiXSxbMCwxLCJcXGFscGhhX3tBICwgQlxcb3QgQyAsIER9Il0sWzEsMiwiQSBcXG90IFxcYWxwaGFfe0IgLCBDICxEfSJdLFszLDIsIlxcYWxwaGFfe0EgLEIgLENcXG90IER9IiwyXSxbNCwzLCJcXGFscGhhX3tBIFxcb3QgQiAsIEMgLCBEfSIsMl0sWzQsMCwiXFxhbHBoYV97QSAsIEIgLEN9IFxcb3QgRCJdXQ==
% 	\begin{tikzcd}
% 		{(A\ot (B\ot C)) \ot D} && {A \ot ((B \ot C) \ot D)} \\[-.2cm]
% 		{((A \ot B)\ot C) \ot D} & {(A \ot B) \ot (C \ot D)} & {A \ot (B \ot (C \ot D))}
% 		\arrow["{\alpha_{A , B\ot C , D}}", from=1-1, to=1-3]
% 		\arrow["{A \ot \alpha_{B , C ,D}}", from=1-3, to=2-3]
% 		\arrow["{\alpha_{A ,B ,C\ot D}}"', from=2-2, to=2-3]
% 		\arrow["{\alpha_{A \ot B , C , D}}"', from=2-1, to=2-2]
% 		\arrow["{\alpha_{A , B ,C} \ot D}", from=2-1, to=1-1]
% 	\end{tikzcd}
% 	\end{center}
% 	\end{defn}
% Left skew monoidal closed category has other equivalent characterizations \cite{street:skew-closed:2013,uustalu:eilenberg-kelly:2020}, because natural transformations $(\lambda, \rho, \alpha)$ are in bijective correspondence with tuples of (extra)natural transformations $(j, i, L)$ typed $j_A : \I \to A \lolli A$, $i_A : \I \lolli A \to A$, and $L_{A,B,C} : B \lolli C \to (A \lolli B) \lolli (A \lolli C)$
% \begin{displaymath}
%   \begin{array}{c}
%     j_A : \I \to A \lolli A
%     \qquad
%     i_A : \I \lolli A \to A
%     \\[5pt]
%     L_{A,B,C} : B \lolli C \to (A \lolli B) \lolli (A \lolli C)
%   \end{array}
% \end{displaymath}
% Moreover, $\alpha$ and $L$ are interdefinable with a natural transformation $\mathsf{p}$ typed $\mathsf{p}_{A , B , C} : (A \ot B) \lolli C \to \linebreak A \lolli (B \lolli C)$, embodying an internal version of the adjunction between $\ot$ and $\lolli$.

% \begin{defn}\label{def:right:skewcat}
% A \emph{right skew monoidal closed category} $(\mathbb{C}, \I, \ot, \lolli)$ is defined with the same objects and adjoint functors as in left skew monoidal closed category but three natural transformations $\lambda^{\mf{R}}$, $\rho^{\mf{R}}$, $\alpha^{\mf{R}}$ are typed
% 	%\begin{displaymath}
% $\lambda^{\mf{R}}_A : A \to \I \ot A$, $\rho^{\mf{R}}_A : A \ot \I \to A$ and $\alpha^{\mf{R}}_{A,B,C} : A \ot (B \ot C) \to (A \ot B) \ot C$.
% 	%\end{displaymath}
% The equations on morphisms are analogous but modified to fit the definition.
% \end{defn}
% Similar to left skew monoidal closed categories, natural transformations $(\lambda^{\mf{R}}, \rho^{\mf{R}}, \alpha^{\mf{R}})$ are in bijective correspondence with tuples ($j^{\mf{R}}, i^{\mf{R}}, L^{\mf{R}}$) typed $j^{\mf{R}}_{A, B} : \mbb{C} (\I , A \lolli B) \to \mbb{C} (A , B)$, $i^{\mf{R}}_{A} : A \to \I \lolli A$, and $L^{\mf{R}}_{A,B,C,D} : \mbb{C} (A , B \lolli (C \lolli D)) \to \exists X. \mbb{C} (A , X \lolli D) \times \mbb{C} (B , C \lolli X)$.
% % \begin{displaymath}
% %   \begin{array}{c}
% %   j^{\mf{R}}_{A, B} : \mbb{C} (\I , A \lolli B) \to \mbb{C} (A , B) \qquad i^{\mf{R}}_{A} : A \to \I \lolli A
% %   \\[5pt]
% %   L^{\mf{R}}_{A,B,C,D} : \mbb{C} (A , B \lolli (C \lolli D)) \to \exists X. \mbb{C} (A , X \lolli D) \times \mbb{C} (B , C \lolli X)
% %   \end{array}
% % \end{displaymath}
% $\mbb{C} (A, B)$ means the set of morphisms from $A$ to $B$.
% The existential quantifier in $L^{\mf{R}}_{A, B, C, D}$ is a coend $\int^{X}$ in its original definition in \cite[Section 4]{uustalu:eilenberg-kelly:2020}. 
% However, in the next sections, we only work with thin categories, so it is safe to replace $\int^{X}$ with an existential quantifier.
% \\
% In the rest of the paper, we usually omit subscripts of natural transformations.
% \begin{defn}\label{def:normal}
%   A left skew monoidal closed category is
%   \begin{itemize}
%     \item[--] \emph{associative normal} if $\alpha$ is a natural isomorphism;
%     \item[--] \emph{left unital normal} if $\lambda$ is a natural isomorphism;
%     \item[--] \emph{right unital normal} if $\rho$ is a natural isomorphism.
%   \end{itemize}
%   The $(j, i, L)$ version is similar. The case of right skew monoidal closed categories is analogous.
% \end{defn}

% \begin{defn}\label{def:SkewBiC}
%   A category $(\mbb{C}, \I , \otl, \llolli, \otr, \rlolli)$ is skew bi-closed (\SkBiC) if there exists a natural isomorphism $\gamma : A \otl B \to B \otr A$, $(\mbb{C}, \I , \otl, \llolli)$ is left skew monoidal closed, and $(\mbb{C}, \I , \otr, \rlolli)$ is right skew monoidal closed.
%   \\
%   This definition combines concepts from skew bi-monoidal and bi-closed categories as introduced in \cite{uustalu:eilenberg-kelly:2020}.
% \end{defn}
% In contrast to the categorical model of associative Lambek calculus, the monoidal bi-closed category, we do not have both left ($\lolli$) and right residuation ($\illol$), but instead have two right residuations corresponding to different tensor products.
% However, with the natural isomorphism $\gamma$, and selecting a specific tensor, we can simulate both left and right residuations.

% In the remainder of the paper, we will develop axiomatic and sequent calculi for \SkBiC~and explore its relational semantics.

% \section{Calculi for \SkBiC}\label{sec:calculi:skbic}
% By defining new formulae and adding rules in \LSkNL, \SkBiC~categories have an axiomatic calculus \SkBiCA, where formulae ($\mf{Fma}$) are inductively generated by the grammar $A,B::= X \mid \I \mid A \otl B \mid A \llolli B \mid A \otr B \mid A \rlolli B$. $X$ and $\I$ adhere to the definitions provided in Section \ref{sec:syntax}, and $\otl$ and $\llolli$ ($\otr$ and $\rlolli$) represent left (right) skew multiplicative conjunction and implication, respectively.
% \\
% Derivations in \SkBiCA~are inductively generated by following rules: 
% \begin{equation*}\label{eq:seqcalc:biskmc:Lam}
%   % \def\arraystretch{1.5}
%   \small\begin{array}{c}
%         \infer[\id]{A \vdL A}{}
%         \quad
%         \infer[\mathsf{comp}]{A \vdL C}{
%           A \vdL B
%           &
%           B \vdL C
%         }
%         \quad
%       \infer[\otl]{A \otl B \vdL C \otl D}{
%         A \vdL C
%         &
%         B \vdL D
%       }
%       \quad
%       \infer[\llolli]{A \llolli B \vdL C \llolli D}{
%         C \vdL A
%         &
%         B \vdL D
%       }
%       \\[5pt]
%       \infer[\otr]{A \otr B \vdL C \otr D}{
%         A \vdL C
%         &
%         B \vdL D
%       }
%       \quad
%       \infer[\rlolli]{A \rlolli B \vdL C \rlolli D}{
%         C \vdL A
%         &
%         B \vdL D
%       }
%       \\[5pt]
%       \infer[\lambda]{\I \otl A \vdL A}{}
%       \quad
%       \infer[\rho]{A \vdL A \otl \I}{}
%       \quad
%       \infer[\alpha]{(A \otl B) \otl C \vdL A \otl (B \otl C)}{}
%       \\[5pt]
%       \infer[\lambda^{\mf{R}}]{A \otr \I \vdL A}{}
%       \quad
%       \infer[\rho^{\mf{R}}]{A \vdL \I \otr A}{}
%       \quad
%       \infer[\alpha^{\mf{R}}]{A \otr (B \otr C) \vdL (A \otr B) \otr C}{}
%       \\[5pt]
%       \infer[\Gg]{A \otl B \vdL B \otr A}{}
%       \quad
%       \infer[\Gg^{-1}]{A \otl B \vdL B \otr A}{}
%       \quad
%       \infer=[\pi]{A \vdL B \llolli C}{A \otl B \vdL C}
%       \quad
%       \infer=[\pi^{\mf{R}}]{A \vdL B \rlolli C}{A \otr B \vdL C}
%   \end{array}
% \end{equation*}

% However, it remains unclear how to construct a sequent calculus {\`a} la Girard for \SkBiC.
% A simpler scenario to consider is the sequent calculus for right skew closed categories.
% In this context, recalling the definition (\ref{def:right:skewcat}), where natural transformations are in an opposite direction compared to left skew monoidal closed categories.
% One approach is to propose a dual sequent calculus to (\ref{eq:seqcalc:skmc:Gir}).
% Here, sequents would take the form $\GG \mid S \vdG A$, indicating a reversal of stoup and context, with all left rules applicable solely to the stoup.
% We should think of the antecedents as trees associating to the right, structured as $(A_n, (\dots, (A_1, A_0)) \dots)$.
% Nevertheless, $\rlolli$, by definition, is again a right residuation, implying that $\rlleft$ and $\rlright$ should resemble those in (\ref{eq:seqcalc:skmc:Gir}).
% This requirement then necessitates contexts to appear on the right-hand side of the stoup.

% % Fortunately, sequent calculus in the style of \LSkT captures skew bi-closed categories nicely.
% % We call the calculus \SkBiCT~in which formulae are inductively generated by the grammar $A,B::= X \mid \I \mid A \otl B \mid A \llolli B \mid A \otr B \mid A \rlolli B$, where $X$ and $\I$ are the same as in section (\ref{sec:syntax}), and $\otl$ and $\llolli$ ($\otr$ and $\rlolli$) are left (right) skew multiplicative conjunction and implication.
% Fortunately, we can develop a sequent calculus, denoted as \SkBiCT, which is inspired by \LSkT~to characterize \SkBiC~categories.
% Specifically, \SkBiCT~is an instantiation of Moortgat's multimodal Lambek calculus \cite{moortgat:multimodl:1996} with unit.

% Trees in \SkBiCT~are inductively defined by the grammar $T ::= \mf{Fma} \mid {-}\mid (T, T)\mid(T;T)$.
% What we have defined are trees with two different ways of linking nodes: through the use of commas and semicolons, corresponding to $\otl$ and $\otr$, respectively.
% Contexts and substitution are defined analogously to those of \LSkT.
% Sequents are in the form $T \vdT A$ analogous to those in Section \ref{sec:syntax}.
% % Contexts and substitution are defined analogously to those outlined in Section \ref{sec:syntax}.
% \\
% Derivations in \SkBiCT~are generated recursively by following rules:
% \begin{displaymath}
%   \footnotesize\begin{array}{lc}
%     &
%     \infer[\ax]{A \vdT A}{}
%     \quad
%     \infer[\unitr]{{-} \vdT \I}{}
%     \quad
%     \infer[\unitl]{T[\I] \vdT C}{T [{-}] \vdT C}
%     \\[5pt]
%     (\text{logical rules})
%     &
%     \textcolor{red}{
%     \infer[\tll]{T [A \ot^{\mf{L}} B] \vdT C}{T [A , B] \vdT C}
%     \quad
%     \infer[\trl]{T , U \vdT A \ot^{\mf{L}} B}{
%       T \vdT A
%       &
%       U \vdT B
%     }
%     }
%     \quad
%     \textcolor{blue}{
%     \infer[\tlr]{T [A \ot^{\mf{R}} B] \vdT C}{T [A ; B] \vdT C}
%     \quad
%     \infer[\trr]{T ; U \vdT A \ot^{\mf{R}} B}{
%       T \vdT A
%       &
%       U \vdT B
%     }
%     }
%     \\[5pt]

%     &
%     \textcolor{red}{
%     \infer[\llleft]{T[A \llolli B , U] \vdT C}{
%       U \vdT A
%       &
%       T[B] \vdT C
%     }
%     \quad
%     \infer[\llright]{T \vdT A \llolli B}{T , A \vdT B}
%     }
%     \quad
%     \textcolor{blue}{
%       \infer[\rlleft]{T[A \rlolli B ; U] \vdT C}{
%       U \vdT A
%       &
%       T[B] \vdT C
%     }
%     \quad 
%     \infer[\rlright]{T \vdT A \rlolli B}{T ; A \vdT B}
%     }
%     \\[5pt]
%     (\text{structural rules})
%     &
%     \textcolor{red}{
%     \infer[\assl]{T [(U_0 , U_1) , U_2] \vdT C}{T [U_0 , (U_1 , U_2)] \vdT C}
%     }
%     \quad
%     \infer=[\comm]{T[U_1 ; U_0] \vdT C}{T [U_0 , U_1] \vdT C}
%     \quad
%     \textcolor{blue}{
%     \infer[\assr]{T [U_0 ; (U_1 ; U_2)] \vdT C}{T [(U_0 ; U_1) ; U_2] \vdT C}
%     }
%     \\[5pt]
    
%     &
%     \textcolor{red}{
%     \infer[\mf{unitL^{L}}]{T[{-},U] \vdT C}{T[U] \vdT C}
%     \quad
%     \infer[\mf{unitR^{L}}]{T[U] \vdT C}{T[U,{-}] \vdT C}
%     }
%     \quad
%     \textcolor{blue}{
%     \infer[\mf{unitL^{R}}]{T[U;{-}] \vdT C}{T[U] \vdT C}
%     \quad
%     \infer[\mf{unitR^{R}}]{T[U] \vdT C}{T[{-};U] \vdT C}
%     }
%   \end{array}
% \end{displaymath}
% We can think of these rules as originating from two separate calculi: \LSkT~(the red part with $\ax,\unitr$, and $\unitl$) and another for right skew monoidal closed categories (\RSkT, the blue part with $\ax,\unitr$, and $\unitl$), linked by $\comm$.
% \SkBiCT~can be condensed to have solely the rules outlined below.
% \begin{displaymath}
%   \footnotesize\begin{array}{lc}
%     &
%     \infer[\ax]{A \vdT A}{}
%     \quad
%     \infer[\unitr]{{-} \vdT \I}{}
%     \quad
%     \infer[\unitl]{T[\I] \vdT C}{T {-} \vdT C}
%     % \quad
%     % \infer[\unitl^{\mf{R}}]{T[A ; \I] \vdT C}{T [A] \vdT C}
%     \\[5pt]
%     (\text{logical rules})
%     &
%     \infer[\tll]{T [A \otl B] \vdT C}{T [A , B] \vdT C}
%     \quad
%     \infer[\trl]{T , U \vdT A \otl B}{
%       T \vdT A
%       &
%       U \vdT B  
%     }
%     \quad
%     \infer[\tlr]{T [B \otr A] \vdT C}{T [A ; B] \vdT C}
%     \quad
%     \infer[\trr]{T, U \vdT B \otr A}{
%       T \vdT A
%       &
%       U \vdT B
%     }
%     \\[5pt]
    
%     &
%     \infer[\llleft]{T[A \llolli B,U] \vdT C}{
%       U \vdT A
%       &
%       T[B] \vdT C
%     }
%     \quad
%     \infer[\llright]{T \vdT A \llolli B}{T, A\vdT B}
%     \quad
%     \infer[\rlleft]{T[U, A \rlolli B] \vdT C}{
%       U \vdT A
%       &
%       T[B] \vdT C
%     }
%     \quad 
%     \infer[\rlright]{T \vdT A \rlolli B}{A, T\vdT B}
%     \\[5pt]
%     (\text{structural rules})
%     &
%     % \infer=[\comm]{T[B ; A] \vdT C}{T [A , B] \vdT C}
%     % \quad
%     \infer[\assl]{T [(U_0 , U_1) , U_2] \vdT C}{T [U_0 , (U_1 , U_2)] \vdT C}
%     \quad
%     \infer[\mf{unitL^{L}}]{T[{-},U] \vdT C}{T[U] \vdT C}
%     \quad
%     \infer[\mf{unitR^{L}}]{T[U] \vdT C}{T[U,{-}] \vdT C}
%     % \quad
%     % \infer[\assr]{T [A ; (B ; C)] \vdT D}{T [(A ; B) ; C] \vdT D}
%   \end{array}
% \end{displaymath}
% % To fully elucidate the structure of \SkBiC, we will continue using the intricate version \SkBiCT~throughout the remainder of the paper.
% The equivalence between \SkBiCA~and \SkBiCT~can be proved by structural induction.
% \begin{theorem}
% \SkBiCT~is equivalent to \SkBiCA, meaning that following two statements are true:
%   \begin{itemize}
%     \item For any derivation $f:A \vdL C$, there exists a derivation $\mf{A2G} f : A \vdT C$.
%     \item For any derivation $f:T \vdT C$, there exists a derivation $\mf{G2A} f : T^{\#} \vdL C$, where $T^{\#}$ transforms a tree into a formula by replacing commas with $\otl$ and semicolons with $\otr$, and ${-}$ with $\I$, respectively.
%   \end{itemize}
% \end{theorem}
% % Moreover, interpolation for \SkBiCT~can be proved by an argument analogous to the proof of the theorem (\ref{thm:Craig:interpolation:LSkT}).
% % % , which is proved by structural induction with this admissible rule.
% % % \begin{displaymath}
% % %     \small\begin{array}{c}
% % %       \infer=[\mathsf{gen}\ot\mf{comm}]{T [U ,U'] \vdT A}{
% % %       \deduce{T [U';U] \vdT A}{f}
% % %     }
% % %     \end{array}
% % %   \end{displaymath} 
% % % \begin{lemma}
% % %   Given any tree $U, U'$, the rule
% % %   \begin{displaymath}
% % %     \infer=[\mathsf{gen}\ot\mf{comm}]{T [U ,U'] \vdT A}{
% % %       \deduce{T [U';U] \vdT A}{f}
% % %     }
% % %   \end{displaymath} 
% % %   is admissible.
% % % \end{lemma}
% % % \begin{proof}
% % %   By structural induction on $f$.
% % % \end{proof}
% % \begin{theorem}\label{thm:craig:skbict}
% %   Given $f : T[U] \vdT C$ in \SkBiCT, then there exist a formula $D$ and two derivations $f_0 : U \vdT D$ and $f_1: T[D] \vdT C$, and $\mf{var} (D) \subseteq \mf{var} (\Gd (U)) \cap \mf{var}(\Gd (T[{-}]), C)$.
% %   % , and $\vars{B} \subseteq \vars{U^*} \cap \vars{T[B]^*}$, where $T^{\#}$ transforms a tree into a formula by replacing commas with $\otl$ and semicolons with $\otr$.
% % \end{theorem}
% % However, \RSkT~enjoys Craig interpolation since the counterexample (\ref{example:failure:Craig:interpolation:LSkT}) would not happen.


\section{Formalization}
In this ongoing work, we show that sequent calculi for left skew monoidal (closed) categories enjoy Craig interpolation.
The proofs of two statements of generalized interpolation are formalized in the proof assistant Agda.
The code is available at
\begin{center}
  \url{https://github.com/niccoloveltri/code-skewmonclosed/tree/interpolation}.
\end{center}
For the future, we would like to extend the result to other semi-substructural logics in \cite{veltri:coherence:2021,VW:2023}.
% This paper addresses two limitations of the sequent calculus \LSkG~in the previous work on proof theoretical analysis of skew monoidal closed category \cite{UVW:protsn}, i.e. lacking of Craig interpolation and being unable to modularly characterize skew bi-closed categories.

% To overcome the problems, we adapt sequent calculus for non-associative Lambek calculus to the left skew monoidal closed setting.
% The resulting calculus \LSkT~only admits, from a bottom-up perspective, one specific rule $\mf{assoc}$ that moves brackets from left to right and $\mf{unitL}$ ($\mf{unitR}$) that adds (removes) an empty tree from the left (right).

% The proof of interpolation for \LSkT~is more intricate than expected due to the semi-associativity.
% We strengthen the inductive hypothesis by introducing arrows $\curly$ being an accumulator of tree rewriting by which we can rebuild derivations as desired.
% \LSkT~is equivalent to \LSkG~and enjoys Craig interpolation, and by the equivalence of \LSkT~and \LSkG, we prove $\mf{scut}$ interpolation for \LSkG~via \LSkT. 
% Moreover, we extend \LSkT~to \SkBiCT~for modularly capturing \SkBiC~by incorporating rules for right skew monoidal closed categories and a rule $\comm$ that connects left and right skew structures.

% In the last section, we focus on the relational semantics of \SkBiCA~via the Kripke frame $\langle W, \I, \mbb{L}, \mbb{R} \rangle$ where $\mbb{L}$ and $\mbb{R}$  satisfy structural conditions characterizing left and right skew monoidal closed structures respectively and are connected with $\mbb{LR}$ equality.
% Given the Kripke frame, we can construct a thin skew bi-closed category $(\mc{P}(W) , \subseteq, \I, \otl, \llolli, \otr, \rlolli)$.
% From the proof of theorem (\ref{thm:main}), we obtain algebraic proofs of main theorems in \cite{uustalu:eilenberg-kelly:2020}.
% % If we can construct one of the semantics, then we conjecture that we can prove the finite model property of \SkBiCT, and then with the theorem (\ref{thm:craig:skbict}), \SkBiCT~is decidable.

% A future project is to analyze the sequent calculus and left distributive monoidal categories in \cite{VW:2023} similarly in here.
% This project can be treated as a semi-substructural generalization of \cite{buszkowski:2009}.

% Another direction is to explore whether semi-substructural logics also enjoy the uniform interpolation analogous to \cite{alizadeh:2014}.

% We are also interested in incorporating modalities (exponentials in linear logical terminology) with semi-substructural logic as in \cite{moortgat:multimodl:1996,lin:2013} (modalities) and \cite{Blaisdell:subexpon:linear:2022} (subexponentials) with non-associative Lambek calculus and non-commutative and non-associative linear logic.

% The paper presents a sequent calculus for a semi-associative and semi-unital logic,  extending the system introduced in \cite{uustalu:sequent:2021} with additive conjunction and disjunction. Categorical models of this calculus are skew monoidal categories with binary products and coproducts, and the tensor product preserves coproducts on the left: $(A + B) \ot C \cong (A \ot C) + (B \ot C)$.
% Derivations in the sequent calculus are equated by a congruence relation $\circeq$ and canonical representatives of each $\circeq$-equivalence class can be computed in a separate sequent calculus of normal forms, that we dubbed ``focused'' due to its phase separation similar to the one in Andreoli's technique \cite{andreoli:logic:1992}.  It should be remarked that, differently from Andreoli's focusing, and also the maximally multi-focused sequent calculus for skew monoidal closed categories by one of the authors \cite{veltri:multifocus:23}, we do not insist on keeping the focus during the synchronous phase of proof search, and we always privilege the application of left non-invertible rules over right non-invertible ones. In order to achieve completeness wrt. the sequent calculus, the focused system employs a system of tag annotations providing explicit justifications for cases where right non-invertible rules must be applied before the left non-invertible ones.
% %In order to eliminate non-determinism related to permutative conversions of non-invertible rules, the focused calculus prioritizes the left-invertible rules over the right ones and employs tag annotations to ensure completeness.
% The focused sequent calculus is a concrete presentation of the free distributive skew monoidal category on the set of atomic formulae. Therefore the normalization/focusing algorithm determines a procedure for solving the coherence problem of distributive skew monoidal categories.

% In the final part of the paper, we have looked at extensions of the logic with additive units, a skew exchange rule in the style of Bourke and Lack \cite{bourke:lack:braided:2020}, and linear implication. This section still needs to be formalized in Agda, which will be our forthcoming step.

% This paper takes one step further in a large project aiming at modularly analyzing proof systems with categorical models given by categories with skew structure \cite{zeilberger:semiassociative:19, uustalu:sequent:2021,uustalu:proof:nodate,uustalu:deductive:nodate,veltri:coherence:2021,UVW:protsn}. We are interested in looking for applications of these systems to combinatorics and linguistics, following the initial investigation by Zeilberger \cite{zeilberger:semiassociative:19} and Moortgat \cite{moortgat:tamari:20}.
\paragraph{Acknowledgements} 
We would like to thank Jan von Plato, who was an invited speaker at the World Logic Day 2024 in Tallinn, and on that occasion asked about Craig interpolation for \LSkG.
This work was supported by the Estonian Research Council grant PSG749.
%  and the ESF funded Estonian IT Academy research measure (project 2014-2020.4.05.19-0001). 
\bibliographystyle{eptcs}
\bibliography{LSFA24}

% \appendix
\end{document}
